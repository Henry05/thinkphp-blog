O:9:"MagpieRSS":21:{s:6:"parser";i:0;s:12:"current_item";a:3:{s:5:"title";s:46:"Coding 孙宇聪：《人，技术与流程》";s:4:"link";s:42:"http://segmentfault.com/a/1190000003725944";s:2:"id";s:42:"http://segmentfault.com/a/1190000003725944";}s:5:"items";a:39:{i:0;a:11:{s:5:"title";s:72:"[译]使用 Postgres 递归公共表表达式解决旅行销售员问题";s:4:"link";s:42:"http://segmentfault.com/a/1190000003739666";s:2:"id";s:42:"http://segmentfault.com/a/1190000003739666";s:7:"updated";s:25:"2015-09-12T16:58:42+08:00";s:9:"published";s:25:"2015-09-12T16:58:42+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:9:"halfcoder";s:10:"author_uri";s:35:"http://segmentfault.com/u/halfcoder";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:14070:"
<blockquote><p>原文：<a href="https://www.periscope.io/blog/postgres-recursive-cte.html">Solving the Traveling Salesman Problem with Postgres Recursive CTEs</a></p></blockquote>
<p>Many SQL implementations don't have loops, making some kinds of analysis very difficult. Postgres, SQL Server, and several others have the next best thing — recursive CTEs!</p>
<p>许多 SQL 实现没有将循环包括在内，使进行一些分析工作变得很困难。Postgres、SQL Server 以及一些其它的 SQL 实现则提供了下面将要提到的优良特性：递归公共表表达式（recursive CTE）。</p>
<p>We'll use them to solve the <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Traveling Salesman Problem</a> and find the shortest round-trip route through several US cities.</p>
<p>我们将使用它们来解决旅行销售员问题（<a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Traveling Salesman Problem</a> ）并且找出经过若干美国城市的最短巡回路径。</p>
<p><img src="/img/bVpQOa" alt="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/map.png" title="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/map.png"></p>
<h3>使用递归</h3>
<p>Normal CTEs are great at helping to organize large queries. They are a simple way to make temporary tables you can access later in your query.</p>
<p>一般的公共表表达式（CTE）主要用于帮助组织大型查询语句。你可以简便地创建临时表，并在稍后的查询语句中访问它们。</p>
<p><a href="http://www.postgresql.org/docs/8.4/static/queries-with.html">Recursive CTEs</a> are more powerful - they reference themselves and allow you to explore hierarchical data. While that may sound complicated, the underlying concept is very similar to a <code>for</code> loop in other programming languages.</p>
<p>递归公共表表达式（<a href="http://www.postgresql.org/docs/8.4/static/queries-with.html">Recursive CTEs</a>）的能力更强——它们通过自引用，使你能够探索层次化的数据。虽然这听起来很复杂，但其背后的概念和其它编程语言中的 <code>for</code> 循环十分相似。 </p>
<p>These CTEs have two parts — an <code>anchor</code> member and a <code>recursive</code> member. The <code>anchor</code> member selects the starting rows for the recursive steps.</p>
<p>该公共表表达式（CTE）包含两个部分——一个 <strong>anchor</strong> 部分和一个 <strong>recursive</strong> 部分。 <strong>anchor</strong> 部分提供了递归步骤的起始数据。</p>
<p>The <code>recursive</code> member generates more rows for the CTE by first joining against the <code>anchor</code> rows, and then joining against rows created in previous recursions. The <code>recursive</code> member comes after a <code>union all</code> in the CTE definition.</p>
<p><strong>recursive</strong> 部分为此公共表表达式（CTE）生成更多的数据，方法是先连接（join） <strong>anchor</strong> 数据，然后连接（join）上次递归产生的数据。在公共表表达式（CTE）的定义语句中，<strong>recursive</strong> 部分接在 <code>union all</code> 关键字后面。</p>
<p>Here's a simple recursive CTE that generates the numbers 1 to 10. The <code>anchor</code> member selects the value 1, and the <code>recursive</code> member adds to it up to the number 10:</p>
<p>这是一个能产生数字1到10的简单的递归公共表表达式（CTE）。其中 <strong>anchor</strong> 部分提供了数据值1，然后 <strong>recursive</strong> 部分将其逐步累加至10。</p>
<pre><code class="sql">with recursive incrementer(prev_val) as (
  select 1 -- anchor member
  union all
  select -- recursive member
    incrementer.prev_val + 1
  from incrementer
  where prev_val &lt; 10 -- termination condition
)

select * from incrementer</code></pre>
<p>The first time the recursive CTE runs it generates a single row <code>1</code> using the <code>anchor</code> member. In the second execution, the <code>recursive</code> member joins against the <code>1</code> and outputs a second row, <code>2</code>. In the third execution the <code>recursive</code> step joins against both rows <code>1</code> and <code>2</code> and adds the rows <code>2</code> (a duplicate) and <code>3</code>.</p>
<p>该递归公共表表达式（recursive CTE）在第一次执行的时候根据 <strong>anchor</strong> 部分生成了一行数据“1”。在第二次执行中， <strong>recursive</strong> 部分连接到数据“1”并输出了第二行“2”。在第三次执行中，<strong>recursive</strong> 部分同时连接到了数据“1”和“2”并且添加了新数据“2”（重复）和“3”。</p>
<p>Recursive CTEs also only return distinct rows. Even though our CTE above creates many rows with the same value, only a distinct set of rows will be returned.</p>
<p>同时递归公共表表达式（recursive CTE）只返回互不相同的数据。虽然我们的公共表表达式（CTE）创建了许多相同的数据行，但返回的数据集只包含互不相同的数据。</p>
<p>Notice how the CTE specifies its output as the named value <code>prev_val</code>. This lets us refer to the output of the previous recursive step.</p>
<p>注意该公共表表达式（CTE）是如何将其输出命名为 <code>prev_val</code> 的。这使得我们可以引用上一次递归的输出结果。</p>
<p>And at the very end there is a termination condition to halt the recursion once the sum gets to 10. Without this condition, the CTE would enter an infinite loop!</p>
<p>并且在最后的最后有一个终止条件：一旦 sum 到达10就停止递归。如果没有这个条件，该公共表表达式（CTE）将会进入一个无限循环！</p>
<p>Under the hood, the database is building up a table named after this recursive CTE using unions:</p>
<p>这样，数据库以该递归公共表表达式（recursive CTE）为名字，基于并集建立了一个数据表：</p>
<p><img src="/img/bVpQOi" alt="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/incrementer.png" title="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/incrementer.png"></p>
<p>Recursive CTEs can also have many parameters. Here's one that takes the sum, double, and square of starting values of 1, 2 and 3:</p>
<p>递归公共表表达式（recursive CTE）还可以包含多个参数。下面的例子以1、2和3为初始值，分别计算了依次加1的和、倍增值和依次平方的值。</p>
<pre><code class="sql">with recursive cruncher(inc, double, square) as (
  select 1, 2.0, 3.0 -- anchor member
  union all
  select -- recursive member
    cruncher.inc + 1,
    cruncher.double * 2,
    cruncher.square ^ 2
  from cruncher
  where inc &lt; 10
)

select * from cruncher</code></pre>
<p>With recursive CTEs we can solve the Traveling Salesman Problem.</p>
<p>通过使用递归公共表表达式（recursive CTE），我们能够解决旅行销售员问题。</p>
<h3>找出最短路径</h3>
<p>There are many algorithms for finding the shortest round-trip path through several cities. We'll use the simplest: brute force. Our recursive CTE will enumerate all possible routes and their total distances. We'll then sort to find the shortest.</p>
<p>有许多算法可以用于找出经过若干城市的最短巡回路径。我们将使用最简单的一种：暴力搜索。我们的递归公共表表达式（recursive CTE）将枚举所有可能的路径和它们的总距离，然后排序以找出最短的一条。</p>
<p>First, a list of cities with Periscope customers, along with their latitudes and longitudes:</p>
<p>首先是一个顾客所在城市的列表，包含它们的纬度和经度。</p>
<pre><code class="sql">create table places as (
  select
    'Seattle' as name, 47.6097 as lat, 122.3331 as lon
    union all select 'San Francisco', 37.7833, 122.4167
    union all select 'Austin', 30.2500, 97.7500
    union all select 'New York', 40.7127, 74.0059
    union all select 'Boston', 42.3601, 71.0589
    union all select 'Chicago', 41.8369, 87.6847
    union all select 'Los Angeles', 34.0500, 118.2500
    union all select 'Denver', 39.7392, 104.9903
)</code></pre>
<p>And we'll need a distance function to compute how far two lat/lons are from each other (thanks to <a href="http://stackoverflow.com/questions/10034636/postgres-longitude-longitude-query">strkol on stackoverflow.com</a>):</p>
<p>然后我们需要一个距离函数来计算两个经纬度之间的距离（<a href="http://stackoverflow.com/questions/10034636/postgres-longitude-longitude-query">感谢 strkol 在 stackoverflow.com 上的回答</a>）：</p>
<pre><code class="sql">create or replace function lat_lon_distance(
  lat1 float, lon1 float, lat2 float, lon2 float
) returns float as $$
declare
  x float = 69.1 * (lat2 - lat1);
  y float = 69.1 * (lon2 - lon1) * cos(lat1 / 57.3);
begin
  return sqrt(x * x + y * y);
end
$$ language plpgsql</code></pre>
<p>Our CTE will use San Francisco as its anchor city, and then recurse from there to every other city:</p>
<p>我们的公共表表达式（CTE）将使用 San Francisco 作为出发城市，然后从那开始递归抵达其它城市。</p>
<pre><code class="sql">with recursive travel(places_chain, last_lat, last_lon,
    total_distance, num_places) as (
  select -- anchor member
    name, lat, lon, 0::float, 1
    from places
    where name = 'San Francisco'
  union all
  select -- recursive member
    -- add to the current places_chain
    travel.places_chain || ' -&gt; ' || places.name,
    places.lat,
    places.lon,
    -- add to the current total_distance
    travel.total_distance + 
      lat_lon_distance(last_lat, last_lon, places.lat, places.lon),
    travel.num_places + 1
  from
    places, travel
  where
    position(places.name in travel.places_chain) = 0
)</code></pre>
<p>The parameters in the CTE are:</p>
<ul>
<li><p><code>places_chain</code>: The list of places visited so far, which will be different for each instance of the recursion</p></li>
<li><p><code>last_lat and last_lon</code>: The latitude and longitude of the last place in the <code>places_chain</code></p></li>
<li><p><code>total_distance</code>: The distance traveled going from one place to the next in the <code>places_chain</code></p></li>
<li><p><code>num_places</code>: The number of places in <code>places_chain</code> — we'll use this to tell which routes are complete because they visited all cities</p></li>
</ul>
<p>该公共表表达式（CTE）中的参数有：</p>
<ul>
<li><p><code>places_chain</code>：截至目前访问过的位置的列表，在每条递归路径中都是不同的</p></li>
<li><p><code>last_lat and last_lon</code>：<code>places_chain</code> 中最后一个位置的纬度和经度。</p></li>
<li><p><code>total_distance</code>：<code>places_chain</code> 中相邻位置的距离的总和</p></li>
<li><p><code>num_places</code>：<code>places_chain</code> 中位置的数目——我们使用该参数来分辨哪条路径已经完成，由其访问过了所有城市</p></li>
</ul>
<p>In the <code>recursive</code> member, the <code>where</code> clause ensures that we never repeat a place. If we've already visited Denver, <code>position(...)</code> will return a number greater than 0, invalidating this instance of the recursion.</p>
<p>在 <code>recursive</code> 部分中，<code>where</code> 子句确保了我们不会重复访问一个地方。（比如说）如果我们已经访问过 Denver，<code>position(...)</code> 将返回一个大于0的数字，使得该递归路径无效化。</p>
<p>We can see all possible routes by selecting all 8-city chains:</p>
<p>通过列出所有包含了8个城市的城市链，我们可以看到所有可能的路径：</p>
<pre><code class="sql">select * from travel where num_places = 8</code></pre>
<p>We need to add in the distance from the last city back to San Francisco to complete the round-trip. We could hard code San Francisco's lat/lon, but a join is more elegant. Once that's done we sort by distance and show the smallest:</p>
<p>我们需要加上从最后一个城市回到 San Francisco 的距离以完成回路。我们可以在代码中显式写入 San Francisco 的经纬度，但使用连接操作看起来更加优雅。一完成这个我们就可以根据距离进行排序并输出最短路径：</p>
<pre><code>select
  travel.places_chain || ' -&gt; ' || places.name,
  total_distance + lat_lon_distance(
      travel.last_lat, travel.last_lon,
      places.lat, places.lon) as final_dist
from travel, places
where
  travel.num_places = 8
  and places.name = 'San Francisco'
order by 2 -- ascending!
limit 1</code></pre>
<p>Even though this query is significantly more complicated than the <code>incrementer</code> query earlier, the database is doing the same things behind the scenes. The top branch is the creating the CTE's rows, the bottom branch is the final join and sort:</p>
<p>虽然该查询语句明显复杂于之前的 <code>incrementer</code> 查询，数据库在幕后做的事情依然一样。最顶上的分支是创建该公共表表达式（CTE）的数据，最底部的分支是最终的连接和排序。</p>
<p><img src="/img/bVpQOp" alt="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/postgres-cte.png" title="//s3.amazonaws.com/periscope-blog-assets/postgres-ctes/postgres-cte.png"></p>
<p>Run this query and you'll see the shortest route takes 6671 miles and visits the cities in this order:</p>
<p>执行该查询语句，你会看到最短路径需要 6671 英里并且按顺序经过了下列城市：</p>
<blockquote><p>San Francisco -&gt; Seattle -&gt; Denver -&gt;<br>Chicago -&gt; Boston -&gt; New York -&gt; Austin -&gt;<br>Los Angeles -&gt; San Francisco</p></blockquote>
<p>Thanks to recursive CTEs, we can solve the Traveling Salesman Problem in SQL!</p>
<p>得益于递归公共表表达式（recursive CTE），我们成功地用 SQL 解决了旅行销售员问题！</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003739666";}i:1;a:11:{s:5:"title";s:75:"使用git和github管理自己的项目---实际开发环境的管理策略";s:4:"link";s:42:"http://segmentfault.com/a/1190000003739324";s:2:"id";s:42:"http://segmentfault.com/a/1190000003739324";s:7:"updated";s:25:"2015-09-12T14:59:12+08:00";s:9:"published";s:25:"2015-09-12T14:59:12+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"xumenger";s:10:"author_uri";s:34:"http://segmentfault.com/u/xumenger";s:2:"re";a:1:{s:4:"rank";s:1:"3";}s:7:"summary";s:24962:"
<p>基础知识和命令先参考：<a href="http://segmentfault.com/a/1190000003728094">使用git和github管理自己的项目---基础操作学习</a></p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758410364457b9e3d821f4244beb0fd69c61a185ae0000">13.分支管理策略</a></h2>
<p>通常，合并分支时，如果可能，Git会用<code>Fast forward</code>模式，但这种模式下，删除分支后，会丢掉分支信息。</p>
<p>如果要强制禁用<code>Fast forward</code>模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。</p>
<p>下面我们实战一下<code>--no-ff</code>方式的<code>git merge</code>：</p>
<ul>
<li><p><code>git checkout -b dev</code> 创建并切换到dev分支</p></li>
<li><p><code>vim readme.txt</code> 修改readme.txt文件</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "add merge"</code> 提交一个新的commit</p></li>
<li><p><code>git checkout master</code> 切回master分支</p></li>
<li><p><code>git merge --no-ff -m "merge with with no-ff" dev</code> 准备合并dev分支，注意<code>--no-ff</code>参数表示禁用Fast forward，因为本次合并要创建一个新的commit，所以加上<code>-m</code>参数，把commit描述写进去</p></li>
<li><p><code>git log --graph --pretty=oneline --abbrev-commit</code> 合并后查看分支历史</p></li>
</ul>
<p>合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758410364457b9e3d821f4244beb0fd69c61a185ae0000">14.分支策略</a></h2>
<p>在实际开发中，我们应该按照几个基本原则进行分支管理：</p>
<ul>
<li><p>首先，<code>master</code>分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活</p></li>
<li><p>那在哪里干活呢？干活都在<code>dev</code>分支上，也就是说，<code>dev</code>分支是不稳定的，到某个时候，比如2.0版本发布时，再把<code>dev</code>分支合并到<code>master</code>上，在<code>master</code>分支发新版本</p></li>
<li><p>你和你的小伙伴每个人都在<code>dev</code>分支上干活，每个人都有自己的分支，时不时往<code>dev</code>分支上合并就可以了</p></li>
</ul>
<p>所以，团队合作的分支看起来就像这个样子：<br><img src="/img/bVcc7H" alt="图片描述" title="图片描述"></p>
<p>Git分支十分强大，在团队开发中应该充分应用。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137602359178794d966923e5c4134bc8bf98dfb03aea3000">15.Bug分支</a></h2>
<p>软件开发中，bug就像是家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。</p>
<p>当你街道一个修复代号为101的bug的任务的时候，很自然的，你想创建一个分支<code>issue-101</code>来修复它，但是，等等，当前正在<code>dev</code>上进行的工作还没有提交：</p>
<ul><li><p><code>git status</code> 查看状态</p></li></ul>
<p>并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？</p>
<p>幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：</p>
<ul>
<li><p><code>git stash</code> 用该命令查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心的创建分支来修复bug了。</p></li>
<li><p><code>git checkout master</code> 从dev分支切换回master</p></li>
<li><p><code>git checkout -b issue-101</code>  假定需要在master分支上修复，就从<code>master</code>创建临时分支</p></li>
<li><p>假设现在修复好了bug，本例中，就假如在readme.txt文件中做了修改</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "fic bug 101"</code> 修改之后提交</p></li>
<li><p><code>git checkout master</code> 从issue-101切换回master</p></li>
<li><p><code>git merge --no-ff -m "merged bug fix 101" issue-101</code> 合并分支选择不适用Fast forward模式，然后添加必要的描述信息</p></li>
<li><p><code>git branch -d issue-101</code> 删除issue-101这个临时bug修复分支</p></li>
<li><p>太棒了，bug搞定了，现在可以回到<code>dev</code>分支干活了</p></li>
<li><p><code>git checkout dev</code> 切换回dev分支</p></li>
<li><p><code>git status</code> 可以看出工作区是干净的，那么刚才的工作现场存在哪里呢？</p></li>
<li><p><code>git stash list</code> 看到工作现场还在，Git吧stash内容存在某个地方了，但是需要恢复一下</p></li>
<li><p>方法一<code>git stash apply</code>，但是回复后，stash内容并不删除，你需要使用<code>git stash drop</code>来删除</p></li>
<li><p>方法二<code>git stash pop</code>，恢复的同时也把stas内容删除了</p></li>
<li><p><code>git stash list</code> 再用git stash list查看，就看不到任何stash内容了</p></li>
<li><p>你可以多次<code>stash</code>，恢复的时候，先用<code>giit stash list</code> 查看，然后恢复指定的stash，使用如下的命令</p></li>
<li><p><code>git stash apply stash@{0}</code></p></li>
</ul>
<p>修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除。</p>
<p>当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001376026233004c47f22a16d1f4fa289ce45f14bbc8f11000">16.Feature分支</a></h2>
<p>软件开发中，总有无穷无尽的新的功能要不断添加进来。</p>
<p>添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。</p>
<p>现在，你终于接到了一个新任务：开发代号为Vulcan的新功能，该功能计划用于下一代星际飞船。软件开发中，总有无穷无尽的新的功能要不断添加进来。</p>
<p>添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。</p>
<p>现在，你终于接到了一个新任务：开发代号为Vulcan的新功能，该功能计划用于下一代星际飞船。于是开始准备工作</p>
<ul>
<li><p><code>git checkout -b feature-vulcan</code> 在dev分支上创建并且换到feature-vulcan分支，用来开发新功能</p></li>
<li><p>假如现在经过一定的时间后，工作完成了</p></li>
<li><p><code>git add vulcan.py</code></p></li>
<li><p><code>git status</code> 查看状态</p></li>
<li><p><code>git commit -m "add feature vulcan"</code> 提交</p></li>
<li><p><code>git checkout dev</code> 切换回dev分支</p></li>
<li><p>一切顺利的话，feature分支和bug分支是类似的，合并，然后删除。但是，就在此时，接到上级命令，因经费不足，新功能必须取消！虽然白干了，但是这个分支还是必须就地销毁，不要再合并了:</p></li>
<li><p><code>git branch -d feature-vulcan</code> 销毁失败。Git友情提醒，feature-vulcan分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用命令git branch -D feature-vulcan。</p></li>
<li><p><code>git branch -D feature-vulcan</code></p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013760174128707b935b0be6fc4fc6ace66c4f15618f8d000">17.多人协作</a></h2>
<p>当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。</p>
<p><strong>推送分支</strong></p>
<ul>
<li><p><code>git remote</code> 查看远程库的信息</p></li>
<li><p><code>git remote -v</code> 显示更为详细的信息</p></li>
<li><p><code>git push origin master</code> 推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上。</p></li>
<li><p><code>git push origin dev</code> 也可以推送到其他的分支，比如dev分支</p></li>
<li><p>但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？master分支是主分支，因此要时刻与远程同步；dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。总之，就是在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！</p></li>
</ul>
<p><strong>抓取分支</strong></p>
<p>多人协作时，大家都会往master和dev分支上推送各自的修改。</p>
<ul>
<li><p><code>git clone git@github.com:michaelliao/learngit.git</code>  现在，模拟一个你的小伙伴，可以在另一台电脑（注意要把SSH Key添加到GitHub）或者同一台电脑的另一个目录下克隆。</p></li>
<li><p><code>git branch</code> 当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的master分支，所以执行这条命令只能看到master分支</p></li>
<li><p><code>git checkout -b dev origin/dev</code> 现在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支</p></li>
<li><p><code>git commit -m "add /usr/bin/env"</code> 现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程。</p></li>
<li><p><code>git add hello.py</code> <code>git commit -m "add coding: utf-8"</code> <code> git push origin dev</code> 你的小伙伴已经向origin/dev分支推送了他的提交，而碰巧你也对同样的文件作了修改，并试图推送。推送失败，因为你的小伙伴的最新提交和你试图推送的提交有冲突。</p></li>
<li><p><code>git pull</code> 解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送。</p></li>
<li><p><code>git branch --set-upstream dev origin/dev</code> git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接。</p></li>
<li><p><code>git pull</code> 再次pull，这回git pull成功，但是合并有冲突，需要手动解决，解决的方法和分支管理中的解决冲突完全一样</p></li>
<li><p><code>git commit -m "merge &amp; fix hello.py"</code> <code>git push origin dev</code> 解决冲突后，再提交，再push</p></li>
</ul>
<p><strong>因此，多人协作的工作模式通常是这样的：</strong></p>
<ul>
<li><p>首先，可以试图用<code>git push origin branch-name</code> 推送自己的修改</p></li>
<li><p>如果推送失败，则因为远程分支比你的本地更新，需要先用<code>git pull</code>试图合并</p></li>
<li><p>如果合并有冲突，则解决冲突，并在本地提交</p></li>
<li><p>没有冲突或者解决掉冲突之后，再用<code>git push origin branch-name</code>推送就能成功</p></li>
<li><p>如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream branch-name origin/branch-name。<strong>这就是多人协作的工作模式，一旦熟悉了，就非常简单。</strong></p></li>
</ul>
<h2>18.标签管理</h2>
<p>发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。<strong>所以，标签也是版本库的一个快照。</strong></p>
<p><strong>Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。</strong></p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001376951758572072ce1dc172b4178b910d31bc7521ee4000">19.创建标签</a></h2>
<ul>
<li><p><code>git branch</code> 查看当前有哪些分支</p></li>
<li><p><code>git checkout master</code> 在Git中打标签非常简单，首先，切换到需要打标签的分支上</p></li>
<li><p><code>git tag tagnamev1.0</code> 打一个新标签</p></li>
<li><p><code>git tag</code> 查看所有标签</p></li>
<li><p>默认标签是打在最新提交的commit上的（也就是<code>HEAD</code>）。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？</p></li>
<li><p><code>git log --pretty=oneline --abbrev-commit</code> 方法是找到历史提交的commit id，然后打上就可以了，这时候显示了提交的历史信息 ，假如有这么一条就是你想打标签的历史commit：<code>6224937 add merge</code></p></li>
<li><p><code>git tag tagnamev2.0 6224937</code> 就可以给这次提交打标签了</p></li>
<li><p><code>git tag</code> 可以查看标签信息，注意，标签不是按时间顺序列出，而是按字母排序的</p></li>
<li><p><code>git show tagnamev2.0</code> 查看具体的某个标签的信息</p></li>
<li><p><code>git tag -a v0.1 -m "version 0.1 released" 3628164</code> 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字</p></li>
<li><p><code>git show v0.1</code> 查看具体的某个标签的信息，可以看到说明文字</p></li>
<li><p><code>git tag -s v0.2 -m "signed version 0.2 released" fec145a</code> 还可以通过-s用私钥签名一个标签，签名采用PGP签名，因此，必须首先安装gpg（GnuPG），如果没有找到gpg，或者没有gpg密钥对，就会报错</p></li>
<li><p><code>git show v0.2</code>  用命令git show &lt;tagname&gt;可以看到PGP签名信息，用PGP签名的标签是不可伪造的，因为可以验证PGP签名。</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001376951885068a0ac7d81c3a64912b35a59b58a1d926b000">20.操作标签</a></h2>
<ul>
<li><p><code>git tag -d v0.1</code> 假如标签打错了，也可以删除，因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。</p></li>
<li><p><code>git push origin v1.0</code> 要推送某个标签到远程</p></li>
<li><p><code>git push origin --tags</code> 或者，一次性推送全部尚未推送到远程的本地标签</p></li>
<li><p><code>git tag -d v0.9</code> 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除</p></li>
<li><p><code>git push origin :refs/tags/v0.9</code> 然后，从远程删除。删除命令也是push，但是格式要注意</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137628548491051ccfaef0ccb470894c858999603fedf000">21.使用Github</a></h2>
<p>如何参与一个开源项目呢？比如人气极高的bootstrap项目，这是一个非常强大的CSS框架。</p>
<ul>
<li><p>你可以访问它的项目主页<a href="https://github.com/twbs/bootstrap">https://github.com/twbs/bootstrap</a>，点“Fork”就在自己的账号下克隆了一个bootstrap仓库</p></li>
<li><p><code>git clone git@github.com:yourname/bootstrap.git</code> 然后，从自己的账号下clone</p></li>
<li><p>一定要从自己的账号下clone仓库，这样你才能推送修改。如果从bootstrap的作者的仓库地址git@github.com:twbs/bootstrap.git克隆，因为没有权限，你将不能推送修改。</p></li>
</ul>
<p>Bootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样：<br><img src="/img/bVpQU9" alt="图片描述" title="图片描述"></p>
<p>如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送。</p>
<p><strong>如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了。</strong></p>
<p>如果你没能力修改bootstrap，但又想要试一把pull request，那就Fork一下廖雪峰的仓库：<a href="https://github.com/michaelliao/learngit">https://github.com/michaelliao/learngit</a>，创建一个<code>your-github-id.txt</code>的文本文件，比如我的：<code>xumenger.txt</code>，写点自己学习Git的心得，然后推送一个pull request给他，他会视心情而定是否接受。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137621280731812dec22ecc9b44f4b2ca1c680f181a5b000">22.自定义Git</a></h2>
<p>之前已经说过在使用之前必须先配置<code>user.name</code>和<code>user.email</code>，否则后面commit的时候可能会有错误，实际上git还有很多可配置的：</p>
<ul><li><p><code>git config --global color.ui true</code> 让Git显示颜色，会让命令输出看起来更醒目，自己去试试一些git命令的输出看看是不是有色！</p></li></ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758404317281e54b6f5375640abbb11e67be4cd49e0000">23.忽略特殊文件</a></h2>
<p>有些时候，你必须把某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件啦，等等，每次git status都会显示Untracked files ...，有强迫症的童鞋心里肯定不爽。</p>
<p>好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。</p>
<p>不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：<a href="https://github.com/github/gitignore">https://github.com/github/gitignore</a></p>
<p><strong>忽略文件的原则是：</strong></p>
<ul>
<li><p>忽略操作系统自动生成的文件，比如缩略图等；</p></li>
<li><p>忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；</p></li>
<li><p>忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。</p></li>
</ul>
<p><strong>举个例子</strong></p>
<p>假设你在Windows下进行Python开发，Windows会自动在有图片的目录下生成隐藏的缩略图文件，如果有自定义目录，目录下就会有Desktop.ini文件，因此你需要忽略Windows自动生成的垃圾文件：</p>
<pre><code># Windows:
Thumbs.db
ehthumbs.db
Desktop.ini
</code></pre>
<p>然后，继续忽略Python编译产生的.pyc、.pyo、dist等文件或目录：</p>
<pre><code># Python:
*.py[cod]
*.so
*.egg
*.egg-info
dist
build
</code></pre>
<p>加上你自己定义的文件，最终得到一个完整的.gitignore文件，内容如下：</p>
<pre><code># Windows:
Thumbs.db
ehthumbs.db
Desktop.ini

# Python:
*.py[cod]
*.so
*.egg
*.egg-info
dist
build

# My configurations:
db.ini
deploy_key_rsa
</code></pre>
<p>最后一步就是把.gitignore也提交到Git，就完成了！当然检验.gitignore的标准是git status命令还会不会再说working directory clean。<strong>.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理！</strong></p>
<p>使用Windows的童鞋注意了，如果你在资源管理器里新建一个.gitignore文件，它会非常弱智地提示你必须输入文件名，但是在文本编辑器里“保存”或者“另存为”就可以把文件保存为.gitignore了。</p>
<blockquote><p>再次建议：有钱的买mac，没钱的用ubuntu--或者其他的linux发行版、被逼无奈的用Windows--但是被逼之余的自主时间一定要远离Windows。</p></blockquote>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375234012342f90be1fc4d81446c967bbdc19e7c03d3000">24.配置别名</a></h2>
<blockquote><p>给Git配置好别名，就可以输入命令时偷个懒。我们鼓励偷懒。</p></blockquote>
<ul>
<li><p><code>git config --global alias.st status</code> 有没有经常敲错命令？比如git status？status这个单词真心不好记。如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。</p></li>
<li><p><code>git config --global alias.co checkout</code></p></li>
<li><p><code>git config --global alias.ci commit</code></p></li>
<li><p><code>git config --global alias.br branch</code></p></li>
<li><p>很多人都用co表示checkout，ci表示commit，br表示branch</p></li>
<li><p><code>git ci -m "bala bala bala..."</code> 以后提交就可以简写成这样</p></li>
<li><p><code>git config --global alias.unstage 'reset HEAD'</code> 在<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374831943254ee90db11b13d4ba9a73b9047f4fb968d000">撤销修改</a>一节中，我们知道，命令<code>git reset HEAD file</code>可以把暂存区的修改撤销掉（unstage），重新放回工作区。既然是一个unstage操作，就可以配置一个unstage别名</p></li>
<li><p><code>git unstage test.py</code> 当你敲入此命令，实际上Git执行的是：<code>git reset HEAD test.py</code></p></li>
<li><p><code>git config --global alias.last 'log -1'</code> 配置一个git last，让其显示最后一次提交信息</p></li>
<li><p><code>git config --global alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit"</code> 甚至还有人这样的配置，那么，这时候<code>git lg</code>的效果是这样的<br><img src="/img/bVpQW9" alt="图片描述" title="图片描述"></p></li>
</ul>
<p><strong>配置文件</strong></p>
<p>配置Git的时候，加上<code>--global</code>是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。</p>
<p>配置文件放哪了？每个仓库的Git配置文件都放在<code>.git/config</code>文件中：</p>
<pre><code>$ cat .git/config 
[core]
    repositoryformatversion = 0
    filemode = true
    bare = false
    logallrefupdates = true
    ignorecase = true
    precomposeunicode = true
[remote "origin"]
    url = git@github.com:michaelliao/learngit.git
    fetch = +refs/heads/*:refs/remotes/origin/*
[branch "master"]
    remote = origin
    merge = refs/heads/master
[alias]
    last = log -1
</code></pre>
<p>别名就在<code>[alias]</code>后面，要删除别名，直接把对应的行删掉即可。</p>
<p>而当前用户的Git配置文件放在用户主目录下的一个隐藏文件<code>.gitconfig</code>中：</p>
<pre><code>$ cat .gitconfig
[alias]
    co = checkout
    ci = commit
    br = branch
    st = status
[user]
    name = Your Name
    email = your@email.com
</code></pre>
<p>配置别名也可以直接修改这个文件，如果改错了，可以删掉文件重新通过命令配置。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137583770360579bc4b458f044ce7afed3df579123eca000">25.搭建Git服务器</a></h2>
<p>如果需要的话，请自己参考<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137583770360579bc4b458f044ce7afed3df579123eca000">廖雪峰的教程</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003739324";}i:2;a:11:{s:5:"title";s:24:"spring事务管理总结";s:4:"link";s:42:"http://segmentfault.com/a/1190000003739293";s:2:"id";s:42:"http://segmentfault.com/a/1190000003739293";s:7:"updated";s:25:"2015-09-12T14:48:36+08:00";s:9:"published";s:25:"2015-09-12T14:48:36+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:10:"yemengying";s:10:"author_uri";s:36:"http://segmentfault.com/u/yemengying";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:6329:"
<p>在项目开发过程中经常会使用事务来确保数据的一致性。根据网上的资料整理一下在spring中配置事务的几种方式。<br>无论是哪种方式都需要在配置文件中配置连接池和事务管理器,代码如下。</p>
<pre><code class="xml">   &lt;!-- 读取配置文件 --&gt;
   &lt;bean
        class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
        &lt;property name="locations"&gt;
            &lt;list&gt;
                &lt;value&gt;classpath:database.properties&lt;/value&gt;
                &lt;value&gt;classpath:service.properties&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
        &lt;property name="fileEncoding" value="UTF-8" /&gt;
        &lt;property name="ignoreResourceNotFound" value="false" /&gt;
    &lt;/bean&gt;
    &lt;!--连接池 --&gt;
    &lt;bean id="dataSource"
        class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt;
        &lt;property name="driverClassName" value="${db.driver}" /&gt;
        &lt;property name="url" value="${db.url}" /&gt;
        &lt;property name="username" value="${db.username}" /&gt;
        &lt;property name="password" value="${db.password}" /&gt;
    &lt;/bean&gt;
    &lt;!-- 配置事务管理器 --&gt;
    &lt;bean id="transactionManager"
        class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;
        &lt;property name="dataSource" ref="dataSource" /&gt;
    &lt;/bean&gt;</code></pre>
<h2>声明式事务管理</h2>
<h3>基于AspectJ的XML方式的配置</h3>
<p>这是我觉得最好的方式，基于aop配置，当新增的方法要使用事务管理时，无需修改代码。<br>首先在配置文件xml中引入aop和tx的命名空间</p>
<pre><code>xmlns:tx="http://www.springframework.org/schema/tx" 
xmlns:aop="http://www.springframework.org/schema/aop"
xsi:schemaLocation="http://www.springframework.org/schema/tx
http://www.springframework.org/schema/tx/spring-tx-3.0.xsd
http://www.springframework.org/schema/aop   
http://www.springframework.org/schema/aop/spring-aop-3.0.xsd"</code></pre>
<p>然后在xml中加入aop的配置,下面的配置就是在services的切入点上应用txAdvice的增强，services的切入点就是ymy.com.service.impl包下的所有方法应用txAdvice的增强。然后txAdvice是在所有以create,add,delete,update,change开头的方法上加上事务管理。</p>
<pre><code>    &lt;!-- 定义事务通知 （事务的增强）--&gt;
    &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;
        &lt;!-- 定义方法的过滤规则 --&gt;
        &lt;tx:attributes&gt;
            &lt;!-- 所有方法都使用事务 --&gt;
            &lt;!-- 
                propagation:事务传播行为
                isolation：事务隔离
                read-only:只读
                rollback-for:发生哪些异常回滚
                no-rollback-for:发生哪些异常不回滚 
                timeout:过期信息    
             --&gt;
            &lt;tx:method name="create*" propagation="REQUIRED"/&gt;
            &lt;tx:method name="add*" propagation="REQUIRED"/&gt;
            &lt;tx:method name="delete*" propagation="REQUIRED"/&gt;
            &lt;tx:method name="update*" propagation="REQUIRED"/&gt;
            &lt;tx:method name="change*" propagation="REQUIRED"/&gt;
        &lt;/tx:attributes&gt;
    &lt;/tx:advice&gt;
      
    &lt;!-- 定义AOP配置 配置切面 --&gt;
    &lt;aop:config&gt;
        &lt;!-- 定义一个切入点 --&gt;
        &lt;aop:pointcut expression="execution (* ymy.com.service.impl.*.*(..))" id="services"/&gt;
        &lt;!-- 对切入点和事务的通知，进行适配 --&gt;
        &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="services"/&gt;
    &lt;/aop:config&gt; </code></pre>
<p>采用这种方式配置，当方法是按照事务定义的规则命名时，都会加入事务管理。</p>
<h3>基于注解</h3>
<p>这种方式是我觉得最简单的，第二推荐。要采用注解的方式，需要在配置文件中开启注解事务。</p>
<pre><code>&lt;!-- 开启注解事务 --&gt;
&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;</code></pre>
<p>在使用时只需在对应的类上添加注解@Transactional即可</p>
<pre><code>@Service
@Transactional
public class TaskService implements ITaskService {

}</code></pre>
<p>也可在使用注解时定义事物的传播级别 隔离行为等。。</p>
<pre><code>@Transactional(propagation=Propagation.REQUIRED)</code></pre>
<h3>基于TransactionProxyFactoryBean</h3>
<p>这种方式配置比较麻烦，需要为每一个需要事务管理的类配置一个代理类，不推荐使用。例如我要对taskService进行事务管理，需要如下配置，用代理类对目标类进行增强。</p>
<pre><code>    &lt;!-- 配置service层的代理 --&gt;
    &lt;bean id = "taskServiceProxy" class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean"&gt;
        &lt;!-- 配置目标对象 --&gt;
        &lt;property name = "target" ref="taskService"&gt;&lt;/property&gt;
        &lt;!-- 注入事务管理器 --&gt;
        &lt;property name = "transactionManager" ref="transactionManager"&gt;&lt;/property&gt;
        &lt;!-- 设置需要事务管理的方法 --&gt;
        &lt;property name="transactionAttributes"&gt;
            &lt;props&gt;
                &lt;prop key="update*"&gt;PROPAGATION_REQUIRED&lt;/prop&gt;
            &lt;/props&gt;
        &lt;/property&gt;
    &lt;/bean&gt;</code></pre>
<p>之后在注入service类时，就要注入它的代理类。</p>
<pre><code>@Resource(name = "taskServiceProxy")
private ITaskService taskSerivce;</code></pre>
<h2>编程式事务管理</h2>
<p>超级不推荐，需要为每个类注入事务模板，然后在需要事务管理的方法中使用事务模板。</p>
<pre><code>private TransactionTemplate transactionTemplate;
public void test(){
        transactionTemplate.execute(new TransactionCallbackWithoutResult() {
            
            @Override
            protected void doInTransactionWithoutResult(TransactionStatus status) {
                //进行事务相应的操作。。。
                //方法一...
                //方法二...
            }
        });
    }</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003739293";}i:3;a:11:{s:5:"title";s:55:"Lumen如何实现类Laravel5用户友好的错误页面";s:4:"link";s:42:"http://segmentfault.com/a/1190000003738977";s:2:"id";s:42:"http://segmentfault.com/a/1190000003738977";s:7:"updated";s:25:"2015-09-12T12:38:04+08:00";s:9:"published";s:25:"2015-09-12T12:38:04+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:15:"一堆好人卡";s:10:"author_uri";s:35:"http://segmentfault.com/u/silentred";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:3523:"
<blockquote><p>Laravel5实现用户友好的错误页面非常简单，例如想要返回status 404，只需要在<code>view/errors</code>中添加一个<code>404.blade.php</code>文件即可。Lumen中没有默认实现这种便利，于是自己添加一个。</p></blockquote>
<h1>Lumen如何实现类Laravel5用户友好的错误页面</h1>
<h2>原理</h2>
<p>抛出错误的函数是<code>abort()</code>, 进入该函数一看究竟，会发现只是抛出一个<code>HttpException</code>. 在Application中，处理http request的时候，有一个try catch的过程，Exception就是在这里被捕获的。</p>
<pre><code class="php">try {
    return $this-&gt;sendThroughPipeline($this-&gt;middleware, function () use ($method, $pathInfo) {
        if (isset($this-&gt;routes[$method.$pathInfo])) {
            return $this-&gt;handleFoundRoute([true, $this-&gt;routes[$method.$pathInfo]['action'], []]);
        }

        return $this-&gt;handleDispatcherResponse(
            $this-&gt;createDispatcher()-&gt;dispatch($method, $pathInfo)
        );
    });
} catch (Exception $e) {
    return $this-&gt;sendExceptionToHandler($e);
}</code></pre>
<p>接着可以看出，Exception是交给了<code>sendExceptionToHandler</code>去处理了。这里的handler具体是哪个类呢？是实现了<code>Illuminate\Contracts\Debug\ExceptionHandler</code>的一个单例。为啥说他是单例？因为在bootstrap的时候，已经初始化为单例了，请看。</p>
<pre><code class="php">$app-&gt;singleton(
    Illuminate\Contracts\Debug\ExceptionHandler::class,
    App\Exceptions\Handler::class
);</code></pre>
<p>进入该类看一下，他有一个<code>render</code>方法，好吧，找到问题所在了，修改一下这个方法即可。</p>
<pre><code class="php">public function render($request, Exception $e)
{
    return parent::render($request, $e);
}</code></pre>
<h2>动手修改</h2>
<p>由于Laravel已经有实现了，所以最简便的方法就是复制黏贴。在<code>render</code>中先判断下是否为<code>HttpException</code>, 如果是，就去<code>errors</code>目录下找对应status code的view，如果找到，就渲染它输出。就这么简单。修改<code>Handler</code>如下：</p>
<pre><code class="php">/**
 * Render an exception into an HTTP response.
 *
 * @param  \Illuminate\Http\Request  $request
 * @param  \Exception  $e
 * @return \Illuminate\Http\Response
 */
public function render($request, Exception $e)
{
    if( !env('APP_DEBUG') and $this-&gt;isHttpException($e)) {
        return $this-&gt;renderHttpException($e);
    }
    return parent::render($request, $e);
}

/**
 * Render the given HttpException.
 *
 * @param  \Symfony\Component\HttpKernel\Exception\HttpException  $e
 * @return \Symfony\Component\HttpFoundation\Response
 */
protected function renderHttpException(HttpException $e)
{
    $status = $e-&gt;getStatusCode();

    if (view()-&gt;exists("errors.{$status}"))
    {
        return response(view("errors.{$status}", []), $status);
    }
    else
    {
        return (new SymfonyExceptionHandler(env('APP_DEBUG', false)))-&gt;createResponse($e);
    }
}

/**
 * Determine if the given exception is an HTTP exception.
 *
 * @param  \Exception  $e
 * @return bool
 */
protected function isHttpException(Exception $e)
{
    return $e instanceof HttpException;
}</code></pre>
<p>好了，在<code>errors</code>目录下新建一个<code>404.blade.php</code>文件，在controller中尝试 <code>abort(404)</code>看一下吧。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003738977";}i:4;a:11:{s:5:"title";s:24:"js 你不知道的 Array";s:4:"link";s:42:"http://segmentfault.com/a/1190000003738483";s:2:"id";s:42:"http://segmentfault.com/a/1190000003738483";s:7:"updated";s:25:"2015-09-12T08:55:58+08:00";s:9:"published";s:25:"2015-09-12T08:55:58+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"honger05";s:10:"author_uri";s:34:"http://segmentfault.com/u/honger05";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:6556:"
<h2>一、在类数组对象上复用通用的数组方法</h2>
<p>类数组有：<code>arguments, NodeList, 字符串</code></p>
<p>什么是类数组？ 两个条件</p>
<ol>
<li><p>具有 length 属性</p></li>
<li><p>length 属性大于该对象的最大索引</p></li>
</ol>
<p>比如：</p>
<pre><code class="js">  var arrayLike = { 0: "a", 1: "b", 2: "c", length: 3};
  var result = Array.prototype.map.call(arrayLike, function(s) {
    return s.toUpperCase();
  });//["A", "B", "C"]</code></pre>
<p>几乎所有的数组方法都是通用的（forEach，slice，map ...） 除了 concat。</p>
<p>因为 concat 在连接时，会检查其参数的 [[Class]] 属性。</p>
<blockquote><p>一些方法，比如 join，仅仅读取他们被调用的对象的长度和数值属性。 另外，像 reverse 一样，要求对象的数值属性和长度属性是可变的；因此，这些方法不能在像 String 这样的对象上被调用，String不允许它的长度属性和synthesized的数值属性被设置。</p></blockquote>
<pre><code class="js">  function namesColumn() {
    return ['Names'].concat(arguments);
  }
  namesColumn("alice", "arale");//["Names", {0: "alice", 1: "arale"}]

  //解决办法：应先使用 slice 将 arguments 转为数组
  function namesColumn() {
    return ['Names'].concat([].slice.call(arguments));
  }</code></pre>
<hr>
<h2>二、数组优先使用 for 循环，而不是 for in 循环。</h2>
<p>for in 更多的是用于 遍历对象，但是 它也会去检查 对象的原型。</p>
<p>如果浏览器支持 for of （ES6）的话，最好是使用它，它不会去遍历原型。</p>
<hr>
<h2>三、迭代优于循环</h2>
<p>一个原因是，迭代可以消除没必要的 <code>终止条件</code> 和 <code>任何数组索引</code></p>
<p>比如：</p>
<pre><code class="javascript">  for (var i = 0; n = players.length; i &lt; n; i++) {
    players[i].score++;
  }

  //使用迭代
  players.forEach(function(p){
    p.score++;
  });</code></pre>
<p>例1： 对数组每一个元素操作后生成一个新的数组</p>
<pre><code class="js">  //获得所有输入框去除多余空格后的值
  var trimmed = input.map(function(s) {
    return s.trim()
  })</code></pre>
<p>例2： 获取价格在特定区间的列表</p>
<pre><code class="js">  listings.filter(function(listing) {
    return listing.price &gt;= min &amp;&amp; listing.price &lt;= max
  })</code></pre>
<p>当然这都是 ES5 的方法，我们也可以自己写一个。</p>
<pre><code class="js">  function takeWhile(a, pred) {
    var result = []
    for (var i = 0; n = a.length; i &lt; n; i++) {
      if (!pred(a[i], i)) {
       break
      }
      result[i] = a[i]
    }
    return result
  }

  var prefix = takeWhile([1, 2, 4, 8, 16, 32], function(n) {
    return n &lt; 10
  }) // [1, 2, 4, 8]</code></pre>
<p>把它加在 Array 上</p>
<pre><code class="js">  Array.prototype.takeWhile = function(pred) {
    var result = []
    for (var i = 0; n = this.length; i &lt; n; i++) {
      if (!pred(this[i], i)) {
        break
      }
      result[i] = this[i]
    }
    return result
  }

  [1, 2, 4, 8, 16, 32].takeWhile(function(n) {
    return n &lt; 10
  }) // [1, 2, 4, 8]</code></pre>
<p>循环仅一点优于迭代： 控制流操作 如 break 和 continue</p>
<p>ES5 中 只有 some 和 every 可以提前终止循环, 但设计他们的本意不是用来提前终止循环。</p>
<pre><code class="javascript">// some 一旦回调产生了一个真值，则立即返回，不会执行其余的元素
[1, 10, 100].some(function(x) { return x &gt; 5 }) //true
[1, 10, 100].some(function(x) { return x &lt; 0 }) //false
// every 相反, 一旦产生假值，则立即返回，不会执行其余元素
[1, 2, 3, 4, 5].every(function(x) { return x &gt; 0 }) //true
[1, 2, 3, 4, 5].every(function(x) { return x &lt; 3 }) //false</code></pre>
<p>这种行为可以用来实现 forEach 提前终止循环的变种时派上用场</p>
<pre><code class="js">  function takeWhile(a, pred) {
    var result = [];
    a.every(function(x, i) {
      if (!pred(x)) {
        return false //break
      }
      result[i] = x;
      return true; //continue
    })
    return result
  }</code></pre>
<hr>
<h2>四、数组方法分类</h2>
<h5>1. Mutator 方法</h5>
<blockquote><p>这些方法可以改变数组自身</p></blockquote>
<ul>
<li><p>pop : 移除数组的最后一个元素，返回值是被删除的元素。</p></li>
<li><p>push : 在数组的末尾添加一个或者多个元素，返回值是新的数组的长度。</p></li>
<li><p>reverse : 颠倒数组中元素的顺序，原先第一个元素现在变成最后一个，同样原先的最后一个元素变成了现在的第一个，也就是数组的索引发生了变化。</p></li>
<li><p>shift : 删除数组的第一个元素，返回值是删除的元素</p></li>
<li><p>sort : 对数组中的元素进行排序</p></li>
<li><p>splice : 添加或删除数组中的一个或多个元素。</p></li>
<li><p>unshift : （将废弃）添加一个或者多个元素在数组的开头，返回值是新的数组的长度。</p></li>
</ul>
<hr>
<h5>2. Accessor 方法</h5>
<blockquote><p>这些方法不改变数组自身</p></blockquote>
<ul>
<li><p>concat : 返回一个包含此数组和其他数组和/或值的结合的新数组</p></li>
<li><p>indexOf : 返回第一个与给定参数相等的数组元素的索引，没有找到则返回-1</p></li>
<li><p>join : 将所有的数组元素连接成一个字符串</p></li>
<li><p>lastIndexOf : 返回在数组中搜索到的与给定参数相等的元素的最后（最大）索引</p></li>
<li><p>slice : 返回数组中的一段。</p></li>
<li><p>toString : 返回代表该数组及其元素的字符,重写Object.toString 过程.</p></li>
<li><p>valueOf : 重写Object.valueOf过程。</p></li>
</ul>
<hr>
<h5>3. 循环（迭代） 方法</h5>
<ul>
<li><p>filter : 对数组中的每一个元素调用参数中指定的过滤函数，并将对于过滤函数返回值为true的那些数组元素集合为新的数组返回。</p></li>
<li><p>forEach : 对数组的每一个元素依次调用参数中指定的函数。</p></li>
<li><p>every : 如果数组中每一个元素都满足参数中提供的测试函数，则返回真</p></li>
<li><p>map : 创建一个新数组，新数组中含有，分别对于原来数组的每一个元素调用一个给定函数的结果</p></li>
<li><p>some : 如果数组中至少有一个元素满足参数函数的测试，则返回true。</p></li>
</ul>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003738483";}i:5;a:11:{s:5:"title";s:51:"整理一些质量不错的教程、博客、论坛";s:4:"link";s:42:"http://segmentfault.com/a/1190000003737649";s:2:"id";s:42:"http://segmentfault.com/a/1190000003737649";s:7:"updated";s:25:"2015-09-11T21:02:02+08:00";s:9:"published";s:25:"2015-09-11T21:02:02+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"xumenger";s:10:"author_uri";s:34:"http://segmentfault.com/u/xumenger";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:7335:"
<p>欢迎大家也来推荐好的资源！！！！</p>
<blockquote><p>送自己一句话：你可能不愿意与人分享自己所知道的，你可能以为“教会徒弟能饿死师父”，但我告诉你，你的保守会让你失去更多更好的东西，请你相信我，我绝不是在这里耸人听闻。</p></blockquote>
<h2>为什么整理这篇文章</h2>
<p>想通过在网络上随便搜索出来的文章学习其实是很不明智的，往往不能保证知识的质量、全面性和系统性。甚至是粗制滥造、造假的所谓知识！</p>
<p>用Google，不用Baidu。可是虽然<a href="https://www.google.com">Google</a>搜出来的比Baidu好，但是也还是不能确保质量都是没问题的。所以还是请自己去认真筛选！</p>
<p>虽然好的论坛上的信息比一般的论坛更靠谱，但是你也不能保证在<a href="http://stackoverflow.com">StackOverFlow</a>上回到你问题的那个人就是高手、给的答案就是准确无误的。所以本文虽然整理出了一些论坛，但是在使用的时候还是不能轻信，还是要自己去认真的考证！我觉得论坛最大的作用不是学习系统化的知识(<code>系统地、深入地学习知识是一件很严肃的事</code>)，而主要是用来是交流信息，给你提供一些思路和启发，当然一些具体的技巧的学习也是可以的。</p>
<p>所以请<code>怀疑一切</code>。</p>
<h2>怎么保证知识的质量</h2>
<p>当然首先是看书，去找那些公认的权威的书籍！好的书能让人受益良多，而且好书的知识比较能够保证质量和系统性，也会有一些有意义的思考。好书看得再多也不为过！好书对待知识都是严肃、认真的！不会误导你！</p>
<p>在网络上找教材也可以，但是这时候就需要你去仔细甄别，确保你将准备花时间学习的东西的质量是没有问题的，否则你将走偏，最可怕的是你可能要花双倍甚至十倍的时间扭转这些垃圾信息带给你的知识上的、思想上的误导。</p>
<p>下面我想整理一些不错的资源，方便自己的学习和讨论。</p>
<blockquote><p>真实的情况是你无法决定环境，而一定是环境最终改造了你，但是至少我们还能做这样一件事：选择呆在一个好的环境里！</p></blockquote>
<p>活到老，学到老。以下是摘自<a href="http://coolshell.cn/articles/222.html">CoolShell</a>的一段话：就算是你有了10年以上的程序员经历，你也得要使劲地学习，因为你在计算机这个充满一创造力的领域，每天都会有很多很多的新事物出现。你需要跟上时代的步伐。你需要去了解新的程序语言，以及了解正在发展中的程序语言，以及一些编程框架。还需要去阅读一些业内的新闻，并到一些热门的社区去参与在线的讨论，这样你才能明白和了解整个软件开发的趋势。</p>
<h2>实践是检验真理的唯一标准</h2>
<p><a href="https://github.com">Github</a>上有足够多的高质量的开源项目。重点是自己开发并托管到Github。</p>
<p>这里是<a href="http://segmentfault.com/a/1190000003713616">我整理的一些资源</a>。</p>
<p>这里是我整理的<a href="http://segmentfault.com/a/1190000003728094">关于git、github使用的方便快速查看的笔记</a>。</p>
<h2>好书读的再多也不为过</h2>
<p><a href="http://www.douban.com/">豆瓣</a>上自己找。</p>
<p>不要只读技术书，请各个领域的书都读些。</p>
<p>书去当当或亚马逊买，多说一点：不知道为什么最近在当当买的两本书有点像盗版。</p>
<h2>别人整理的好的资源</h2>
<ul>
<li><p><a href="http://www.jianshu.com/p/9c02dade7e90">Python 零基础入门资料整理</a></p></li>
<li><p><a href="http://segmentfault.com/a/1190000002706247">Python初学者的资源总结</a></p></li>
</ul>
<h2>博客</h2>
<ul>
<li><p><a href="http://coolshell.cn/">陈皓coolshell</a></p></li>
<li><p><a href="http://www.ruanyifeng.com/home.html">阮一峰的博客</a></p></li>
<li><p><a href="http://www.cnblogs.com/v-July-v/">July | 算法与数据结构</a></p></li>
<li><p><a href="http://blog.codingnow.com/">云风的blog</a></p></li>
<li><p>陈硕(muduo的作者)<a href="http://blog.csdn.net/Solstice">在CSDN的博客</a></p></li>
<li><p>陈硕在<a href="http://www.cnblogs.com/solstice">博客园的博客</a></p></li>
<li><p><a href="http://blog.csdn.net/myan/">孟岩</a></p></li>
<li><p><a href="http://www.laruence.com/">风雪之隅</a>：PHP、Zend</p></li>
<li><p><a href="http://www.cnblogs.com/vamei/tag/%E7%B3%BB%E5%88%97%E7%B4%A2%E5%BC%95/">Vamei</a>：Python、Java……</p></li>
<li><p><a href="http://www.phpgao.com/">老高</a>：PHP、ThinkPHP、Typecho、Python</p></li>
<li><p><a href="http://mindhacks.cn/">刘未鹏</a>：思维改变生活</p></li>
<li><p><a href="http://www.trinea.cn/">Trinea</a>：Android源码解析、性能优化</p></li>
</ul>
<h2>教程</h2>
<p>首先说一下自己的个人观点，不推荐使用视频教程来学习，没有什么理性的理由，纯粹是感觉的问题。</p>
<ul>
<li><p><a href="http://www.liaoxuefeng.com/">廖雪峰的Python、Git、JS的教程</a></p></li>
<li><p><a href="http://www.walu.cc/phpbook/index.md">PHP扩展开发及内核应用</a></p></li>
<li><p><a href="http://www.cnblogs.com/del/">万一的 Delphi 博客</a></p></li>
<li><p><a href="http://vbird.dic.ksu.edu.tw/">鸟哥的Linux私房菜</a></p></li>
<li><p><a href="http://www.w3school.com.cn/index.html">w3school</a></p></li>
<li><p><a href="http://www.runoob.com/">菜鸟教程(原w3cschool)</a></p></li>
<li><p><a href="http://www.pythoner.cn/">Python学习平台</a></p></li>
</ul>
<h2>论坛&amp;技术问答</h2>
<ul>
<li><p><a href="http://stackexchange.com/">StackExchange</a></p></li>
<li><p><a href="http://stackoverflow.com/">StackOverFlow</a></p></li>
<li><p><a href="https://www.quora.com/">Quora</a></p></li>
<li><p><a href="http://www.zhihu.com/">知乎</a>，去杂七杂八的都看一些吧</p></li>
<li><p><a href="http://bbs.csdn.net/home">CSDN论坛</a></p></li>
<li><p><a href="http://ask.csdn.net/">CSDN技术问答</a></p></li>
<li><p><a href="http://python-china.org/">python中国</a></p></li>
<li><p><a href="https://ruby-china.org/">Ruby中国</a></p></li>
<li><p><a href="http://www.getyii.com/">Get Yii</a>打造国内最权威的 Yii 社区</p></li>
<li><p><a href="http://ionichina.com/">Ionichina</a>：全球最大的 Ionic Framework 中文社区</p></li>
<li><p><a href="https://cnodejs.org/">Node.js专业中文社区</a></p></li>
<li><p><a href="http://golangtc.com/">Golang中国</a></p></li>
<li><p><a href="http://elixir-cn.com/">ElixirChina</a></p></li>
<li><p><a href="http://www.ngnice.com/">AngularJS Nice Things</a></p></li>
<li><p><a href="http://www.swiftist.org/">Swift社区</a></p></li>
<li><p><a href="http://www.meteorhub.org/">Meteor 中文社区</a></p></li>
<li><p><a href="http://www.eoeandroid.com/forum.php">eoe</a>：Android、iOS</p></li>
</ul>
<h2>投资理财</h2>
<ul>
<li><p><a href="http://cn.morningstar.com/">晨星</a></p></li>
<li><p><a href="http://www.szse.cn/">深圳证券交易所</a></p></li>
<li><p><a href="http://www.sse.com.cn/">上海证券交易所</a></p></li>
</ul>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003737649";}i:6;a:11:{s:5:"title";s:33:"Python 版 APM 服务使用测试";s:4:"link";s:42:"http://segmentfault.com/a/1190000003737491";s:2:"id";s:42:"http://segmentfault.com/a/1190000003737491";s:7:"updated";s:25:"2015-09-11T20:13:21+08:00";s:9:"published";s:25:"2015-09-11T20:13:21+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:7:"Scholer";s:10:"author_uri";s:33:"http://segmentfault.com/u/scholer";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:14912:"
<h2>后端开发与云服务</h2>
<p>云服务这个词，大概最早是从云盘开始的，那时候概念也特别简单，无非就是把一些数据存在别人的服务器上，在”云存储”这个名词火起来之前，QQ 也有提供网站的功能用来存一些小东西（05年06年的样子，那时候大概只有几十 M 的空间），其实刚听到这个概念的时候我就很不理解，光存存东西不至于吹得这么玄乎吧。毕业后入行，云服务器才慢慢真真的丰富起来，从最开始的 VPS 变成云服务器、存储变成资源服务器、远程数据库等等，现在甚至有帮你防 DDOS 的服务（去年和今年貌似 DDOS 变得越来越没有节操了）。确实节省了很多精力，也省钱。</p>
<p>除了云，最近几年还有另外一个比较火的词："大数据”。我没接触过那么大的数据，作为一个半吊子运维，接触的最大的数据应该就是服务器 log 了。所以大数据的东西以后有机会接触再说，对我来说更重要的是 — <strong>数据统计</strong>。</p>
<p>服务端的各种 log 不仅是分析服务器的状态的重要参数，也是从后台代码里抓 bug 抓异常检查 SQL 性能等各种工作的参考。log 数据一般都是单调而且重复的居多，要发现它的价值，往往需要大量的分析和统计工作。各种监控服务、分析工具也是层出不穷。不过到今年我才知道有个词叫 "APM"。</p>
<p>APM (Application Performance Management/Monitoring) 简单翻译过来就是"应用性能管理/监控”(也许说监控更准确一些)。大概就是服务器上部署的 awstats、nagios、zabbix 等一堆东西的集合。有服务器的地方就有云，既然这个事情这么麻烦，那就自然也可以交给别人来做了。</p>
<p>前几天找到了一个 Python 的小 web 框架：<a href="http://bottlepy.org/">bottle</a>，只有一个文件，简洁好用，觉得很不错，先是用它来做了一个简单的小应用（APP 下载，公司内部使用），准备这段时间尝试用它来自己写一个简单的博客系统，改造一下自己的博客，所以业务时间花在搞 Python 上的比较多一点。恰好看到了在测 Python 版本的探针，于是部署来测试一下。部署之前先在本地做了一些测试，不过听云目前仅支持基于 django 开发的程序（文档上写的目标是支持所有以 wsgi 协议部署的 Python Web 服务，包括 flask、tornado 等等，不过这个应该还要等后续开发支持了），所以我就先在本地用 django 测了一下。</p>
<h2>听云探针(Python版)的使用</h2>
<p>探针部署过程十分简单，在听云后台复制自己账户的 license key，生成配置文件，将配置文件地址加载到环境变量中，就可以启动程序开始使用了。以下是测试环境部署步骤的介绍。</p>
<p>先用 virtualenv 开辟一个环境并 active 之：</p>
<pre><code class="sh">virtualenv tingyun
cd tingyun
source bin/active</code></pre>
<p>听云探针在 pypi 的仓库里有，所以可以直接安装了，同时也安装 django , 探针支持 MySQL 的 log 记录，所以我也安装了 MySQL 的组件并将 django 的数据库从 sqlite 改成 MySQL：</p>
<pre><code class="sh"># 安装组件
pip install tingyun django MySQL-python
# 创建一个 django 工程
django-admin startproject www</code></pre>
<p>接着需要修改一下 django 的数据库选项，进入到 www/www 目录，打开 settings.py，找到 DATABASE 的字典，注释掉原有的 sqlite 选项并改为 MySQL：</p>
<pre><code class="python"># 'default': {
#     'ENGINE': 'django.db.backends.sqlite3',
#     'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
# }
'default': {
    'ENGINE': 'django.db.backends.mysql',
    'NAME': 'django',
    'USER': 'root',
    'PASSWORD': '',
    'HOST': '',
    'PORT': '',
}</code></pre>
<p>在 MySQL 中创建 django 的库，然后安装 django 的 admin 后台需要的数据表（注意回到 manage.py 所在的目录）：</p>
<pre><code class="sh">python manage.py syncdb</code></pre>
<p>接下来设置听云的服务，按照听云后台的提示和文档说明进行就可以了：</p>
<pre><code class="sh"># YourLicenseKey 是你的听云后台里显示的 key
# 听云后台里将 tingyun.ini 放置在 tmp 目录，我建议你放在当前工作目录，免得丢失
# 一些配置参数可以打开 tingyun.ini 进行修改
tingyun-admin generate-config YourLicenseKey tingyun.ini
#
# 这里的 TING_YUN_CONFIG_FILE 写绝对路径比较保险，以下是我本地的目录
# 如果是在服务器上，可以写入到 .bashrc 或者 .bash_profile 中去，需要重启服务时不用重新设置
export TING_YUN_CONFIG_FILE=/Users/Scholer/Work/Personal/tingyun/tingyun.ini
#
# 听云的服务会读取当前环境变量的参数 TING_YUN_CONFIG_FILE 来获取配置文件
# 我们可以先检查一下，如果看到 success 字样就 OK
tingyun-admin check-config</code></pre>
<p>万事具备，可以启动服务了：</p>
<pre><code class="sh">tingyun-admin run-program python www/manage.py runserver</code></pre>
<p>接下来我们就可以浏览一下页面，登录一下后台等等生成一些访问记录来看看效果了（或者可以比较残暴一点用测试工具，我用 <a href="http://httpd.apache.org/docs/2.0/programs/ab.html">ab</a> 发了一些的测试请求）。</p>
<p>一切顺利的话，过一会儿刷新一下听云的后台，就能看到一些数据了。</p>
<p>有一些事情需要注意一下：</p>
<ol>
<li><p>听云的多个应用是同一个 key，通过应用名称来区分应用；</p></li>
<li><p>不同于一些其他服务、听云没有新建一个 应用的过程，有部署、上报的数据就能看到数据了；</p></li>
<li><p>如果使用 uwsgi 的方式不是，需要开启 <code>enable-threads</code> 和 <code>single-interpreter</code> 的选项。</p></li>
</ol>
<h2>上报数据观察</h2>
<p>登录到听云的后台管理面板就能查看到一些监控日志分析了（图表是用 highcharts 做的，体验相当不错）。</p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195506_sC9h.png" alt="输入图片说明" title="输入图片说明"></p>
<p>图中可以看到一些基本的数据图表，包括应用的响应时间、Apdex（应用程序性能指数），应用响应耗时和吞吐率等等。</p>
<p>此外面板上也会有硬件的基本信息，包括 CPU 的占用时间、内存占用等参数。</p>
<p>各项参数指标的统计最终目的都是为了分析服务器本身的承载能力和性能。当以上参数出现异常情况，比如响应时间过长、CPU负载过高或者内存剩余不多时，就要考虑升级硬件资源或者对程序进行优化了。</p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195532_TDpB.png" alt="输入图片说明" title="输入图片说明"></p>
<p>Apdex (Application Performance Index) ，应用性能指数。这是一个近几年成立的联盟组织，大概是在 2010 年发起的，12 年之后沉寂了两年，去年又开始活跃了。这个联盟意在通过一个统一的标准来计算和衡量应用程序的的性能，在它的 <a href="http://www.apdex.org">官网</a> 中有一些专门的文章来介绍自己。</p>
<p>"Apdex is a way to study measurements of any experience that can be interpreted on a scale ranging from excellent to unacceptable. "<br>（Apdex 用以学习解释从好到坏的评级标准的相关经验。）</p>
<p>Apdex 的计算在下面这篇文章用也有介绍：</p>
<pre><code>Apdex = (正常样本 + 0.5 x 低质样本 + 0 x 高质样本) / 样本总量
</code></pre>
<p>我们可以这样把正常样本理解成正常的时间，低质和高质就分别表示响应的慢和快。显然计算结果从 1 到 0 就表示从好到坏。</p>
<p>详细介绍：<a href="http://www.apdex.org/index.php/2014/05/apdex-is-not-just-for-application-performance/"></a><a href="http://www.apdex.org/index.php/2014/05/apdex-is-not-just-for-application-performance/">http://www.apdex.org/index.php/2014/05/apdex-is-not-just-for-application-performance/</a></p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195605_XUiq.png" alt="输入图片说明" title="输入图片说明"></p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195615_5tyy.png" alt="输入图片说明" title="输入图片说明"></p>
<p>以上两张统计图分别展示了应用层的处理时间与数据库调用时间。这两个参数是对程序和 SQL 语句进行优化的重要参考。这里应该是计算的平均时间。</p>
<p>在实际的分析过程中，我们也同样需要对于所有耗时过长的处理或者 SQL 慢查询进行分析和优化。听云也提供了对于耗时应用和 SQL 的统计。</p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195645_9KYw.png" alt="输入图片说明" title="输入图片说明"></p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195655_kuyM.png" alt="输入图片说明" title="输入图片说明"></p>
<p>在上面的"最耗时的应用过程"中，有一个<strong>墙钟时间比</strong>的概念。墙钟时间（Wall-clock time / wall time）指的是程序从开始执行到结束的过程中人的时间感知（这个时间是大于 CPU 时间的，由系统提供）。墙钟时间比就表示当前时间点下某个程序占总墙钟时间的百分比。</p>
<p>除了常见关系型数据库的监控，听云也提供了对 memcached、Redis、MongoDB 等非关系型数据库的监控和统计。</p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195705_SQAR.png" alt="输入图片说明" title="输入图片说明"></p>
<p>响应率和吞吐率参数参数。吞吐率指的是单位时间内响应的数量。这两个参数是对网站总体的响应速度和承载能力的评估。</p>
<p><img src="https://static.oschina.net/uploads/img/201509/06195718_gtD1.png" alt="输入图片说明" title="输入图片说明"></p>
<p>吞吐量、响应时间、Apdex和错误率的概览。</p>
<p>听云后台的参数记录十分全面，从硬件基础到程序响应到数据库执行耗时都有完整的分析和记录。不过遗憾的是在后台没有看到 HTTP 状态码的记录，类似 awstats 提供的记录和统计功能。不过相对于一个需要自己做复杂的配置的开源组件，优势还是十分明显的。我也相信随着时间的推移，服务会越来越丰富，这些信息都会被记录并分析出来。</p>
<h2>简析</h2>
<p>部署和数据分析都说了，现在也可以简单的来分析下听云是如何运作的。我无意去弄清楚探针工作的每一个步骤，但却可以了解一下大致的流程。</p>
<p>Python 作为一门胶水语言，已经积淀了丰富的优秀模块，历来都是被公认为作为服务端运维最强力的脚本语言，对于这类问题的处理上，具有天然的优势。听云在语言上也做了处理，能够同时支持 Python 2 和 Python 3。</p>
<p>在听云的配置文件 tingyun.ini 中，除了有 <code>license_key</code> 以外，还有 <code>app_name</code>、 <code>log_file</code> 、 <code>log_level</code> 等参数配置。其中 <code>action_tracer.log_sql</code> 可以选择是否将 SQL 日志只保存在本地文件中（这应该是出于安全考虑，毕竟把所有的 SQL 日志都暴漏给服务平台，有些人可能会有些顾虑。但是考虑到现在服务器一般都是云服务器，所以这其实问题也并不大，选择了服务，就应该相信服务），这点听云考虑的很周到。</p>
<p>log 文件中记录了一些 trace 的log，包括程序耗时等。</p>
<p>回到程序本身中去，在启动探针的时，我们执行的是 <code>tingyun run-program</code>，最终执行的是听云的 package 中 admin 目录下的  <code>run_program</code> 的函数，<code>check_config</code>、<code>generate_config</code> 也位于 admin 目录下。整个程序目录还包括 bootstrap 、hook 和 api 目录。</p>
<pre><code class="python">root_directory = os.path.dirname(root_directory)
boot_directory = os.path.join(root_directory, 'bootstrap')
python_path = boot_directory</code></pre>
<p><code>run_program</code> 将 bootstrap 目录加入系统 path 中。通过 Python 提供的两个 hook（sitecustomize 和 usercustomize 之中的 sitecustomize，听云探针正式被加载到运行环境中：</p>
<pre><code class="python">if config_file is not None:
    # When installed as an egg with buildout, the root directory for
    # packages is not listed in sys.path and scripts instead set it
    # after Python has started up. This will cause importing of
    # 'tingyun' module to fail.

    if root_directory not in sys.path:
        sys.path.insert(0, root_directory)

    import tingyun.agent

    # Finally initialize the agent.
    tingyun.agent.initialize(config_file=config_file)</code></pre>
<p>在 <code>tingyun.api.initial.config</code> 中，<code>initialize</code> 函数被执行，调用 <code>_process_module_builtin</code> 函数，探针开始工作 ：</p>
<pre><code class="python">_load_configuration(config_file=config_file)

if not _detect_done:
    _detect_done = True
    _process_module_builtin()</code></pre>
<p>MySQL、Redis 等监控模块都位于 hook 目录下，通过 <code>_process_module_definition_wrapper</code> 函数将进程与监控模块进行绑定，包括 django 的主要模块以及常用的数据库等。在核心模块执行的时候触发监控，将数据回传到 <code>api.tracert</code> 模块进行处理。</p>
<p>而对于硬件信息的检测则由 <code>api.platform.system_info</code> 进行。</p>
<p>应用监控数据最终会由 <code>api.tracert.uploader</code> 上传到听云的服务器（host 的设置位于 <code>api.settings</code> 中，host 地址是 <a href="http://redirect.networkbench.com">redirect.networkbench.com</a>，所以看到你的服务器往这个域名发送请求时，不要觉得奇怪），通过听云的处理，我们就能看到应用程序的各种监控数据了。</p>
<p>对听云探针的简单分析就到这里，有兴趣的读者可以进一步深入研究。其实对于这类云服务，程序的本身都是透明的，不用有太大的安全顾虑，对于服务提供方而言，更重要的是数据的分析工作。</p>
<p>听云本身提供的服务器是非常优秀的，虽然目前还并非完美。我也期待服务能更加完善，提供更完善的数据分析。另外一方面，通过 <code>tingyun-admin run-program</code> 的方式启动程序，对开发者和服务器管理员来说可能有些侵入感。如果能用模块加载的方式调用，或许更符合某些开发者的习惯。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003737491";}i:7;a:11:{s:5:"title";s:47:"JS语言精粹--函数篇之this与调用模式";s:4:"link";s:42:"http://segmentfault.com/a/1190000003737348";s:2:"id";s:42:"http://segmentfault.com/a/1190000003737348";s:7:"updated";s:25:"2015-09-11T19:18:48+08:00";s:9:"published";s:25:"2015-09-11T19:18:48+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:10:"羅聲門X";s:10:"author_uri";s:35:"http://segmentfault.com/u/tony2lord";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:10341:"
<blockquote><p>久违的博文，貌似距离我上一篇也算是有些年岁（加班的日子真是度日如年啊T^T）了，所以呢，现在是时候回归正道了，还是欢迎各位IT道友多多交（tu）流（cao）哈！</p></blockquote>
<h2>正文</h2>
<p>首先，说到 JavaScript 函数，我们就要先理解下一些很可能被忽视的小概念：<code>函数对象</code> 和 <code>函数字面量</code>。</p>
<h3>函数对象</h3>
<p>我们知道，在JavaScript中 <strong>函数</strong> 就是 <strong>对象</strong>。对象是“名/值”的集合，并拥有一个连到原型对象的隐藏连接。其中，对象字面量产生的对象连接到 <code>Object.prototype</code>，而函数对象连接到 <code>Function.prototype</code> （注：该原型对象本身连接到 <strong><em> Object.prototype </em></strong>）。每个函数在创建时，都附有两个附加的隐藏属性：<strong> 函数的上下文 </strong> 和 <strong> 实现函数行为的代码 </strong>。</p>
<p>另外，每个函数对象在创建时，也随带有一个 <code>prototype</code> 属性，他的值是一个拥有 <code>constructor</code> 属性，而且其值即为该函数的对象。这和隐藏连接到 <strong>Function.prototype</strong> 完全不同，而这个令人费解的构造过程的意义，我先埋个坑，以后在继承篇的相关文章中再来填好了。</p>
<p>因为函数是对象，所以它可以像其他值一样被使用，比如，可以存放在变量、对象和数组中，可以被当做参数传递给其他函数，也可以在函数中返回函数，而且，更因为函数是对象，因此 <strong>函数也可以拥有方法</strong>。</p>
<h3>函数字面量</h3>
<p>函数对象可以通过函数字面量来创建：</p>
<pre><code>var add = function (a, b) {
    return a + b;
}</code></pre>
<p>函数字面量包括四个部分：</p>
<p>第一部分，是 <strong>保留字</strong> <code>function</code>。</p>
<p>第二部分，是 <strong>函数名</strong>，它可以省略不写。函数可以用它的名字来 <strong>递归</strong> 地调用自己。此名字也能被调试器和开发工具来识别函数（如：<strong>FireBug</strong>、<strong>Chrome console</strong> 等）。如果没有给函数命名，比如上面的例子，它会认为是 <code>匿名函数</code>。</p>
<p>第三部分，是包围在圆括号中的一组 <strong>参数</strong>，其中每个参数之间用逗号隔开，这些参数（也称<code>形式参数</code>，即<strong>形参</strong>）将被定义为函数中的变量，但是，<strong>它们不像普通变量那样被初始化为</strong> <code>undefined</code>，<strong>而是在该函数被调用时初始化为实际提供的参数的值</strong>（也称<code>实际参数</code>，即<strong>实参</strong>）。</p>
<p>第四部分，是包围在花括号中的一组语句，这些语句就是 <strong>函数主体</strong>，它们在函数被调用时执行。</p>
<p>函数字面量可以出现在任何允许表达式出现的地方。当然，函数也可以嵌套在其他函数中，这样的话，一个内部函数不仅可以访问自己的参数和变量，同时也可以方便地访问它被嵌套的那个外部函数的参数和变量。</p>
<p>通过函数字面量创建的函数对象包含一个连到外部上下文的连接，这被称为 <code>闭包</code>。<strong>它是 JavaScript 强大表现力的根基</strong>。而关于闭包的详细原理和使用方法，以后会发布一些专门的文章进行说明，敬请期待 ( ^_^ ) ~~</p>
<hr>
<blockquote><p>荤割线之后，接下来就是本文的重头戏 -- 关键字 <code>this</code> 上场。众所周知，这个老（son）伙（of）计（bit ch）可以说是JavaScript中的一大深坑，至于如何华丽丽地跳出这个坑，还请各位搬好板凳，备好瓜子，听我慢慢道来。</p></blockquote>
<h3>调用</h3>
<p>当我们调用一个函数时，将暂停当前函数的执行，将传递控制器与参数给新函数。然而，除了声明时定义的形参，每个函数接收两个附加的参数：<code>this</code> 和 <code>arguments</code>。参数 this 在面向对象编程中是非常重要的，它的值取决于调用的模式。在JavaScript中有四种调用模式：<code>方法调用模式</code>、<code>函数调用模式</code>、<code>构造器调用模式</code>和<code>apply调用模式</code>。</p>
<p><strong>调用运算符</strong>，就是跟在任何一个函数值的表达式之后的一对圆括号，它可以包含零个或者多个用逗号隔开的表达式，每个表达式产生一个参数值，每个参数值被赋予函数声明时定义的形式参数名，而当<strong>实际参数（arguments）</strong>的个数与<strong>形式参数（parameters）</strong>的个数不匹配时，不会导致运行时报错。比如说，如果实参值过多，超出的参数值将被忽略，如果实参值过少，缺失的值将会被替换为 <strong>undefined</strong>。并且，对参数值不会进行类型检查，即任何类型的值都可以被传递给参数。</p>
<h4>方法调用模式</h4>
<p>当一个函数被保存为对象的一个属性时，我们称之为<code>方法</code>。当一个方法被调用时，<strong>this</strong> 会被绑定到该对象，即<strong>this就是该对象</strong>。如果一个调用表达式包含一个属性存取表达式（即一个 <strong>. 点表达式</strong> 或者 <strong>[subscript] 下标表达式</strong>），那么它将被当做一个方法来调用。</p>
<pre><code>// 创建 myObject。它有一个 value 属性 和一个 increment 方法
// increment 方法接收一个可选的参数，若参数不是数字型，则默认使用数字 1。
var myObject = {
    value: 0,
    increment: function (inc) {
        this.value += typeof inc === 'number' ? inc : 1;
    }
};
// 不传参
myObject.increment();  
console.log(myObject.value);  // 1

// 传非数字型
myObject.increment('a');  
console.log(myObject.value);  // 2 

// 传数字型
myObject.increment(2);  
console.log(myObject.value);  // 4 
</code></pre>
<p>方法可以使用 this 去访问对象，所以它能从对象中取值或者修改该对象。this 到对象的绑定，发生在调用的时候。这个<strong>“超级”迟绑定（very late binding）</strong>使得函数可以对 this 高度复用。通过 this 可取得它们所属对象的上下文的方法，称为<code>公共方法</code>。</p>
<h4>函数调用模式</h4>
<p>当一个函数并非一个对象的属性（即<strong>方法</strong>）时，那么它将被当做一个函数来调用。</p>
<pre><code>function add (a, b) {
    return a + b;
}

var sum = add(3,4);
console.log(sum);  // 7
</code></pre>
<p>当函数以此模式调用时，this 被绑定到全局对象（即 <strong>window 对象</strong>），这是语言设计上的一个重大的错误啊！！如果设计正确的话，当内部函数被调用时，this 应该仍然绑定到外部函数的 this 变量才对。这个错误设计的后果是，方法不能利用内部函数来帮助他工作，因为内部函数的 this 被绑定了错误的值，或者说绑定了我们不想要的值，所以不能共享该方法对于对象的访问权。不过，幸运的是，有一个很容易的解决方案：如果该方法定义一个变量并给它赋值为this，那么内部函数就可以通过那个变量访问到 this，而这个变量我们通常命名为 <strong>that</strong>。</p>
<pre><code>function add (a, b) {
    return a + b;
}

// 给 myObject 增加一个double方法
myObject.double = function () {
    var that = this;
    console.log(that);

    var helper = function () {
        that.value = add(that.value, that.value);
    };

    // 以函数的形式调用 helper
    helper();  
};

// 以方法的形式调用 double
myObject.double();  
console.log(myObject.getValue());  // 8
</code></pre>
<h4>构造器调用模式</h4>
<p>JavaScript 是一门基于<strong>原型</strong>继承的语言，这就意味着对象可以直接从其它对象继承属性或方法，而该语言也是无类别的。</p>
<p>如果在一个函数前面加上一个 <strong>new</strong> 来调用，那么将会创建一个隐藏连接到该函数的 prototype 成员的新对象（或者称之为该对象的<strong>实例</strong>），同时，this 将会被绑定到那个新对象（实例）上。</p>
<p>然而，new 前缀也会改变 return 语句的行为，这个我们以后再做详细解析。</p>
<pre><code>Quo.prototype.get_status = function () {
    return this.status;
};

// 构造一个 Quo 的实例
var myQuo = new Quo('success');
console.log(myQuo.get_status());  // success  
</code></pre>
<p>目标就是结合 new 前缀来调用的函数，被称为<code>构造函数</code>。按照约定，它们保存在以首字母大写命名的变量里。如果调用构造函数时，没有在前面加上 new，可能会发生非常糟糕的事情（如，实例无法调用该原型对象的方法，等），这样既没有编译时警告，也没有运行时警告，所以<strong>加 new 前缀和大写约定，是非常、非常、非常重要的</strong>（重要话，说三遍）。</p>
<p>然并卵，实际使用中，我们并不推荐这种形式的构造器函数，以后将在JavaScript的继承篇为各位提供更好的解决方案。</p>
<h4>Apply 调用模式</h4>
<p>因为 JavaScript 是一门函数式的面向对象的编程语言，所以<strong>函数可以拥有方法</strong>。</p>
<p>apply 方法让我们构建一个参数数组并用其去调用函数，它也允许我们选择 this 的取值。apply 方法接收两个参数，第一个是将被绑定给 this 的值，第二个就是一个参数数组。</p>
<pre><code>// 1.构造一个带有两个数字的数组，将之相加
var arr = [3, 4];
var sum = add.apply(null, arr);  

console.log(sum);  // 7

// 2.构造一个含有 status 成员的对象
var statusObj = {
    status: 'right'
};

var status = Quo.prototype.get_status.apply(statusObj);  
console.log(status);  // right
</code></pre>
<p>这里第二个例子的代码，通过了 apply 方法替换 Quo 对象中的 this 指针。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003737348";}i:8;a:11:{s:5:"title";s:47:"企业运营对 DevOps 的「傲慢与偏见」";s:4:"link";s:42:"http://segmentfault.com/a/1190000003737192";s:2:"id";s:42:"http://segmentfault.com/a/1190000003737192";s:7:"updated";s:25:"2015-09-11T18:31:19+08:00";s:9:"published";s:25:"2015-09-11T18:31:19+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:18:"OneAPM蓝海讯通";s:10:"author_uri";s:41:"http://segmentfault.com/u/oneapm_official";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:13831:"
<p><strong>摘要：出于各种原因，并非所有人都信任 DevOps 。有些人觉得 DevOps 只不过给开发者改善产品提供了一个途径而已，还有的人觉得 DevOps 是一堆悦耳的空头支票，甚至有人认为 DevOps 根本无法采用。</strong></p>
<blockquote><p>【编者按】近日，Alex Honor 在 Dev2ops 上撰文阐述了当下企业对 DevOps 所存在的偏见，并就造成这些问题的原因分享了企业该如何向 DevOps 模式切换，本文系 <a href="http://www.oneapm.com/index.html?utm_source=Community&amp;utm_medium=Article&amp;utm_term=prejudice&amp;utm_campaign=SeptArti&amp;from=matefisppr">OneAPM</a> 工程师编译整理。</p></blockquote>
<p>笔者曾帮助多家大型企业深入了解 DevOps，帮助他们理解如何改善服务交付能力。这些公司大多听说过 DevOps，也在四处寻求一个策略来采用 DevOps 方法，从而进一步占领市场，提升产品质量。出于各种原因，并非所有人都信任 DevOps。有些人觉得 DevOps 只不过给开发者改善产品提供了一个途径而已，还有的人觉得 DevOps 是一堆悦耳的空头支票，甚至有人认为 DevOps 根本无法采用，因为其所在领域所必须的自动化工具根本不存在。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/DevOpsEntOpsObjects-350x337.jpg" alt="企业对 DevOps 的偏见，及几个转型建议" title="企业对 DevOps 的偏见，及几个转型建议"></p>
<p>通常在企业里，运维通常由一个集中且独立的团队完成，同时他们需要支撑多个应用程序组。如果网站的可用性出问题，责任就落在运维团队身上。一旦出现性能问题、宕机或故障，运维团队无疑是第一道防线，但有时问题升级会返回到应用组去修复 bug 或者帮助诊断问题。</p>
<p>对 DevOps 感兴趣的企业往往实践或采用了一个对运维需求非常搞的敏捷技术，比如建立一个测试环境，或者测试节后发布软件到生产环境。持续加快的步伐给运维团队施加了很大的压力，因为大多时候工作集中在项目后期（例如，是时候发布到生产环境中）。迫于时间压力或者过量工作，运营团队很难完成相对请求，甚至有时听到开发者埋怨想亲力亲为。那些用户可能想重建服务器、获取 Shell 访问、安装软件、运行命令和脚本、设置虚拟机、修改网络 ACL 和更新负载平衡器等。他们认为有些事情还不如自己来做，从而不再需要高度集中的运维小组。</p>
<p>如何让运维团队，一直负责生产环境运行时的部门能扩展其支持的环境？他们应该如何避免成为各应用团队项目周期尾端的瓶颈？如何让业务更加稳定可靠，而不是混乱、中断或不按预期执行？</p>
<p>如果你身处这种企业环境，又该如何进入 DevOps？如果你身处高度集中的运营团队，又该解决采用 DevOps 的压力，这里有几个问题需要企业团队谨慎考虑，问题的答案则是一步步形成 DevOps 战略的重要步骤。</p>
<blockquote><p>那么，一个高度集中的运营团队如何处理必要任务，使得应用程序可以在生产环境或其他环境下顺利运行？</p></blockquote>
<p>在有些企业中，初期会创建一个名为「Devops」的专业团队来解决各种「Devops 问题」，这便是良好运营的开端。这个团队可能会负责接手开发团队的应用程序，使用自动化工具进行打包，进行部署并将其转交给 Site Reliability 团队。不幸的是，集中式的 Devops 团队也可能变成「silo」 ，也要不断接受传统运维组所面临的「项目末期」交接挑战。同时，随着更多的开发者和开发项目涌入，Devops 工程师和 Devops 团队再次成为瓶颈。集中的 Devops 团队和传统的 QA 部门一样，当他们尝试「添加质量检测」作为一个独立过程阶段时，也不得不面临同样的压力。</p>
<p>为了确保应用程序可以在生产环境以及其他环境下正常运行，Devops 重点必须嵌入应用体系结构。这就意味着，让应用程序易于配置、部署和监控均在开发阶段完成。集中的运维团队必须学会开发一个共享式软件交付流程和工具链。在交付工具链内部，任务可以分布在多个团队。集中的运维组可以支持工具链，正如架构师和服务提供者提供给应用开发团队一个基础框架，而在填充所需的构件就可以驱动这个管道。</p>
<blockquote><p>什么是合规策略（compliance policies）？</p></blockquote>
<p>大多数企业都遵循一个修改策略，即预先指定谁可以在生产过程中做出修改。很多时候，这一策略常常被理解为除了运维组以外，其他人都不能发布更新。这种切换可能导致交付时间拖延，同时如果在传递过程中丢失信息，甚至可能导致故障发生。</p>
<p>这些规则都是由企业制定的，但事实上，在交付端的职员从未去认真地去理解这些政策的语义，他们通常根据想象或者习惯去判断。而随着时间推移，工具和流程往往发酵成无效率的官僚机构。</p>
<p>基于应用或客户类型，通常会形成不同的限制规则。当涉及到如何缩短交付周期时，这些差异应该纳入考虑，因为它能帮助你发现究竟谁可以做出更改，以及修改该如何进行。</p>
<p>除了主动理解规则，规则同样需要做到快速和便捷地审校：</p>
<p>简单易懂的规则能清晰展现以下内容：</p>
<ul>
<li><p>谁做出了变动以及是否有权限</p></li>
<li><p>改变应用在哪里</p></li>
<li><p>具体的改变内容，这些调整是否能接受</p></li>
</ul>
<p>这种查询应该能即时访问，而不是在某个事情后（比如故障发生）通过人工收集得到。当你拿到服务器过去24小时的工作报告时，便能轻而易举了解到环境中发生了哪些变化。</p>
<p>这些审计视图应该包含基础设施和工件信息，因为不管是开发者还是运维人员都想清楚软件和服务器的信息，一堆不明所以的修改信息和错误链接报告无论如何也无法组成一张全景图。</p>
<blockquote><p>如何开放访问又不会失去控制？</p></blockquote>
<p>通过审视软件交付的整个过程工作流全时监控将变得简单，在以往这个工作通常由一个独立的团队完成，他们往往以往竞争优先级导致的上下文切换而变得没有效率，这种情况通常在运维团队发生。运维团队需要平衡来源于应用开发团队的工作（例如，参与敏捷开发冲刺）、网络操作（例如，处理中断和生产问题）、企业用户（例如，收集信息用于控制策略）。最后，运维还需负责维护或改善基础设施等项目工作。</p>
<p>为了释放这个流程的瓶颈，企业必须发掘应该如何重新分配工作，或者建立一个自服务流程。因为部署、配置和监控都是需要设计到应用中的运维问题，一次需要将之一定程度地传递给开发人员。聚焦这一系列动作，运维团队需要维护一组基本的自动化模块，给开发人员相应方法来参与。创建一个开发环境和工具允许开发人员在自己的沙箱中将所需的改变整合到这个框架中。通过自助服务界面让开发人员可以便捷地创建托管环境，打开 VMs 或者容器，允许他们测试运维管理代码。</p>
<p>给运维管理框架构建合规的审计日志，便能跟踪到哪些资源被创建和使用。一旦资源发生冲突，这些日志将会有非常大的帮助，并让你了解到哪里需要更多的沙箱或者哪些更细粒度的配置需要定义。</p>
<blockquote><p>欲速则不达，速度越快反而导致质量下降？</p></blockquote>
<p>对于企业来说，不断提升创新速度才能保持竞争力，所以速度至关重要。因此这里需要更快的软件交付速度，也正是采用 DevOps 做法的主要动机。</p>
<p>许多 <a href="http://news.oneapm.com/tag/devops/">DevOps</a> 成功案例都在展示其一天能部署多少次，10还是1000。但是在现实世界中，这些指标简可以称得上是神话。有些企业尽量一个月实现一次部署，还有些企业一个主要版本更新需要按年计算，而发布给用户更需要30天的时间。这三十天的滞后时间，同时生产环境处于不一致的状态，所有人都难以应付生产中出现的问题。「是新版本还是旧版本造成了这个尚未确定的问题？」操作无法加快的一个主要原因是无法确定问题究竟是发生在改变期间或改变后。</p>
<p>当改动导致问题，可能导致以下结果：</p>
<ul>
<li><p>添加更多控制过程（审批门槛更多，改动窗口更小）</p></li>
<li><p>改变批次变大（更多的工作塞到给定的变化窗口）</p></li>
<li><p>增加「紧急修正」（高优先级功能得到快速跟踪，才能避免正常的变化流程）</p></li>
<li><p>因为批系统和非正常软件发布流程，应用程序快速更新将带来很大压力</p></li>
</ul>
<p>鉴于以上后果，加快改变速度的想法显得不切实际，因为它确实可能诱发更多的问题。</p>
<p>问题是企业该如何快速给系统做更新？首先，指定更新过程中的安全策略非常重要。快速转变意味着能安全地快速改变。下面是一些常见策略：</p>
<h3>小批量</h3>
<p>大批量改变所带来的工作量需要耗费大量的人力和时间。</p>
<p>解决办法是利用这种策略：变化越少越容易实现，完成后也便于检查。</p>
<h3>预演</h3>
<p>这里有一个很好的谚语，「Don’t practice until you get it right. Practice until you can’t get it wrong」。当然，你不能在生产环境中实践这个途径。将更新应用到生产环境之前，你应该在非生产环境下进行多次实验。不要依赖于运气，要抱着必然存在故障的理念。</p>
<h3>可核查的流程阶段</h3>
<p>不管是新建立的一个网站或者是现有应用程序需要更新，请确保已经为先决条件做好了足够的检查。也就是说，如果你要部署一个应用，在这之前你就要准备好脚本测试，来证实你的外部或环境依赖性。如果你正在构建一个网站，在安装操作平台之前，保证你已经确认好硬件和网络环境。在流程阶段边界构建这种自动化测试，对于防止问题遗漏是一个巨大的安全保障。你可以使用这些验证检查来决定「stop the line」。</p>
<h3>流程规则</h3>
<p>是什么导致了环境中布满了特殊定制的服务器和网络？缺少规则。如果企业无法统一管理变动，每个人都会按自己的方式行事。那如何对流程进行管控？搜寻所有不同的版本。如果流程在两个版本中不同，那么就意味着这里存在一个 variation。流程 variation 意味着流程失控。有两个简单的度量可用于了解你对流程控制的程度：交货时间和报废率。交货时间代表改变所需的时间。废品率是返工频率。预演和可核查的流程可以通过降低废品率和稳定交货时间帮助获得控制过程。流程管控的最大好处是提高可预测变化的能力。业务依赖于这种可预测性。可预测性的业务可以提前规划移动速度的快慢。</p>
<blockquote><p>更多途径进入运维管理环境？</p></blockquote>
<p>每个人都更好地了解生产中各部分是如何执行的，可以帮助企业设计更好的系统来支持业务。如果开发人员或测试人员都难以发现服务运行的问题，只会耽搁有利于用户操作的改进。让任何人都能容易地了解到应用版本在主机是如何部署的，以及主机配置和应用程序的性能。</p>
<p>有时数据隐私规则使得数据访问并不那么直接。一些日志包含客户数据和规则可能限制有限的用户访问。不要说「没有」或手动地去收集和清洗，这里需要存在一个自动化的自服务，从而让开发者或审计人员可以自己获取。</p>
<p>生产环境的可见性对于开发人员来说是至关重要的，从而他们可以建立一个类似的环境。模拟声场环境建模开发和测试环境是减少变数并让一切都在控制中的有效手段。</p>
<blockquote><p>这是否意味着允许开发者进行 Shell访问？</p></blockquote>
<p>这个问题是传统企业运营团队的弊病。通常这个问题是另一个问题的征兆。为什么一个开发者要 Shell 访问运维支持的环境？在开发或早期的测试环境下，开发人员可能需要Shell访问来实验开发部署和配置代码。这的确是申请 Shell 访问的一个合理理由。</p>
<p>这是临时或生产环境中 Shell 访问的请求吗？Shell 访问请求可能是即席改变方法的一个标志，从而改变一个环境的稳定性。因此，对改变方法进行自动化封装非常重要。</p>
<p>归根结底，Shell 访问生产环境确实有很大的风险。</p>
<p>原文链接：<a href="http://dev2ops.org/2014/06/adopting-devops-in-enterprise-operations/"></a><a href="http://dev2ops.org/2014/06/adopting-devops-in-enterprise-operations/">http://dev2ops.org/2014/06/adopting-devops-in-enterprise-operations/</a></p>
<p><strong>本文系 |
31a86d24833cfae285650a96be0588874
| 工程师编译整理。想阅读更多技术文章，请访问 OneAPM <a href="http://news.oneapm.com/?utm_source=TechCommunity&amp;utm_medium=TechArticle&amp;utm_campaign=JulSoftArti">官方博客</a>。</strong></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003737192";}i:9;a:11:{s:5:"title";s:38:"Linux的硬连接与软连接的区别";s:4:"link";s:42:"http://segmentfault.com/a/1190000003737107";s:2:"id";s:42:"http://segmentfault.com/a/1190000003737107";s:7:"updated";s:25:"2015-09-11T18:12:48+08:00";s:9:"published";s:25:"2015-09-11T18:12:48+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"赵雍";s:10:"author_uri";s:39:"http://segmentfault.com/u/zhaoyongxiang";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:2842:"
<h2>1.Linux链接概念</h2>
<p>Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。</p>
<h2>硬连接</h2>
<p>硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。</p>
<h2>软连接</h2>
<p>另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。</p>
<h2>2.通过实验加深理解</h2>
<p>[oracle@Linux]$ touch f1          #创建一个测试文件f1<br>[oracle@Linux]$ ln f1 f2          #创建f1的一个硬连接文件f2<br>[oracle@Linux]$ ln -s f1 f3       #创建f1的一个符号连接文件f3<br>[oracle@Linux]$ ls -li            # -i参数显示文件的inode节点信息<br>total 0<br>9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f1<br>9797648 -rw-r--r--  2 oracle oinstall 0 Apr 21 08:11 f2<br>9797649 lrwxrwxrwx  1 oracle oinstall 2 Apr 21 08:11 f3 -&gt; f1</p>
<p>从上面的结果中可以看出，硬连接文件f2与原文件f1的inode节点相同，均为9797648，然而符号连接文件的inode节点不同。</p>
<p>[oracle@Linux]$ echo "I am f1 file" &gt;&gt;f1<br>[oracle@Linux]$ cat f1<br>I am f1 file<br>[oracle@Linux]$ cat f2<br>I am f1 file<br>[oracle@Linux]$ cat f3<br>I am f1 file<br>[oracle@Linux]$ rm -f f1<br>[oracle@Linux]$ cat f2<br>I am f1 file<br>[oracle@Linux]$ cat f3<br>cat: f3: No such file or directory</p>
<p>通过上面的测试可以看出：当删除原始文件f1后，硬连接f2不受影响，但是符号连接f1文件无效</p>
<h2>3.总结</h2>
<p>依此您可以做一些相关的测试，可以得到以下全部结论：<br>1).删除符号连接f3,对f1,f2无影响；<br>2).删除硬连接f2，对f1,f3也无影响；<br>3).删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效；<br>4).同时删除原文件f1,硬连接f2，整个文件会真正的被删除。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003737107";}i:10;a:11:{s:5:"title";s:25:"Android换肤技术总结";s:4:"link";s:42:"http://segmentfault.com/a/1190000003735849";s:2:"id";s:42:"http://segmentfault.com/a/1190000003735849";s:7:"updated";s:25:"2015-09-11T14:27:21+08:00";s:9:"published";s:25:"2015-09-11T14:27:21+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"cogitate";s:10:"author_uri";s:34:"http://segmentfault.com/u/cogitate";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:10694:"
<p>原文出处：<br><a href="http://blog.zhaiyifan.cn/2015/09/10/Android%E6%8D%A2%E8%82%A4%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/">http://blog.zhaiyifan.cn/2015/09/10/Android%E6%8D%A2%E8%82%A4%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/</a></p>
<h1>背景</h1>
<p>纵观现在各种Android app，其换肤需求可以归为</p>
<ul>
<li><p>白天/黑夜主题切换（或者别的名字，通常2套），如同花顺/自选股/天天动听等，UI表现为一个switcher。</p></li>
<li><p>多种主题切换，通常为会员特权，如QQ/QQ空间。</p></li>
</ul>
<p>对于第一种来说，目测应该是直接通过本地theme来做的，即所有图片/颜色的资源都在apk里面打包了。<br>而对于第二种，则相对复杂一些，由于作为一种线上服务，可能上架新皮肤，且那么多皮肤包放在apk里面实在太占体积了，所以皮肤资源会在选择后再进行下载，也就不能直接使用android的那套theme。</p>
<h1>技术方案</h1>
<p>内部资源加载方案和动态下载资源下载两种。<br>动态下载可以称为一种黑科技了，因为往往需要hack系统的一些方法，所以在部分机型和新的API上有时候可能有坑，但相对好处则很多</p>
<ul>
<li><p>图片/色值等资源由于是后台下发的，可以随时更新</p></li>
<li><p>APK体积减小</p></li>
<li><p>对应用开发者来说，换肤几乎是透明的，不需要关心有几套皮肤</p></li>
<li><p>可以作为增值服务卖钱！！</p></li>
</ul>
<h2>内部资源加载方案</h2>
<p>内部资源加载都是通过android本身那套theme来做的，相对业务开发来说工作量更大（需要定义attr和theme），不同方案类似地都是在BaseActivity里面做setTheme，差别主要在解决以下2个问题的策略：</p>
<ul>
<li><p>setTheme后如何实时刷新，而不用重新创建页面（尤其是listview里面的item）。</p></li>
<li><p>哪些view需要刷新，刷新什么（背景？字体颜色？ImageView的src？）。</p></li>
</ul>
<h3>自定义view</h3>
<p><a href="https://github.com/dersoncheng/MultipleTheme">MultipleTheme</a><br>做自定义view是为了在setTheme后会去立即刷新，更新页面UI对应资源（如TextView替换背景图和文字颜色），在上述项目中，则是通过对rootView进行遍历，对所有实现了ColorUiInterface的view/viewgroup进行setTheme操作来实现即使刷新的。<br>显然这样太重了，需要把应用内的各种view/viewgroup进行替换。<br>手动绑定view和要改变的资源类型</p>
<p><a href="https://github.com/bboyfeiyu/Colorful">Colorful</a><br>这个…我们看看用法吧…</p>
<pre><code>ViewGroupSetter listViewSetter = new ViewGroupSetter(mNewsListView);
// 绑定ListView的Item View中的news_title视图，在换肤时修改它的text_color属性
listViewSetter.childViewTextColor(R.id.news_title, R.attr.text_color);

// 构建Colorful对象来绑定View与属性的对象关系
mColorful = new Colorful.Builder(this)
        .backgroundDrawable(R.id.root_view, R.attr.root_view_bg)
        // 设置view的背景图片
        .backgroundColor(R.id.change_btn, R.attr.btn_bg)
        // 设置背景色
        .textColor(R.id.textview, R.attr.text_color)
        .setter(listViewSetter) // 手动设置setter
        .create(); // 设置文本颜色</code></pre>
<p>我就是想换个皮肤，还得在activity里自己去设置要改变哪个view的什么属性，对应哪个attribute？是不是成本太高了？而且activity的逻辑也很容易被弄得乱七八糟。</p>
<h2>动态资源加载方案</h2>
<h3>resource替换</h3>
<p>开源项目可参照<a href="https://github.com/fengjundev/Android-Skin-Loader">Android-Skin-Loader</a><br>即覆盖application的getResource方法，优先加载本地皮肤包文件夹下的资源包，对于性能问题，可以通过attribute或者资源名称规范(如需要换肤则用skin_开头)来优化，从而不对不换肤的资源进行额外开销。<br>可以重点关注该项目中的SkinInflaterFactory和SkinManager（实现了自己的getColor、getDrawable方法）。<br>不过由于Android 5.1源码里，getDrawable方法的实现被修改了，所以会导致无法跟肤的问题（其实是loadDrawable被修改了，连参数都改了，类似的内部API大改在5.1上还很多）。<br>4.4的源码中Resources.java:</p>
<pre><code>public Drawable getDrawable(int id) throws NotFoundException {
    TypedValue value;
    synchronized (mAccessLock) {
        value = mTmpValue;
        if (value == null) {
            value = new TypedValue();
        } else {
            mTmpValue = null;
        }
        getValue(id, value, true);
    }
    // 实际资源通过loadDrawable方法加载
    Drawable res = loadDrawable(value, id);
    synchronized (mAccessLock) {
        if (mTmpValue == null) {
            mTmpValue = value;
        }
    }
    return res;
}

// loadDrawable会去preload的LongSparseArray里面查找
/*package*/ Drawable loadDrawable(TypedValue value, int id)
        throws NotFoundException {

    if (TRACE_FOR_PRELOAD) {
        // Log only framework resources
        if ((id &gt;&gt;&gt; 24) == 0x1) {
            final String name = getResourceName(id);
            if (name != null) android.util.Log.d("PreloadDrawable", name);
        }
    }

    boolean isColorDrawable = false;
    if (value.type &gt;= TypedValue.TYPE_FIRST_COLOR_INT &amp;&amp;
            value.type &lt;= TypedValue.TYPE_LAST_COLOR_INT) {
        isColorDrawable = true;
    }
    final long key = isColorDrawable ? value.data :
            (((long) value.assetCookie) &lt;&lt; 32) | value.data;

    Drawable dr = getCachedDrawable(isColorDrawable ? mColorDrawableCache : mDrawableCache, key);

    if (dr != null) {
        return dr;
    }
    ...
    ...
    return dr;
}</code></pre>
<p>而5.1代码里Resources.java:</p>
<pre><code>// 可以看到，方法参数里面加上了Theme
public Drawable getDrawable(int id, @Nullable Theme theme) throws NotFoundException {
    TypedValue value;
    synchronized (mAccessLock) {
        value = mTmpValue;
        if (value == null) {
            value = new TypedValue();
        } else {
            mTmpValue = null;
        }
        getValue(id, value, true);
    }
    final Drawable res = loadDrawable(value, id, theme);
    synchronized (mAccessLock) {
        if (mTmpValue == null) {
            mTmpValue = value;
        }
    }
    return res;
}

/*package*/ Drawable loadDrawable(TypedValue value, int id, Theme theme) throws NotFoundException {
    if (TRACE_FOR_PRELOAD) {
        // Log only framework resources
        if ((id &gt;&gt;&gt; 24) == 0x1) {
            final String name = getResourceName(id);
            if (name != null) {
                Log.d("PreloadDrawable", name);
            }
        }
    }

    final boolean isColorDrawable;
    final ArrayMap&lt;String, LongSparseArray&lt;WeakReference&lt;ConstantState&gt;&gt;&gt; caches;
    final long key;
    if (value.type &gt;= TypedValue.TYPE_FIRST_COLOR_INT
            &amp;&amp; value.type &lt;= TypedValue.TYPE_LAST_COLOR_INT) {
        isColorDrawable = true;
        caches = mColorDrawableCache;
        key = value.data;
    } else {
        isColorDrawable = false;
        caches = mDrawableCache;
        key = (((long) value.assetCookie) &lt;&lt; 32) | value.data;
    }

    // First, check whether we have a cached version of this drawable
    // that was inflated against the specified theme.
    if (!mPreloading) {
        final Drawable cachedDrawable = getCachedDrawable(caches, key, theme);
        if (cachedDrawable != null) {
            return cachedDrawable;
        }
    }</code></pre>
<p>方法名字都改了</p>
<h3>Hack Resources internally</h3>
<p>黑科技方法，直接对Resources进行hack，Resources.java:</p>
<pre><code>// Information about preloaded resources.  Note that they are not
// protected by a lock, because while preloading in zygote we are all
// single-threaded, and after that these are immutable.
private static final LongSparseArray&lt;Drawable.ConstantState&gt;[] sPreloadedDrawables;
private static final LongSparseArray&lt;Drawable.ConstantState&gt; sPreloadedColorDrawables
        = new LongSparseArray&lt;Drawable.ConstantState&gt;();
private static final LongSparseArray&lt;ColorStateList&gt; sPreloadedColorStateLists
        = new LongSparseArray&lt;ColorStateList&gt;();</code></pre>
<p>直接对Resources里面的这三个LongSparseArray进行替换，由于apk运行时的资源都是从这三个数组里面加载的，所以只要采用interceptor模式：</p>
<pre><code>public class DrawablePreloadInterceptor extends LongSparseArray&lt;Drawable.ConstantState&gt;</code></pre>
<p>自己实现一个LongSparseArray，并通过反射set回去，就能实现换肤，具体getDrawable等方法里是怎么取preload数组的，可以自己看<strong>Resources</strong>的源码。</p>
<p><strong>等等，就这么简单？</strong>，NONO，少年你太天真了，怎么去加载xml，9patch的padding怎么更新，怎么打包/加载自定义的皮肤包，drawable的状态怎么刷新，等等。这些都是你需要考虑的，在存在插件的app中，还需要考虑是否会互相覆盖resource id的问题，进而需要修改apt，把resource id按位放在2个range。<br>手Q和独立版QQ空间使用的是这种方案，效果挺好。</p>
<h2>总结</h2>
<p>尽管动态加载方案比较黑科技，可能因为系统API的更改而出问题，但相对来所<br><strong>好处有</strong></p>
<ul>
<li><p>灵活性高，后台可以随时更新皮肤包</p></li>
<li><p>相对透明，开发者几乎不用关心有几套皮肤，不用去定义各种theme和attr，甚至连皮肤包的打包都- - 可以交给设计或者专门的同学</p></li>
<li><p>apk体积节省<br><strong>存在的问题</strong></p></li>
<li><p>没有完善的开源项目，如果我们采用动态加载的第二种方案，需要的项目功能包括：</p></li>
<li><p>自定义皮肤包结构</p></li>
<li><p>换肤引擎，加载皮肤包资源并load，实时刷新。</p></li>
<li><p>皮肤包打包工具</p></li>
<li><p>对各种rom的兼容</p></li>
</ul>
<p><strong>如果有这么一个项目的话，就一劳永逸了，有兴趣的同学可以联系一下，大家一起搞一搞。</strong></p>
<p>内部加载方案大同小异，主要解决的都是即时刷新的问题，然而从目前的一些开源项目来看，仍然没有特别简便的方案。让我选的话，我宁愿让界面重新创建，比如重启activity，或者remove所有view再添加回来。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003735849";}i:11;a:11:{s:5:"title";s:24:"Objective C 链式调用";s:4:"link";s:42:"http://segmentfault.com/a/1190000003735680";s:2:"id";s:42:"http://segmentfault.com/a/1190000003735680";s:7:"updated";s:25:"2015-09-11T13:58:45+08:00";s:9:"published";s:25:"2015-09-11T13:58:45+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:9:"canopus4u";s:10:"author_uri";s:35:"http://segmentfault.com/u/canopus4u";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:2297:"
<h2>起因</h2>
<p>某日使用<code>DKChainableAnimationKit</code>的时候发现可以如下写代码：</p>
<pre><code>view.animation.rotate(180).anchorTopLeft.thenAfter(1.0).rotate(90).anchorCenter.animanimation</code></pre>
<p>无独有偶。<code>Masonry</code>其实也是这样用的</p>
<pre><code>make.right.equalTo(self.view).with.offset(-10);</code></pre>
<h2>原理</h2>
<p>看了一下代码，其实就是通过一个实现了所有方法的<code>Chaining Method Object</code>,每一个方法都返回一个`Block<br><code>, 这个</code>Block<code>返回类型为</code>Chaining Method Object<code>，</code>Block`的参数为你想要传入的参数类型。</p>
<pre><code>@interface ChainingMethodObject : NSObject
- (ChainingMethodObject * (^)(void))doA;
- (ChainingMethodObject * (^)(NSInteger i))doB;
- (ChainingMethodObject * (^)(NSString* str))doC;
- (ChainingMethodObject * (^)(NSString* str, NSArray* array))doD;
@end

@implementation ChainingMethodObject
- (ChainingMethodObject * (^)(NSInteger i))doB{
    return ^id(NSInteger i) {
        //do actual stuff related with B
        return self;
    };
}
...其他方法类似
@end</code></pre>
<p>通常情况下，<code>ChainingMethodObject</code>都会有<code>delegate</code>存在，具体视实际运用情况而定，如动画库<code>DKChainableAnimationKit</code>中，<code>animation</code>里有个<code>weak var view:UIView</code>指向UIView从而对target View进行操作。</p>
<pre><code>@implementation ChainingMethodObject
- (id) initWithObject:(id)obj{
    self = [super init];
    _delegate = obj;
    return self;
}
@end</code></pre>
<pre><code>@interface HostObject()
ChainingMethodObject * _cObj;
@end
@implementation HostObject (ChainingMethodObject)
- (ChainingMethodObject *) getChainingMethodObject{
    if (!_cObj)
        _cObj = [[ChainingMethodObject alloc] initWithObject:self];
    return _cObj;
}
@end</code></pre>
<p>然后就可以了：</p>
<pre><code>HostObject* hostObject = [HostObject new];
[hostOjbect getChainingMethodObject].doA.doC(@"Hi there!").doD(@"Hello",@[@1,@2]).doB(100).doA;</code></pre>
<h2>参考</h2>
<p><a href="https://github.com/Draveness/DKChainableAnimationKit">DKChainableAnimationKit</a></p>
<p><a href="https://github.com/SnapKit/Masonry">Masonry</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003735680";}i:12;a:11:{s:5:"title";s:48:"Laravel 5系列教程九：Eloquent Relationship";s:4:"link";s:42:"http://segmentfault.com/a/1190000003735637";s:2:"id";s:42:"http://segmentfault.com/a/1190000003735637";s:7:"updated";s:25:"2015-09-11T13:51:57+08:00";s:9:"published";s:25:"2015-09-11T13:51:57+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:9:"JellyBool";s:10:"author_uri";s:35:"http://segmentfault.com/u/jellybool";s:2:"re";a:1:{s:4:"rank";s:1:"2";}s:7:"summary";s:14165:"
<blockquote><p>原文来自 <a href="https://laravist.com/article/18">https://laravist.com/article/18</a></p></blockquote>
<p><a href="https://laravist.com/">Laravist</a>是我刚刚上线的Laravel社区，有任何与Laravel相关的问题可以到这里来问我，我会尽力去帮大家解决问题，后期会尝试录制一些视频教程，形式大概是这样的</p>
<p><a href="https://laravist.com/lesson/1">https://laravist.com/lesson/1</a></p>
<h2>前奏</h2>
<p>在开始正文之前，我们首先来说说在实际的开发中，经常会接触到几种常见的对应关系模式：</p>
<pre><code>One-To-One //一对一

One-To-Many //一对多

Many-To-Many //多对多

</code></pre>
<p>不知道你对这些概念是一种什么样的感受，如果是不太理解的。你可以将这些概念应用到生活中，理解起来就很简单了，就举一个与我们在网上经常见到的例子：</p>
<pre><code>User-To-Profile // One-To-One

User-To-Articles // One-To-Many

Article-To-Comments // One-To-Many

Articles-To-Tags // Many-To-Many
</code></pre>
<p>翻译过来就是：</p>
<ol>
<li><p>一个用户对应一个用户档案</p></li>
<li><p>一个用户可以发表多篇文章</p></li>
<li><p>一篇文章可以有多个评论</p></li>
<li><p>而文章和标签确实多对多的关系，一篇文章可以有多个标签；一个标签可以属于多篇文章</p></li>
</ol>
<p>在这些关系模型中，最难实现的就是Many-To-Many这种多对多的关系，但是我们这个简单地博客并没有用户管理，也就是并没有开放让用户注册，所以我们在这里还是要挑战一下难度，实现Articles-To-Tags这种Many-To-Many关系，借助Laravel的强大的Eloquent，实现这个功能还是比较顺心的。至于一对一和一对多这两种关系，可以触类旁通。</p>
<h2>创建tags表</h2>
<p>要实现Articles-To-Tags这种Many-To-Many关系，我们需要<code>tags</code>表和<code>Tag</code>模型，所以我们分别来创建之。</p>
<pre><code>php artisan make:migration create_tags_table --create=tags</code></pre>
<p>打开生成的migration文件，为up()方法增加一行代码：</p>
<pre><code>public function up()
{
    Schema::create('tags', function (Blueprint $table) {
        $table-&gt;increments('id');
        $table-&gt;string('name');
        $table-&gt;timestamps();
    });
}
</code></pre>
<p>这里我们增加了<code>$table-&gt;string('name');</code>这一行，这个字段表示为<code>tags table</code>添加一个<code>name</code>字段，代表标签的名字。</p>
<p>接下来，我们为<code>tags</code>表创建一个<code>Tag</code>模型:</p>
<pre><code>php artisan make:model Tag</code></pre>
<p>生成了<code>Tag</code>模型之后，我们先不用去管<code>Tag.php</code>文件，因为我们还需要一张关系表<code>article_tag</code>，这个表只存<code>tag_id</code>和<code>article_id</code>，所以我们来创建之：</p>
<pre><code>php artisan make:migration create_article_tag_table --create=article_tag</code></pre>
<p>打开migration文件来为之加上<code>tag_id</code>和<code>article_id</code>这两个字段：</p>
<pre><code> public function up()
    {
        Schema::create('article_tag', function (Blueprint $table) {
            $table-&gt;increments('id');
            $table-&gt;integer('article_id')-&gt;unsigned()-&gt;index();
            $table-&gt;foreign('article_id')-&gt;references('id')-&gt;on('articles')-&gt;onDelete('cascade');
            $table-&gt;integer('tag_id')-&gt;unsigned()-&gt;index();
            $table-&gt;foreign('tag_id')-&gt;references('id')-&gt;on('tags')-&gt;onDelete('cascade');
            $table-&gt;timestamps();
        });
    }
</code></pre>
<p>这里貌似就添加tag_id和article_id这两个字段，但是用了很多行代码，我们只要是理解下面这个：</p>
<pre><code>$table-&gt;foreign('article_id')-&gt;references('id')-&gt;on('articles')-&gt;onDelete('cascade');
</code></pre>
<p>foreign()：外键<br>references()：参照字段<br>on()：参照表<br>onDelete()：删除时的执行动作<br><code>这里是跟着删除，比如删除了某篇文章，我们将article_tag中包含article_id一样的记录也删除</code></p>
<p>最后，执行migration生成<code>article_tag</code>表：</p>
<pre><code>php artisan migrate</code></pre>
<p>OK，生成这两个表之后，我们就可以正式开始我们的工作了。</p>
<h2>声明Eloquent的关系</h2>
<p>Articles和Tags是多对多的关系，所以我们需要在<code>Article.php</code>中声明下面的关系：</p>
<pre><code>
public function tags()
    {
        return $this-&gt;belongsToMany('App\Tag');
    }
</code></pre>
<p>在Tag.php，也同样：</p>
<pre><code> public function articles()
    {
        return $this-&gt;belongsToMany('App\Article');
    }
</code></pre>
<p>我们使用<code>$this-&gt;belongsToMany()</code>来表明Eloquent的关系，这里需要注意的是如果你的外键并不是<code>article_id</code>和<code>tag_id</code>，你需要在第三个参数进行设置，写成类似下面这样：</p>
<pre><code> public function articles()
    {
        return $this-&gt;belongsToMany('App\Article','conversation_id');
    }
</code></pre>
<p>OK，这样，我们的多对多关系就声明完毕了。</p>
<h2>使用Select2</h2>
<p>在开始之前，我们使用tinker生成几个tag，过程就不演示了，最后是这样的：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/c51c299e-b7fb-4307-8b4d-020ec3461ee7.png" alt="替代文字" title="替代文字"></p>
<p>然后，为了更好地用户体验，我们引入<a href="https://select2.github.io/">Select2</a>，这个对选择多个选项的时候表现得异常完美。</p>
<p>Select2 用法：<a href="https://select2.github.io/examples.html">https://select2.github.io/examples.html</a></p>
<p>我们在app.blade.php引入Select2的css文件和js文件：</p>
<pre><code>&lt;link rel='stylesheet' href="/css/select2.css" type='text/css' media='all'/&gt;
&lt;script src="/js/jquery-2.1.0.min.js"&gt;&lt;/script&gt;
&lt;script src="/js/select2.full.min.js"&gt;&lt;/script&gt;
</code></pre>
<p>在&lt;head&gt;&lt;/head&gt;标签内，我们还引入了jquery，因为select2依赖于jquery，所以。注意文件的下载或来源，请自行获取。</p>
<p>引入之后，我们就可以在文件创建的页面依旧使用我们的<code>Form</code>来生成我们的选择框了，来到<code>articles/create.blade.php</code>文件，在<code>published_at</code>下面添加一个输入表单：</p>
<pre><code>&lt;div class="form-group"&gt;
        {!! Form::label('tag_list','选择标签') !!}
        {!! Form::select('tag_list[]',$tags,null,['class'=&gt;'form-control js-example-basic-multiple','multiple'=&gt;'multiple']) !!}
&lt;/div&gt;</code></pre>
<p>这里需要注意的是<code>tag_list[]</code>，如果我们只是使用<code>tag_list</code>,就只能选到一个标签，如果我们需要选择多个，我们需要已数组的形式来储存我们的标签，还有一个就是指定一下<code>'multiple'=&gt;'multiple'</code>，就是开启支持多选模式。然后<code>$tags</code>就是我们需要从数据库获tags表取到得数据，所以自然而然，我们到<code>ArticleController</code>中的<code>create()</code>方法中，稍微修改一下代码：</p>
<pre><code>public function create()
    {
        $tags = Tag::lists('name', 'id');
        //为了在界面中显示标签name，id为了在保存文章的时候使用。
        return view('articles.create',compact('tags'));
    }
</code></pre>
<p>这里我们使用lists()方法将Tag中(对于tags数据表)name和id以一个Eluqoent的方式返回，你可以使用dd($tags)，来看看。恩，这个时候来看看我们的create页面：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/096cfcd2-9bbc-4dd2-816c-16414758c10c.png" alt="替代文字" title="替代文字"></p>
<p>这时候我们发现，样式并没有Select2那么好看，那是因为我们还没有初始化Select2，所以我们在create.blade.php写几行简单地js代码：</p>
<pre><code> &lt;script type="text/javascript"&gt;
        $(function() {
            $(".js-example-basic-multiple").select2({
                placeholder: "添加标签"
            });
        });
    &lt;/script&gt;
</code></pre>
<p>在<code>@endsection</code>紧接着的上一行加上上面的代码，这里我们使用jquery的选择器，然后调用<code>select2();</code>来初始化我们的选择框，再来看看效果：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/7e673045-88ed-43fa-af9f-555dc9e19ab7.gif" alt="替代文字" title="替代文字"></p>
<p>很完美，我们将整个UI完善得还不错，我们用<code>dd()</code>;来看看我们表单提交过来的是什么，在<code>ArticleController</code>中的<code>store()</code>方法中添加一行代码：</p>
<pre><code>dd($request-&gt;all());
</code></pre>
<p>我们来看看效果：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/a12b891a-cfe0-4878-bf09-a586352a5377.gif" alt="替代文字" title="替代文字"></p>
<p>我们看到得<code>tag_list</code>是一个数组，里面的值并不是我们选择的标签的<code>name</code>，而是标签的<code>id</code>，这样我们就可以使用laravel提供的<code>attach()</code>来添加我们的标签了，这个<code>attach()</code>接受一个id的数组，这里正好！，所以我们来稍微来修改一下<code>store()</code>方法：</p>
<pre><code>
 public function store(Requests\StoreArticleRequest $request)
    {
        $input = $request-&gt;all();
        $input['intro'] = mb_substr($request-&gt;get('content'),0,64);
        $article = Article::create($input);
        $article-&gt;tags()-&gt;attach($request-&gt;input('tag_list'));
        return redirect('/');
    }
</code></pre>
<p>我们这里首先将<code>Article::create($input)</code>赋予<code>$article</code>变量(Eloquent对象)，然后使用<code>$article-&gt;tags()-&gt;attach()</code>来添加标签，并将我们的标签数组传给<code>attach()</code>方法，我们来看看有没有成功：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/ec755987-2b65-4248-9d35-d2d0c80ce098.gif" alt="替代文字" title="替代文字"></p>
<p>这里的文章是发表成功了，我们再来看看我们的标签是否添加成功，来看看我们的<code>article_tag</code>表：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/1bf4c1be-a7a6-4dc4-8db9-0fc60cbe6e86.png" alt="替代文字" title="替代文字"></p>
<p>是添加了三个标签，但是我们发现这个<code>created_at</code>和<code>updated_at</code>貌似有点问题，我们来修复一下，在<code>Article.php</code>中的<code>tags()</code>方法中：</p>
<pre><code>public function tags()
    {
        return $this-&gt;belongsToMany('App\Tag')-&gt;withTimestamps();
    }
</code></pre>
<p>我们在后面直接使用<code>withTimestamps()</code>来同步我们的时间，我们再来试一试：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/9300c01d-a4b3-45b1-abcd-c1ac12a1299c.gif" alt="替代文字" title="替代文字"></p>
<p>再来看看我们的数据库：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/1705d4e8-7f52-4177-b105-7a8a4cddebd0.png" alt="替代文字" title="替代文字"></p>
<p>看到最后的两个记录，很完美。</p>
<h2>在视图中显示我们的tags</h2>
<p>我们既然有了标签，我们为什么不来将它展示出来呢？在<code>articles/index.blade.php</code>中，我们来将文件的标签输出一下：</p>
<pre><code>&lt;h2 class="post-title pad"&gt;
    &lt;a href="/articles/{{ $article-&gt;id }}"&gt; {{ $article-&gt;title }}&lt;/a&gt;
&lt;/h2&gt;
&lt;ul class="post-meta pad group"&gt;
    &lt;li&gt;&lt;i class="fa fa-clock-o"&gt;&lt;/i&gt;{{ $article-&gt;published_at-&gt;diffForHumans() }}&lt;/li&gt;
    @if($article-&gt;tags)
        @foreach($article-&gt;tags as $tag)
            &lt;li&gt;&lt;i class="fa fa-tag"&gt;&lt;/i&gt;{{ $tag-&gt;name }}&lt;/li&gt;
        @endforeach
    @endif
&lt;/ul&gt;
</code></pre>
<p>我们在<code>&lt;h2&gt;</code>标签下面增加一个<code>&lt;ul&gt;</code>列表，然后是首先将发表日期<code>published_at</code>输出了，这里我们使用了Carbon的<code>diffForHumans()</code>方法，这个方法就会产生几分钟之前，几个小时之前的效果，这里也可以体会我们之前需要将<code>published_at</code>这个对象作为Carbon对象来对待了，如果是简单地字符串，是不能调用Carbon的<code>diffForHumans()</code>方法的。</p>
<p>接下来，我们使用<code>$article-&gt;tags</code>取得文章的标签，这个<code>tags</code>就是我们声明多对多关系的<code>tags()</code>方法。我们来看看效果：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/b6b9c9eb-d0af-4e54-89b0-1a99927abfcd.png" alt="替代文字" title="替代文字"></p>
<p>我们发现<code>我们的多少分钟之前</code>都是英文，那是因为我们没有设置Carbon，我们来修复一下，在<code>app/Providers/AppServiceProvider.php</code>中的<code>boot()</code>方法添加下面这一行：</p>
<pre><code>\Carbon\Carbon::setLocale('zh');</code></pre>
<p>然后刷新，见证一下奇迹吧：</p>
<p><img src="https://wt-prj.oss.aliyuncs.com/0d06af79c49d4e08abb1ab3f7ab6e860/901b15e7-daf0-4768-bb5c-12e05e6494fe.gif" alt="替代文字" title="替代文字"></p>
<h2>总结</h2>
<p>到这里我们利用laravel提供的<code>attach()</code>方法将基本的多对多关系实现了，并且还稍微美化了一下输出，将<code>published_at</code>字段完美呈现。接下来我打算说一说怎么实现修改文章了，这是一个必走的流程嘛。所以。。。</p>
<p>最后，<strong>Happy Hacking</strong></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003735637";}i:13;a:11:{s:5:"title";s:53:"go标准库剖析1 (transport http请求的承载者)";s:4:"link";s:42:"http://segmentfault.com/a/1190000003735562";s:2:"id";s:42:"http://segmentfault.com/a/1190000003735562";s:7:"updated";s:25:"2015-09-11T13:28:30+08:00";s:9:"published";s:25:"2015-09-11T13:28:30+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:12:"爆料分享";s:10:"author_uri";s:41:"http://segmentfault.com/u/baoliaofenxiang";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:15301:"
<p>使用golang net/http库发送http请求， 最后都是调用 transport的  RoundTrip方法,</p>
<pre><code>type RoundTripper interface {
    RoundTrip(*Request) (*Response, error)
}</code></pre>
<p><code>RoundTrip executes a single HTTP transaction, returning the Response for the request req.</code> (RoundTrip 代表一个http事务，给一个请求返回一个响应)<br>说白了，就是你给它一个request,它给你一个response<br>下面我们来看一下他的实现，对应源文件<br><code>net/http/transport.go</code>， 我感觉这里是http package里面的精髓所在, go里面一个struct就跟一个类一样， transport这个类长这样的</p>
<pre><code>type Transport struct {
    idleMu     sync.Mutex
    wantIdle   bool // user has requested to close all idle conns
    idleConn   map[connectMethodKey][]*persistConn
    idleConnCh map[connectMethodKey]chan *persistConn

    reqMu       sync.Mutex
    reqCanceler map[*Request]func()

    altMu    sync.RWMutex
    altProto map[string]RoundTripper // nil or map of URI scheme =&gt; RoundTripper
    //Dial获取一个tcp 连接，也就是net.Conn结构，你就记住可以往里面写request
    //然后从里面搞到response就行了
    Dial func(network, addr string) (net.Conn, error)
}</code></pre>
<p>篇幅所限， https和代理相关的我就忽略了， 两个<code>map</code> 为  <code>idleConn</code>  <code>idleConnCh</code>，  <code>idleConn</code> 是保存从 connectMethodKey （代表着不同的协议 不同的host，也就是不同的请求）到 persistConn 的映射， <code>idleConnCh</code> 用来在并发http请求的时候在多个 goroutine 里面相互发送持久连接，也就是说， 这些持久连接是可以重复利用的， 你的http请求用某个<code>persistConn</code>用完了，通过这个<code>channel</code>发送给其他http请求使用这个<code>persistConn </code>  <br>然后我们找到<code>transport</code>的<code>RoundTrip </code>方法</p>
<pre><code>func (t *Transport) RoundTrip(req *Request) (resp *Response, err error) {
    ...
    pconn, err := t.getConn(req, cm)
    if err != nil {
        t.setReqCanceler(req, nil)
        req.closeBody()
        return nil, err
    }

    return pconn.roundTrip(treq)
}</code></pre>
<p>前面对输入的错误处理部分我们忽略， 其实就2步，先获取一个TCP长连接，所谓TCP长连接就是三次握手建立连接后不<code>close</code>而是一直保持重复使用（节约环保） 然后调用这个持久连接persistConn 这个struct的roundTrip方法</p>
<p>我们跟踪第一步</p>
<pre><code>func (t *Transport) getConn(req *Request, cm connectMethod) (*persistConn, error) {
    if pc := t.getIdleConn(cm); pc != nil {
        // set request canceler to some non-nil function so we
        // can detect whether it was cleared between now and when
        // we enter roundTrip
        t.setReqCanceler(req, func() {})
        return pc, nil
    }
 
    type dialRes struct {
        pc  *persistConn
        err error
    }
    dialc := make(chan dialRes)
    //定义了一个发送 persistConn的channel

    prePendingDial := prePendingDial
    postPendingDial := postPendingDial

    handlePendingDial := func() {
        if prePendingDial != nil {
            prePendingDial()
        }
        go func() {
            if v := &lt;-dialc; v.err == nil {
                t.putIdleConn(v.pc)
            }
            if postPendingDial != nil {
                postPendingDial()
            }
        }()
    }

    cancelc := make(chan struct{})
    t.setReqCanceler(req, func() { close(cancelc) })
 
    // 启动了一个goroutine, 这个goroutine 获取里面调用dialConn搞到
    // persistConn, 然后发送到上面建立的channel  dialc里面，    
    go func() {
        pc, err := t.dialConn(cm)
        dialc &lt;- dialRes{pc, err}
    }()

    idleConnCh := t.getIdleConnCh(cm)
    select {
    case v := &lt;-dialc:
        // dialc 我们的 dial 方法先搞到通过 dialc通道发过来了
        return v.pc, v.err
    case pc := &lt;-idleConnCh:
        // 这里代表其他的http请求用完了归还的persistConn通过idleConnCh这个    
        // channel发送来的
        handlePendingDial()
        return pc, nil
    case &lt;-req.Cancel:
        handlePendingDial()
        return nil, errors.New("net/http: request canceled while waiting for connection")
    case &lt;-cancelc:
        handlePendingDial()
        return nil, errors.New("net/http: request canceled while waiting for connection")
    }
}</code></pre>
<p>这里面的代码写的很有讲究 , 上面代码里面我也注释了， 定义了一个发送 <code>persistConn</code>的channel<code> dialc</code>， 启动了一个<code>goroutine</code>, 这个<code>goroutine</code> 获取里面调用<code>dialConn</code>搞到<code>persistConn</code>, 然后发送到<code>dialc</code>里面，主协程<code>goroutine</code>在 <code>select</code>里面监听多个<code>channel</code>,看看哪个通道里面先发过来 <code>persistConn</code>，就用哪个，然后<code>return</code>，</p>
<p>这里要注意的是 <code>idleConnCh</code>  这个通道里面发送来的是其他的http请求用完了归还的<code>persistConn</code>，  如果从这个通道里面搞到了，<code> dialc</code>这个通道也等着发呢，不能浪费，就通过<code>handlePendingDial</code>这个方法把<code>dialc</code>通道里面的<code>persistConn</code>也发到<code>idleConnCh</code>， 等待后续给其他http请求使用， </p>
<p>还有就是，读者可以翻一下代码，每个新建的persistConn的时候都把tcp连接里地输入流，和输出流用br（<code>br       *bufio.Reader </code>）,和bw(<code>bw       *bufio.Writer  </code>)包装了一下，往bw写就写到tcp输入流里面了，读输出流也是通过br读，并启动了读循环和写循环</p>
<pre><code>pconn.br = bufio.NewReader(noteEOFReader{pconn.conn, &amp;pconn.sawEOF})
pconn.bw = bufio.NewWriter(pconn.conn)
go pconn.readLoop()
go pconn.writeLoop()</code></pre>
<p>我们跟踪第二步<code>pconn.roundTrip</code> 调用这个持久连接persistConn 这个struct的<code>roundTrip</code>方法。<br>先瞄一下 <code>persistConn</code> 这个struct</p>
<p>type persistConn struct {</p>
<pre><code>t        *Transport
cacheKey connectMethodKey
conn     net.Conn
tlsState *tls.ConnectionState
br       *bufio.Reader       // 从tcp输出流里面读
sawEOF   bool                // whether we've seen EOF from conn; owned by readLoop
bw       *bufio.Writer       // 写到tcp输入流
 reqch    chan requestAndChan // 主goroutine 往channnel里面写，读循环从     
                             // channnel里面接受
writech  chan writeRequest   // 主goroutine 往channnel里面写                                      
                             // 写循环从channel里面接受
closech  chan struct{}       // 通知关闭tcp连接的channel 

writeErrCh chan error

lk                   sync.Mutex // guards following fields
numExpectedResponses int
closed               bool // whether conn has been closed
broken               bool // an error has happened on this connection; marked broken so it's not reused.
canceled             bool // whether this conn was broken due a CancelRequest
// mutateHeaderFunc is an optional func to modify extra
// headers on each outbound request before it's written. (the
// original Request given to RoundTrip is not modified)
mutateHeaderFunc func(Header)</code></pre>
<p>}</p>
<p>里面是各种channel, 用的是出神入化， 各位要好好理解一下， 我这里画一下</p>
<p>这里有三个goroutine，分别用三个圆圈表示， channel用箭头表示</p>
<p><img src="http://7xlp8r.com1.z0.glb.clouddn.com/QQ20150911-2.jpg" alt="仔细看" title="仔细看"></p>
<p>有两个channel <code>writeRequest</code> 和 <code>requestAndChan</code></p>
<pre><code>type writeRequest struct {
    req *transportRequest
    ch  chan&lt;- error
}</code></pre>
<p>主goroutine 往writeRequest里面写，写循环从writeRequest里面接受</p>
<pre><code>type responseAndError struct {
    res *Response
    err error
}

type requestAndChan struct {
    req *Request
    ch  chan responseAndError
    addedGzip bool
}
</code></pre>
<p>主goroutine 往requestAndChan里面写，读循环从requestAndChan里面接受<br>注意这里的channel都是双向channel，也就是channel 的struct里面有一个chan类型的字段，  比如 <code>reqch    chan requestAndChan</code>  这里的 requestAndChan 里面的 <code>ch  chan responseAndError</code> <br>这个是很牛叉， 主goroutine 通过 reqch 发送requestAndChan 给读循环， 然后读循环搞到response后通过  requestAndChan 里面的通道responseAndError把response返给主goroutine,  所以我画了一个双向箭头</p>
<p>我们研究一下代码，我理解下来其实就是三个goroutine通过channel互相协作的过程<br>主循环</p>
<pre><code>
func (pc *persistConn) roundTrip(req *transportRequest) (resp *Response, err error) {
    ... 忽略
    // Write the request concurrently with waiting for a response,
    // in case the server decides to reply before reading our full
    // request body.
    writeErrCh := make(chan error, 1)
    pc.writech &lt;- writeRequest{req, writeErrCh}
    //把request发送给写循环
    resc := make(chan responseAndError, 1)
    pc.reqch &lt;- requestAndChan{req.Request, resc, requestedGzip}
    //发送给读循环
    var re responseAndError
    var respHeaderTimer &lt;-chan time.Time
    cancelChan := req.Request.Cancel
WaitResponse:
    for {
        select {
        case err := &lt;-writeErrCh:
            if isNetWriteError(err) {
                //写循环通过这个channel报告错误
                select {
                case re = &lt;-resc:
                    pc.close()
                    break WaitResponse
                case &lt;-time.After(50 * time.Millisecond):
                    // Fall through.
                }
            }
            if err != nil {
                re = responseAndError{nil, err}
                pc.close()
                break WaitResponse
            }
            if d := pc.t.ResponseHeaderTimeout; d &gt; 0 {
                timer := time.NewTimer(d)
                defer timer.Stop() // prevent leaks
                respHeaderTimer = timer.C
            }
        case &lt;-pc.closech:
            // 如果长连接挂了， 这里的channel有数据， 进入这个case, 进行处理
            
            select {
            case re = &lt;-resc:
                if fn := testHookPersistConnClosedGotRes; fn != nil {
                    fn()
                }
            default:
                re = responseAndError{err: errClosed}
                if pc.isCanceled() {
                    re = responseAndError{err: errRequestCanceled}
                }
            }
            break WaitResponse
        case &lt;-respHeaderTimer:
            pc.close()
            re = responseAndError{err: errTimeout}
            break WaitResponse
            // 如果timeout，这里的channel有数据， break掉for循环
        case re = &lt;-resc:
            break WaitResponse
           // 获取到读循环的response, break掉 for循环
        case &lt;-cancelChan:
            pc.t.CancelRequest(req.Request)
            cancelChan = nil
        }
    }

    if re.err != nil {
        pc.t.setReqCanceler(req.Request, nil)
    }
    return re.res, re.err
}
</code></pre>
<p>这段代码主要就干了三件事<br>主goroutine -&gt;requestAndChan -&gt;  读循环goroutine<br>主goroutine -&gt;writeRequest-&gt;  写循环goroutine<br>主goroutine 通过select 监听各个channel上的数据， 比如请求取消， timeout，长连接挂了，写流出错，读流出错， 都是其他goroutine 发送过来的， 跟中断一样，然后相应处理，上面也提到了，有些channel是主goroutine通过channel发送给其他goroutine的struct里面包含的channel, 比如 <code>case err := &lt;-writeErrCh:</code>  <code>case re = &lt;-resc:</code> </p>
<p>读循环代码</p>
<pre><code>
func (pc *persistConn) readLoop() {
    
    ... 忽略
    alive := true
    for alive {
        
        ... 忽略
        rc := &lt;-pc.reqch

        var resp *Response
        if err == nil {
            resp, err = ReadResponse(pc.br, rc.req)
            if err == nil &amp;&amp; resp.StatusCode == 100 {
                //100  Continue  初始的请求已经接受，客户应当继续发送请求的其 
                // 余部分
                resp, err = ReadResponse(pc.br, rc.req)
                // 读pc.br（tcp输出流）中的数据，这里的代码在response里面
                //解析statusCode，头字段， 转成标准的内存中的response 类型
                //  http在tcp数据流里面，head和body以 /r/n/r/n分开， 各个头
                // 字段 以/r/n分开
            }
        }

        if resp != nil {
            resp.TLS = pc.tlsState
        }

        ...忽略
        //上面处理一些http协议的一些逻辑行为，
        rc.ch &lt;- responseAndError{resp, err} //把读到的response返回给    
                                             //主goroutine

        .. 忽略
        //忽略部分， 处理cancel req中断， 发送idleConnCh归还pc（持久连接）到持久连接池中（map）    
    pc.close()
}
</code></pre>
<p>无关代码忽略，</p>
<p>这段代码主要干了一件事情<br>读循环goroutine 通过channel requestAndChan 接受主goroutine发送的request(<code>rc := &lt;-pc.reqch</code>), 并从tcp输出流中读取response， 然后反序列化到结构体中， 最后通过channel 返给主goroutine (<code>rc.ch &lt;- responseAndError{resp, err} </code>)</p>
<pre><code>func (pc *persistConn) writeLoop() {
    for {
        select {
        case wr := &lt;-pc.writech:   //接受主goroutine的 request
            if pc.isBroken() {
                wr.ch &lt;- errors.New("http: can't write HTTP request on broken connection")
                continue
            }
            err := wr.req.Request.write(pc.bw, pc.isProxy, wr.req.extra)   //写入tcp输入流
            if err == nil {
                err = pc.bw.Flush()
            }
            if err != nil {
                pc.markBroken()
                wr.req.Request.closeBody()
            }
            pc.writeErrCh &lt;- err 
            wr.ch &lt;- err         //  出错的时候返给主goroutineto 
        case &lt;-pc.closech:
            return
        }
    }
}
</code></pre>
<p>写循环就更简单了， select channel中主gouroutine的request，然后写入tcp输入流<br>如果出错了，channel 通知调用者 </p>
<p>整体看下来， 过程都很简单，但是代码中有很多值得我们学习的地方，比如高并发请求如何复用tcp连接， 这里是连接池的做法， 如果使用多个 goroutine相互协作完成一个http请求， <br>出现错误的时候如何通知调用者中断错误， 代码风格也有很多可以借鉴的地方<br>我打算写一个系列， 全面剖析go标准库里面的精彩之处， 分享给大家</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003735562";}i:14;a:11:{s:5:"title";s:19:"React Server Render";s:4:"link";s:42:"http://segmentfault.com/a/1190000003735257";s:2:"id";s:42:"http://segmentfault.com/a/1190000003735257";s:7:"updated";s:25:"2015-09-11T11:56:31+08:00";s:9:"published";s:25:"2015-09-11T11:56:31+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"小俞";s:10:"author_uri";s:41:"http://segmentfault.com/u/yuyang040160120";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:14735:"
<h1>概述</h1>
<p>一直想用React做些东西，苦于没有实际项目练手，所以一直都是自己在搞些小玩意儿，做过用React Router构建的<a href="https://github.com/yuyang041060120/csfz-food-react">内部订餐系统</a>，是个SPA，也在社区分享过。由于一个人做全栈开发，数据库（mongodb）全靠自己设，需求全靠自己编，页面全靠自己扯，心好累，感觉不会在爱了！<br>SPA用来构建内部的系统完全没问题，但是用来做门户、做电商网站就不行了，为啥？因为SEO，很多的MVVM，MV*框架不能用、不敢用都是基于这个原因（当然也可能因为我不会用）。<br>最近拿CNode的API做了个React服务器端渲染的例子，这里跟大家分享下这个项目的构建过程和代码组织，未必好，主要提供一个思路。</p>
<h1>搭建</h1>
<p><img src="/img/bVpPTW" alt="图片描述" title="图片描述"><br>整体项目目录如上，这里作个说明，附上<a href="https://github.com/yuyang041060120/CNode-React">代码地址</a>，上面有说明怎么使用。</p>
<ul>
<li><p>component 我们的组件目录，这里放置了view、ui等组件</p></li>
<li><p>lib 后端代码，如过滤器等</p></li>
<li><p>node_modules 依赖包</p></li>
<li><p>public 静态资源</p></li>
<li><p>routes 路由</p></li>
</ul>
<p>浏览器端和服务器端的代码我们没必要完全独立，实际上有时候代码是可以复用的。举个例子<br>表单异步提交的时候，后端返回一个state状态告知是否成功，相信大部分的人的第一反应都是抽出常量<br>constants.js</p>
<pre><code>module.exports = {
    state: {
        SUCCESS: 10000
    }     
};</code></pre>
<p>当然了，浏览器端也是要判断这个state的，为了提高代码的复用性，这里同样抽出<br>constants.js</p>
<pre><code>module.exports = {
    state: {
        SUCCESS: 10000
    }     
};</code></pre>
<p>虽然内容相同，实际上这是两个不同的js，分处不同的目录，oh shit。我的开发理念一般是这样的</p>
<blockquote><p>相同的代码坚决不写第二遍，特殊情况除外！</p></blockquote>
<p>采用React后端渲染，我用了webpack打包，实际上就避免了这个问题，写一份constants.js，打包到浏览器端去，NICE！</p>
<h1>编码</h1>
<p>既然是后端渲染，首先得选择一个模板引擎，这里我采用的|
90ee772881e409df0a8a3bb9717d59483
|，具体配置和使用可以参考文档，这里我就不赘述了。既然是构建SPA必不可少得要个路由管理，这里我选择的<a href="https://github.com/rackt/react-router">react-router</a>，react-engine也是兼容react-router的，真棒！拿首页的编码举个例子</p>
<h2>route</h2>
<p>路由我这里用的自己的路由组织<a href="https://github.com/yuyang041060120/express-mapping">express-mapping</a>，看首页的代码<br>routes/index.js</p>
<pre><code>var constants = require('../lib/constants');
var request = require('superagent');
var queryString = require('query-string');

module.exports = {
    get: {
        '/': function (req, res) {
            request
                .get('http://cnodejs.org/api/v1/topics?' + queryString.stringify(req.query))
                .end(function (err, response) {
                    if (err) {
                        throw err;
                    }
                    res.render(req.url, {
                        state: constants.state.SUCCESS,
                        data: response.body.data,
                        title: 'CNode：Node.js专业中文社区'
                    });

                });
        }
    }
};</code></pre>
<p>实际上，res.render方法被我重写了，根据发的请求是不是ajax返回不同的内容<br>lib/filter.js</p>
<pre><code>/**
 * 区分ajax请求与普通请求
 */
req.isXmlHttpRequest = (function () {
    var xRequestedWith = req.headers['x-requested-with'];
    return xRequestedWith &amp;&amp; xRequestedWith.toLowerCase() === 'xmlhttprequest';
})();

/**
 * 重写res.render方法
 */
var render = res.render;

res.render = function (view, data) {
    var response = _.extend({session: req.session}, data);
    req.isXmlHttpRequest ? res.json(response) : render.call(res, view, response);
};</code></pre>
<p>这样我们又做到了接口的复用！</p>
<h2>组件</h2>
<p>来看看我们打包的入口</p>
<h3>component/index.js</h3>
<pre><code>var React = require('react');
var Router = require('react-router');
var $ = require('jquery');
var Routes = require('./routes.jsx');

var CLIENT_VARIABLENAME = '__REACT_ENGINE__';

var _window;
var _document;
if (typeof window !== 'undefined' &amp;&amp; typeof document !== 'undefined') {
    _window = window;
    _document = document;
}

document.addEventListener('DOMContentLoaded', function onLoad() {
    Router.run(Routes, Router.HistoryLocation, function onRouterRun(Root, state) {
        var props = _window[CLIENT_VARIABLENAME];
        if (props) {
            var componentInstance = React.createElement(Root, props);
            React.render(componentInstance, _document);
            _window[CLIENT_VARIABLENAME] = null;
        } else {
            $.get(state.path).then(function (data) {
                var componentInstance = React.createElement(Root, data);
                React.render(componentInstance, _document);
            });
        }

    });
});</code></pre>
<p>后端渲染的原理是这样的，当我们第一访问的时候，node端返回React渲染好的HTML结构，并通过script标签将数据传递到前端，然后在浏览器端获取到传递的数据再渲染一次，总共渲染了两次。当我们在浏览器端进行切换切换的时候，页面是不刷新的，通过ajax请求获取到数据，重新渲染DOM结构。</p>
<h3>component/routes.jsx</h3>
<p>再来看看路由，不熟悉React Router的最好熟悉下，会用到</p>
<pre><code>var React = require('react');
var Router = require('react-router');

var Route = Router.Route;
var DefaultRoute = Router.DefaultRoute;

var App = require('./app.jsx');
var Index = require('./views/index.jsx');

var TopicDetail = require('./views/topic/detail.jsx');
var UserDetail = require('./views/user/detail.jsx');

var routes = (
    &lt;Route handler={App} path="/"&gt;
        &lt;DefaultRoute name="index" handler={Index}/&gt;
        &lt;Route name="topic-detail" path="topic/:topicId" handler={TopicDetail}/&gt;
        &lt;Route name="user-detail" path="user/:loginname" handler={UserDetail}/&gt;
    &lt;/Route&gt;
);

module.exports = routes;</code></pre>
<p>都是些基本的路由配置</p>
<h3>component/app.jsx</h3>
<p>再来看下入口组件</p>
<pre><code>var React = require('react');
var Router = require('react-router');

var Layout = require('./views/layouts/default.jsx');

var RouteHandler = Router.RouteHandler;


module.exports = React.createClass({
    render: function () {
        var data = this.props.data;
        return (
            &lt;Layout title={this.props.title}&gt;
                &lt;RouteHandler data={data}/&gt;
            &lt;/Layout&gt;
        )
    }
});</code></pre>
<p>Layout就是我们的布局了，相同的代码总要抽出来的。</p>
<pre><code>var React = require('react');
var constants=require('../../../lib/constants');

var Footer=require('../partials/footer.jsx');

module.exports = React.createClass({
    render: function render() {
        return (
            &lt;html&gt;
            &lt;head&gt;
                &lt;title&gt;{this.props.title}&lt;/title&gt;
                &lt;meta charSet='utf-8'/&gt;
                &lt;meta name="keywords" content={constants.promotion.keywords}/&gt;
                &lt;meta name="description" content={constants.promotion.description}/&gt;
                &lt;link rel="icon" href="//dn-cnodestatic.qbox.me/public/images/cnode_icon_32.png" type="image/x-icon"/&gt;
                &lt;link rel="stylesheet" href="/css/font-awesome.min.css"/&gt;
                &lt;link rel="stylesheet" href="/css/bootstrap.css"/&gt;
                &lt;link rel="stylesheet" href="/css/style.css"/&gt;
            &lt;/head&gt;
            &lt;body&gt;
            {this.props.children}
            &lt;Footer /&gt;
            &lt;script src="/build/vendor.js"&gt;&lt;/script&gt;
            &lt;script src="/build/bundle.js"&gt;&lt;/script&gt;
            &lt;/body&gt;
            &lt;/html&gt;
        );
    }
});
</code></pre>
<h3>component/views/index.jsx</h3>
<p>这里就是业务代码了</p>
<pre><code>var React = require('react');
var Router = require('react-router');
var $ = require('jquery');
var Navbar = require('./partials/navbar.jsx');
var queryString = require('query-string');
var utils=require('../component/utils');

var Link = Router.Link;


var Label = React.createClass({
    render: function () {
        var tab = this.props.tab;
        var data = this.props.data;

        if (data.top) {
            return &lt;label className="label label-success"&gt;置顶&lt;/label&gt;;
        }

        if (data.good) {
            return &lt;label className="label label-success"&gt;精华&lt;/label&gt;;
        }

        if (!tab || tab === 'all') {
            if (data.tab === 'share') {
                return &lt;label className="label label-default"&gt;分享&lt;/label&gt;;
            }

            if (data.tab === 'ask') {
                return &lt;label className="label label-default"&gt;问答&lt;/label&gt;;
            }

            if (data.tab === 'job') {
                return &lt;label className="label label-default"&gt;招聘&lt;/label&gt;;
            }
        }

        return null;
    }
});

module.exports = React.createClass({
    getInitialState: function () {
        return {
            data: this.props.data || [],
            page: 1
        }
    },
    componentWillReceiveProps: function (nextProps) {
        this.setState({
            data: nextProps.data,
            page: 1
        });
    },
    componentDidMount: function () {
        var loading = false;
        $(window).on('scroll', function () {
            var fromBottom = $(document).height() - $(window).height() - $(window).scrollTop();

            if (fromBottom &lt;= 10 &amp;&amp; !loading) {
                loading = true;
                var query = queryString.parse(location.search);
                query.page = this.state.page + 1;
                $.get(location.pathname + '?' + queryString.stringify(query), function (response) {
                    this.setState({
                        data: this.state.data.concat(response.data),
                        page: this.state.page + 1
                    }, function () {
                        loading = false;
                    });
                }.bind(this));
            }
        }.bind(this));
    },
    render: function () {
        var tab = this.props.query.tab;
        return (
            &lt;div className="index"&gt;
                &lt;Navbar /&gt;

                &lt;div className="container"&gt;
                    &lt;ul className="nav nav-tabs"&gt;
                        &lt;li className={!tab || tab==='all'?'active':''}&gt;
                            &lt;Link to="index" query={{tab:'all'}}&gt;全部&lt;/Link&gt;
                        &lt;/li&gt;
                        &lt;li className={tab==='good'?'active':''}&gt;
                            &lt;Link to="index" query={{tab:'good'}}&gt;精华&lt;/Link&gt;
                        &lt;/li&gt;
                        &lt;li className={tab==='share'?'active':''}&gt;
                            &lt;Link to="index" query={{tab:'share'}}&gt;分享&lt;/Link&gt;
                        &lt;/li&gt;
                        &lt;li className={tab==='ask'?'active':''}&gt;
                            &lt;Link to="index" query={{tab:'ask'}}&gt;问答&lt;/Link&gt;
                        &lt;/li&gt;
                        &lt;li className={tab==='job'?'active':''}&gt;
                            &lt;Link to="index" query={{tab:'job'}}&gt;招聘&lt;/Link&gt;
                        &lt;/li&gt;
                    &lt;/ul&gt;

                    {this.state.data.map(function (item) {
                        return (
                            &lt;div className="media"&gt;
                                &lt;div className="media-left"&gt;
                                    &lt;Link to="user-detail" params={{loginname:item.author.loginname}}&gt;
                                        &lt;img className="media-object" src={item.author.avatar_url} width="40"
                                             heigth="40" title={item.author.loginname}/&gt;
                                    &lt;/Link&gt;
                                &lt;/div&gt;
                                &lt;div className="media-body"&gt;
                                    &lt;h4 className="media-heading"&gt;
                                        &lt;Label tab={tab} data={item}/&gt;
                                        &lt;Link to="topic-detail" params={{topicId:item.id}}&gt;{item.title}&lt;/Link&gt;
                                    &lt;/h4&gt;

                                    &lt;p className="media-count"&gt;
                                        &lt;i className="fa fa-hand-pointer-o"&gt;&lt;/i&gt;{item.visit_count}
                                        &lt;i className="fa fa-comment mg-l-5"&gt;&lt;/i&gt;{item.reply_count}
                                        &lt;i className="fa fa-calendar mg-l-5"&gt;&lt;/i&gt;发表于{utils.getPubDate(item.create_at)}
                                    &lt;/p&gt;
                                &lt;/div&gt;
                            &lt;/div&gt;
                        )
                    }.bind(this))}

                &lt;/div&gt;
            &lt;/div&gt;
        )
    }
});</code></pre>
<p>看个效果<br><img src="/img/bVpPQK" alt="图片描述" title="图片描述"></p>
<h1>小结</h1>
<p>总体来说开发流程还是比较顺利，当然了因为这里没有涉及到登录问题。如果想在实际开发中使用React，有几个问题不得不面对</p>
<ol>
<li><p>对开发者的要求高，至少要熟悉React，React Router，特别是组件的构建，如何提高复用率？这些都是要在前期思考的。多人开发协作下，这个问题尤其尖锐，一个不好就是一锅粥！</p></li>
<li><p>React的第三方组件不够成熟，如果是后端渲染，很多组件不能用，以为它们在代码里直接使用的window、document对象！</p></li>
<li><p>程序是为业务服务的！</p></li>
</ol>
<p>就算这样，我还是想还成为那个吃桃子的人！</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003735257";}i:15;a:11:{s:5:"title";s:47:"ReThought (二): 如何照顾团队中的新人";s:4:"link";s:42:"http://segmentfault.com/a/1190000003734131";s:2:"id";s:42:"http://segmentfault.com/a/1190000003734131";s:7:"updated";s:25:"2015-09-11T08:41:27+08:00";s:9:"published";s:25:"2015-09-11T08:41:27+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"phodal";s:10:"author_uri";s:32:"http://segmentfault.com/u/phodal";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:4996:"
<p>当我们在说照顾的时候，我们实际上是在给新人减压。当我们在说容忍犯错的时候，我们实际上说你可以犯一两个错误。减压更像是在塑造一种更好的学习体验，或者说更愉快地学习方式。</p>
<h2>学习与构建系统</h2>
<p>学校的时候，学习倾向于理论性的学习。</p>
<p>工作的时候，学习倾向于应用性的学习。</p>
<p>两种不同方式有着不同的区别，即一个广度，一个深度。</p>
<p>在构建系统的时候，通常我们需要一个基本能工作的系统，其次在系统不断开发的过程中。我们对于深度了解的需求已经变得比广度更为重要。</p>
<p>故而，在一个以产品为主的开发团队中，在早期他们更需要那些有广度和速度作为支撑的开发人员，在后期则需要以深度作为支撑的开发人员。</p>
<p>两种人才可以在不同的时期发挥着重要的作用。</p>
<h2>学习体验</h2>
<p>在《认知设计》一书中，提到了下面的学习体验，即"流"(Flow)。而在我们学习的过程中，我们也会有类似的学习过程。</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/flow.png" alt="Flow" title="Flow"></p>
<p>如在早期我学习Emcas和GNU/Linux的时候，也曾经放弃过，虽然在当时我已经读过Linux内核。然而，在应用之前进行理论学习并没有卵用。</p>
<p>通常我们会有类似于下面的学习体验，对于一本书来说有下面的体验似乎也是一件很不错的事:</p>
<ol>
<li><p>在最开始学习的时候，我们需要一点理论基础，以及我们需要学点什么。</p></li>
<li><p>然后，我们需要构建一个简单可用的系统，以获取信心。如果我们在这一步没有想象中，那么简单，那么我们可能会放弃学习。或者等到某个时期成熟的时刻，如在我开始学习《设计模式》的时候，那么本书的高度太高了。直到有一天，我了解到了一本叫《Head First设计模式》的书，才重新把GoF的书看了一遍，发现其实也没有想象中的难。</p></li>
<li><p>接着在我完成了某个功能之后，那么我可能继续学习某个理论，用于支撑我的下一步计划。</p></li>
<li><p>在那之后，我觉得这一步可能也不是那么难，因为已经有了前面的基础。如果在一步失败的时候，那么我们可能会继续寻找某些可靠的方案，又或者是理论支撑。</p></li>
<li><p>。。。</p></li>
<li><p>直到有一天，我们来到了一个瓶颈的前面，现有的方案已经不满足我们的需求。对于这个问题，我们可能已经没有一个更好的解决方案。于是，我们可能就需要创建一个轮子，只是在这时，我们不知道怎样去造轮子。</p></li>
<li><p>于是我们开始学习造轮子。</p></li>
<li><p>....</p></li>
</ol>
<p>只有当我们保持一个学习的过程，才会让我们在这一步步的计划中不会退缩，也不能退缩。</p>
<h2>如何照顾团队中的新人</h2>
<p>在前面，我们已经说了足够多的废话，来支撑我们的标题。</p>
<p>在上篇<a href="https://www.phodal.com/blog/rethink-one-build-dream-team/">《如何构建理想的开发团队》</a>中我们说到了一点，即结对编程。在结对编程中会存在至少三种模式:</p>
<ol>
<li><p>Coach模式。在我现有的经验里，这个模式对新人会帮助比较大。通常来说，我们是要分解任务，然后带领新人一步步完成任务。或许你注意到就是上文中说到的那个心流的过程。在这个过程中，很容易明白这是怎样的情况。</p></li>
<li><p>导航模式。在一步中，有经验的人更多的是充当观察模式。有时，当新人不知道往哪个方向就知道提示。当新人犯错时，<strong>最好</strong>看着ta犯错。</p></li>
<li><p>Pair模式。理想的结对编程便是在这样的模式之中。而要达成这样的目标需要两个人之间有很好的默契，以及在某方面相接近的能力。在一步中，如果可以平衡好两人的步骤，那么对新人的自信心想必是有很大的帮助。</p></li>
</ol>
<p>采用结对编程不仅可以提高新人的水平，对于老人的能力也是很大输出。即之前别人输入我们脑子中的想法，我们需要再传递出来。对于程序员这一类人必然会有很大的提高，如果你不擅长表达的话。</p>
<h3>结论</h3>
<p>所以，我们所说的照顾实际上是一个更好的学习体验。</p>
<ol>
<li><p>最开始的时候教会如何细分任务，并带领他学习</p></li>
<li><p>给他指导，让他自己完成工作。</p></li>
</ol>
<p>很我时候，我们总是局限于第二步，故而无法更好地指导他们完成工作。</p>
<p>转载保留: <a href="https://www.phodal.com/blog/rethink-one-help-new-hire/">ReThought (二): 如何照顾团队中的新人</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003734131";}i:16;a:11:{s:5:"title";s:52:"回溯法解决N皇后问题（以四皇后为例）";s:4:"link";s:42:"http://segmentfault.com/a/1190000003733325";s:2:"id";s:42:"http://segmentfault.com/a/1190000003733325";s:7:"updated";s:25:"2015-09-10T22:36:08+08:00";s:9:"published";s:25:"2015-09-10T22:36:08+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"xumenger";s:10:"author_uri";s:34:"http://segmentfault.com/u/xumenger";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:6170:"
<p>以4皇后为例，其他的N皇后问题以此类推。所谓4皇后问题就是求解如何在4×4的棋盘上无冲突的摆放4个皇后棋子。在国际象棋中，皇后的移动方式为横竖交叉的，因此在任意一个皇后所在位置的水平、竖直、以及45度斜线上都不能出现皇后的棋子，例子<br><img src="/img/bVpPmO" alt="图片描述" title="图片描述"></p>
<p>要求编程求出符合要求的情况的个数。四皇后问题有很多种解法，这里主要介绍一种经典的解决方法：回溯法</p>
<p>回溯法的基本思想是：可以构建出一棵解空间树，通过探索这棵解空间树，可以得到四皇后问题的一种或几种解。这样的解空间树有四棵</p>
<p>在如上图所示的4×4的棋盘上，按列来摆放棋子，首先因为皇后棋子不能在同一列，所以先排除有2个或2个以上的棋子在同一列的情况，所以第一个棋子在第一列有4种摆放方法（第1列第1行，第1列第2行，第1列第3行，第1列第4行），同样第二个棋子在第二列有4种，同样第三个棋子在第三列有4种，同样第四个棋子在第四列有4种，所以进行简单的排除不在同一列的情况后，还有4×4×4×4=256种可能，但是在这256种可能里，依然存在比如棋子在同一行，或在45度斜线上的情况出现。另一个角度思考，所有的满足四皇后问题的摆放方式一定都存在于这256种情况之中。简单的理解就是：这256种棋盘局面包含了所有满足4皇后问题的解，但是不包含全部的棋盘局面。</p>
<p>下面是解空间树的示例（以上一段的按列摆放的方式来进行示例讲解），其中第i层的棋盘局面是在第i-1层的棋盘局面演化而来的（1&lt;i&lt;4）<br><img src="/img/bVpPmV" alt="图片描述" title="图片描述"></p>
<p>上面的图片是以第一个棋子在第一列的第一行而派生出的一个解空间树，最后一层会有64中结局面，同理在以第一个棋子在第一、列的第二/三/四行都分别可以派生出一个解空间树，最后一层都会有64中局面，所以有4棵解空间树，每一棵最终有64个局面，所以一共有4×64=256种局面</p>
<p>可以用上面的方法穷举出所有的解，再遍历穷举的所有结果找出所有符合四皇后问题的解，但是这样会很浪费。所以这里可以用到回溯法，在构建解空间树的途中进行深度优先探索，当探索到某一种棋盘局面一定不是四皇后问题的解的时候（比如出现任意两个或两个以上的棋子在同一行/同一列/45度斜线上），就可以判断这个节点向下派生出的解空间树的节点也一定不是四皇后问题的解，这样就可以避免大量的无用功。</p>
<p>比如上图中第二行的第一个节点出现了两个棋子在同一行的情况，所以可以判断出这个节点以及这个节点向下派生出的所有节点就不再有必要进行遍历了，这样就会避免4+4×4次的完全无用功的遍历，就会大大的节省时间，再去探索第二行的第二个节点……其他的同理。</p>
<p>这样，如果能够成功遍历到叶子节点，并且判断该叶子节点的局面就是符合4皇后问题的，那么这个节点局面就代表一个合法的四皇后问题的解。下面的图片就代表找到的一个合法的解的过程（注意图片中，虚线代表排除，黑实线代表继续向下探索）     以上图为例，当在第i层出现非法的棋盘局面时，就跳回第i-1层，继续探索第i-1层的那个节点的下一个分支；或者在第4层探索到合法的局面就进行记录并跳回上一层，继续探索下一个分支。其他三个解空间树同理。<br><img src="/img/bVpPmZ" alt="图片描述" title="图片描述"></p>
<p>以上图为例，就单看探索的第四层节点的个数。使用回溯法，就只需探索第4层中的4个节点，而如果使用穷举法，就要探索玩第4层的所有64个节点，显而易见，哪一个方法更有效。</p>
<p>其实在解决四皇后问题的时候，并不一定要真的构建出这样的一棵解空间树，它完全可以通过一个递归回溯来模拟。所谓的解空间树只是一个逻辑上的抽象。当然也可以用树结构来真实的创建出一棵解空间树，不过那样会比较浪费空间资源，也没有那个必要</p>
<p>解决四皇后问题的算法描述如下</p>
<pre><code>#include&lt;stdio.h&gt;

int count = 0;
int isCorrect(int i, int j, int (*Q)[4])
{
    int s, t;
    for(s=i,t=0; t&lt;4; t++)
        if(Q[s][t]==1 &amp;&amp; t!=j)
            return 0;//判断行
    for(t=j,s=0; s&lt;4; s++)
        if(Q[s][t]==1 &amp;&amp; s!=i)
            return 0;//判断列
    for(s=i-1,t=j-1; s&gt;=0&amp;&amp;t&gt;=0; s--,t--)
        if(Q[s][t]==1)
            return 0;//判断左上方
    for(s=i+1,t=j+1; s&lt;4&amp;&amp;t&lt;4;s++,t++)
        if(Q[s][t]==1)
            return 0;//判断右下方
    for(s=i-1,t=j+1; s&gt;=0&amp;&amp;t&lt;4; s--,t++)
        if(Q[s][t]==1)
            return 0;//判断右上方
    for(s=i+1,t=j-1; s&lt;4&amp;&amp;t&gt;=0; s++,t--)
        if(Q[s][t]==1)
            return 0;//判断左下方

    return 1;//否则返回
}

void Queue(int j, int (*Q)[4])
{
    int i,k;
    if(j==4){//递归结束条件
        for(i=0; i&lt;4; i++){
                //得到一个解，在屏幕上显示
            for(k=0; k&lt;4; k++)
                printf("%d ", Q[i][k]);
            printf("\n");
        }
        printf("\n");
        count++;
        return ;
    }
    for(i=0; i&lt;4; i++){
        if(isCorrect(i, j, Q)){//如果Q[i][j]可以放置皇后
            Q[i][j]=1;//放置皇后
            Queue(j+1, Q);//递归深度优先搜索解空间树
            Q[i][j]=0;//这句代码就是实现回溯到上一层
        }
    }
}

int main()
{
    int Q[4][4];
    int i, j;
    for(i=0; i&lt;4; i++)
        for(j=0; j&lt;4; j++)
            Q[i][j] = 0;
    Queue(0, Q);
    printf("The number of the answers are %d\n", count);
    return 0;
}
</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003733325";}i:17;a:11:{s:5:"title";s:36:"js 函数式编程之函数柯里化";s:4:"link";s:42:"http://segmentfault.com/a/1190000003733107";s:2:"id";s:42:"http://segmentfault.com/a/1190000003733107";s:7:"updated";s:25:"2015-09-10T21:29:24+08:00";s:9:"published";s:25:"2015-09-10T21:29:24+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"honger05";s:10:"author_uri";s:34:"http://segmentfault.com/u/honger05";s:2:"re";a:1:{s:4:"rank";s:1:"2";}s:7:"summary";s:4281:"
<p>函数柯里化是指参数逐渐求值的过程。</p>
<p>我觉得它是：降低通用性，提高专用性。</p>
<blockquote><p>通常，柯里化是这样的过程，“如果你固定某些参数，你将得到接受余下参数的一个函数”。所以对于有两个变量的函数y^x，如果固定了 y=2，则得到有一个变量的函数 2^x</p></blockquote>
<p>通用实现</p>
<pre><code class="js">function currying(fn) {
  var slice = Array.prototype.slice;
    var args = alice.call(arguments, 1);
    return function() {
    var innerArgs = slice.call(arguments);
    var finalArgs = args.concat(innerArgs);
    return fn.apply(null, finalArgs);
  }
}</code></pre>
<p>先看一个简单的例子</p>
<pre><code class="js">function add(num1, num2) {
    return num1 + num2;
}

function curryAdd(num) {
    return num + 5;
}

add(2, 4); // 6
curryAdd(1); // 6</code></pre>
<p><code>curryAdd</code> 显然不是一个柯里化的实现。但是它很好的诠释了柯里化的思想。<code>add 函数有两个参数，curryAdd 固定了其中一个参数</code></p>
<hr>
<p>用上面 <code>currying</code> 函数构造 <code>curryAdd</code> 函数。</p>
<pre><code class="js">var curryAdd5 = currying(add, 5);

var curryAdd4 = currying(add, 4);

curryAdd5(1); // 6

curryAdd4(1); // 5</code></pre>
<p>再看一个经典的 ajax 例子。</p>
<pre><code class="js">function Ajax() {
    this.xhr = new XMLHttpRequest();
}

Ajax.prototype.open = function(type, url, data, callback) {
    this.onload = function() {
    callback(this.xhr.responseText, this.xhr.status, thix.xhr);
  }

  this.xhr.open(type, url, data.async);
  this.xhr.send(data.paras);
}

['get', 'post'].forEach(function(type) {
    Ajax.prototype[type] = currying(Ajax.prototype.open, type);
})

var xhr = new Ajax();

xhr.get('/articles/list', {}, function(datas) {});

xhr.post('/articles/add', {}, function(datas) {});</code></pre>
<p><code>get</code> <code>post</code> 两个方法是通过 'open' 方法衍生出来的。</p>
<blockquote><p>从一个通用的 open 函数（可接受任意type），柯里化成专用的函数 get、post。</p></blockquote>
<hr>
<h3>固定易变因数</h3>
<p>提前把易变因数固定下来，生成一个更明确的应用函数，最典型的代码就是 ES5 定义的 Function.prototype.bing 函数</p>
<pre><code class="js">Function.prototype.bing = function(context) {
    var _this = this,
        slice = Array.prototype.slice,
        _args = slice.call(arguments, 1);

    return function() {
        return _this.apply(context, _args.concat(slice.call(arguments)))
    }
}</code></pre>
<hr>
<h3>延迟执行</h3>
<p>不断的柯里化，累积传入的参数，最后执行。</p>
<pre><code class="js">function add() {
  var sum = 0, i, len;
    for (i = 0, len = arguments.length; i &lt; len; i++) {
    sum += arguments[i];
  }
  return sum;
}

var currying = function(fn) {
    var _args = [];

    return function cb() {
        if (arguments.length === 0) {
            return fn.apply(this, _args);
        }

        Array.prototype.push.apply(_args, arguments);

        return cb;
    }
}

var curryingAdd = currying(add);

curryingAdd(1)(2)(3)(4)(); // 10

var add321 = curryingAdd(3)(2, 1);

add321(4)(); // 10</code></pre>
<hr>
<h3>性能</h3>
<p>柯里化肯定会有一些开销（函数嵌套，比普通函数占更多内存），但性能瓶颈首先来自其它原因（DOM 操作等）。</p>
<p>从另外一个角度分析，不管你用不用柯里化这个思维，你的代码很可能已经步入了更复杂的模式，会有更大的开销。</p>
<p>有关性能的一些事：</p>
<ul>
<li><p>存取 arguments 对象通常要比存取命名参数要慢一些。</p></li>
<li><p>一些老版本的浏览器在 arguments.length 的实现上相当慢。</p></li>
<li><p>使用 fn.apply() 和 fn.call() 要比直接调用 fn() 要慢点。</p></li>
<li><p>创建大量嵌套作用域和闭包会带来开销，无论是内容还是速度上。</p></li>
<li><p>大多数瓶颈来自 DOM 操作</p></li>
</ul>
<hr>
<h3>总结</h3>
<p>柯里化是以逻辑学家哈斯凯尔·加里命名的，</p>
<p>正如它的命名一样，函数柯里化给我们带来的是：解决问题的一种逻辑思维方式。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003733107";}i:18;a:11:{s:5:"title";s:38:" Linux gdb调试器用法全面解析 ";s:4:"link";s:42:"http://segmentfault.com/a/1190000003733061";s:2:"id";s:42:"http://segmentfault.com/a/1190000003733061";s:7:"updated";s:25:"2015-09-10T21:17:38+08:00";s:9:"published";s:25:"2015-09-10T21:17:38+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"xumenger";s:10:"author_uri";s:34:"http://segmentfault.com/u/xumenger";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:21744:"
<p>转载自：<a href="http://blog.csdn.net/21cnbao/article/details/7385161">Linux gdb调试器用法全面解析</a> </p>
<p>GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具，GDB主要可帮助工程师完成下面4个方面的功能：</p>
<ul>
<li><p>启动程序，可以按照工程师自定义的要求随心所欲的运行程序。</p></li>
<li><p>让被调试的程序在工程师指定的断点处停住，断点可以是条件表达式。</p></li>
<li><p>当程序被停住时，可以检查此时程序中所发生的事，并追索上文。</p></li>
<li><p>动态地改变程序的执行环境。</p></li>
</ul>
<p>不管是调试Linux内核空间的驱动还是调试用户空间的应用程序，掌握gdb的用法都是必须。而且，调试内核和调试应用程序时使用的gdb命令是完全相同的，下面以代码清单22.2的应用程序为例演示gdb调试器的用法。</p>
<pre><code>1  int add(int a, int b)  
2  {  
3    return a + b;  
4  }  
5    
6  main()  
7  {  
8    int sum[10] =   
9    {  
10     0, 0, 0, 0, 0, 0, 0, 0, 0, 0       
11   }  ;  
12   int i;  
13     
14   int array1[10] =  
15   {  
16     48, 56, 77, 33, 33, 11, 226, 544, 78, 90  
17   };  
18   int array2[10] =  
19   {  
20     85, 99, 66, 0x199, 393, 11, 1, 2, 3, 4  
21   };  
22   
23   for (i = 0; i &lt; 10; i++)  
24   {  
25     sum[i] = add(array1[i], array2[i]);  
26   }  
27 }  
</code></pre>
<p>使用命令gcc –g gdb_example.c –o gdb_example编译上述程序，得到包含调试信息的二进制文件example，执行gdb gdb_example命令进入调试状态：</p>
<pre><code>[root@localhost driver_study]# gdb gdb_example  
GNU gdb Red Hat Linux (5.3post-0.20021129.18rh)  
Copyright 2003 Free Software Foundation, Inc.  
GDB is free software, covered by the GNU General Public License, and you are  
welcome to change it and/or distribute copies of it under certain conditions.  
Type "show copying" to see the conditions.  
There is absolutely no warranty for GDB.  Type "show warranty" for details.  
This GDB was configured as "i386-redhat-linux-gnu"...  
(gdb)  
</code></pre>
<h2>list命令</h2>
<p>在gdb中运行list命令（缩写l）可以列出代码，list的具体形式包括：</p>
<ul><li><p><code>list &lt;linenum&gt;</code> ，显示程序第linenum行周围的源程序，如：</p></li></ul>
<pre><code>    (gdb) list 15  
    10          
    11        int array1[10] =  
    12        {  
    13          48, 56, 77, 33, 33, 11, 226, 544, 78, 90  
    14        };  
    15        int array2[10] =  
    16        {  
    17          85, 99, 66, 0x199, 393, 11, 1, 2, 3, 4  
    18        };  
    19  </code></pre>
<ul><li><p><code>list &lt;function&gt;</code>，显示函数名为function的函数的源程序，如：</p></li></ul>
<pre><code>    (gdb) list main  
    2       {  
    3         return a + b;  
    4       }  
    5  
    6       main()  
    7       {  
    8         int sum[10];  
    9         int i;  
    10          
    11        int array1[10] =  </code></pre>
<ul>
<li><p><code>list</code>，显示当前行后面的源程序。</p></li>
<li><p><code>list -</code> ，显示当前行前面的源程序。</p></li>
</ul>
<p>下面演示了使用gdb中的<code>run</code>（缩写r）、<code>break</code>（缩写b）、<code>next</code>（缩写n）命令控制程序的运行，并使用<code>print</code>（缩写p）命令打印程序中的变量sum的过程：</p>
<pre><code>(gdb) break add
Breakpoint 1 at 0x80482f7: file gdb_example.c, line 3.
(gdb) run  
Starting program: /driver_study/gdb_example 

Breakpoint 1, add (a=48, b=85) at gdb_example.c:3
warning: Source file is more recent than executable.

3         return a + b;
(gdb) next
4       }
(gdb) next
main () at gdb_example.c:23
23        for (i = 0; i &lt; 10; i++)
(gdb) next
25          sum[i] = add(array1[i], array2[i]);
(gdb) print sum
$1 = {133, 0, 0, 0, 0, 0, 0, 0, 0, 0}
</code></pre>
<h2>run命令</h2>
<p>在gdb中，运行程序使用run命令。在程序运行前，我们可以设置如下4方面的工作环境：</p>
<ul><li><p>程序运行参数</p></li></ul>
<p><code>set args</code> 可指定运行时参数，如：<code>set args 10 20 30 40 50</code>；<code>show args</code> 命令可以查看设置好的运行参数。</p>
<ul><li><p>运行环境</p></li></ul>
<p><code>path &lt;dir&gt;</code> 可设定程序的运行路径；how paths可查看程序的运行路径；set environment varname [=value]用于设置环境变量，如set env USER=baohua；</p>
<p><code>show environment [varname]</code>则用于查看环境变量。</p>
<ul><li><p>工作目录</p></li></ul>
<p><code>cd &lt;dir&gt;</code> 相当于shell的cd命令；pwd 显示当前所在的目录。</p>
<ul><li><p>程序的输入输出</p></li></ul>
<p><code>info terminal</code> 用于显示程序用到的终端的模式；gdb中也可以使用重定向控制程序输出，如<code>run &gt; outfile</code>；</p>
<p><code>tty</code>命令可以指定输入输出的终端设备，如：<code>tty /dev/ttyS1</code>。</p>
<h2>break命令</h2>
<p>在gdb中用break命令来设置断点，设置断点的方法包括：</p>
<ul><li><p><code>break &lt;function&gt;</code></p></li></ul>
<p>在进入指定函数时停住，C++中可以使用class::function或function(type, type)格式来指定函数名。</p>
<ul><li><p><code>break &lt;linenum&gt; </code></p></li></ul>
<p>在指定行号停住。</p>
<ul><li><p><code>break +offset / break -offset</code></p></li></ul>
<p>在当前行号的前面或后面的offset行停住，offiset为自然数。</p>
<ul><li><p><code>break filename:linenum</code></p></li></ul>
<p>在源文件filename的linenum行处停住。</p>
<ul><li><p><code>break filename:function</code></p></li></ul>
<p>在源文件filename的function函数的入口处停住。</p>
<ul><li><p><code>break *address</code></p></li></ul>
<p>在程序运行的内存地址处停住。</p>
<ul><li><p><code>break</code></p></li></ul>
<p>break命令没有参数时，表示在下一条指令处停住。</p>
<ul><li><p><code>break ... if &lt;condition&gt;</code></p></li></ul>
<p>“...”可以是上述的<code>break &lt;linenum&gt;</code>、<code>break +offset</code>、<code>break –offset</code>中的参数，condition表示条件，在条件成立时停住。比如在循环体中，可以设置break if i=100，表示当i为100时停住程序。</p>
<p>查看断点时，可使用info命令，如<code>info breakpoints [n]</code>、<code>info break [n]</code>（n表示断点号）。</p>
<h2>单步命令</h2>
<p>在调试过程中，<code>next</code>命令用于单步执行，类似VC++中的step over。next的单步不会进入函数的内部，与<code>next</code>对应的<code>step</code>（缩写s）命令则在单步执行一个函数时，会进入其内部，类似VC++中的step into。下面演示了step命令的执行情况，在23行的add()函数调用处执行step会进入其内部的“return a+b;”语句：</p>
<pre><code>(gdb) break 25  
Breakpoint 1 at 0x8048362: file gdb_example.c, line 25.  
(gdb) run  
Starting program: /driver_study/gdb_example   
  
Breakpoint 1, main () at gdb_example.c:25  
25          sum[i] = add(array1[i], array2[i]);  
(gdb) step  
add (a=48, b=85) at gdb_example.c:3  
3         return a + b;  
</code></pre>
<p>单步执行的更复杂用法包括：</p>
<ul><li><p><code>step &lt;count&gt;</code></p></li></ul>
<p>单步跟踪，如果有函数调用，则进入该函数（进入函数的前提是，此函数被编译有debug信息）。step后面不加count表示一条条地执行，加表示执行后面的count条指令，然后再停住。</p>
<ul><li><p><code>next &lt;count&gt;</code></p></li></ul>
<p>单步跟踪，如果有函数调用，它不会进入该函数。同样地，next后面不加count表示一条条地执行，加表示执行后面的count条指令，然后再停住。</p>
<ul><li><p><code>set step-mode</code></p></li></ul>
<p>set step-mode on用于打开step-mode模式，这样，在进行单步跟踪时，程序不会因为没有debug信息而不停住，这个参数的设置可便于查看机器码。set step-mod off用于关闭step-mode模式。</p>
<ul><li><p><code>finish</code></p></li></ul>
<p>运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。</p>
<ul><li><p><code>until</code> （缩写u）</p></li></ul>
<p>一直在循环体内执行单步，退不出来是一件令人烦恼的事情，until命令可以运行程序直到退出循环体。</p>
<ul><li><p><code>stepi</code>（缩写<code>si</code>）和<code>nexti</code>（缩写<code>ni</code>）</p></li></ul>
<p>stepi和nexti用于单步跟踪一条机器指令，一条程序代码有可能由数条机器指令完成，stepi和nexti可以单步执行机器指令。 另外，运行“display/i $pc”命令后，单步跟踪会在打出程序代码的同时打出机器指令，即汇编代码。</p>
<h2>continue命令</h2>
<p>当程序被停住后，可以使用continue命令（缩写c，fg命令同continue命令）恢复程序的运行直到程序结束，或到达下一个断点，命令格式为：</p>
<pre><code>continue [ignore-count]  
c [ignore-count]  
fg [ignore-count]  
</code></pre>
<p>ignore-count表示忽略其后多少次断点。 假设我们设置了函数断点add()，并watch i，则在continue过程中，每次遇到add()函数或i发生变化，程序就会停住，如：</p>
<pre><code>(gdb) continue  
Continuing.  
Hardware watchpoint 3: i  
  
Old value = 2  
New value = 3  
0x0804838d in main () at gdb_example.c:23  
23        for (i = 0; i &lt; 10; i++)  
(gdb) continue  
Continuing.  
  
Breakpoint 1, main () at gdb_example.c:25  
25          sum[i] = add(array1[i], array2[i]);  
(gdb) continue  
Continuing.  
Hardware watchpoint 3: i  
  
Old value = 3  
New value = 4  
0x0804838d in main () at gdb_example.c:23  
23        for (i = 0; i &lt; 10; i++)  
</code></pre>
<h2>print命令</h2>
<p>在调试程序时，当程序被停住时，可以使用print命令（缩写为p），或是同义命令inspect来查看当前程序的运行数据。print命令的格式是：</p>
<pre><code>print &lt;expr&gt;  
print /&lt;f&gt; &lt;expr&gt;  
</code></pre>
<p><code>&lt;expr&gt;</code>是表达式，是被调试的程序中的表达式，<code>&lt;f&gt;</code>是输出的格式，比如，如果要把表达式按16进制的格式输出，那么就是/x。在表达式中，有几种GDB所支持的操作符，它们可以用在任何一种语言中，“@”是一个和数组有关的操作符，“::”指定一个在文件或是函数中的变量，<code>“{&lt;type&gt;} &lt;addr&gt;”</code>表示一个指向内存地址<code>&lt;addr&gt;</code>的类型为type的一个对象。</p>
<p>下面演示了查看sum[]数组的值的过程：</p>
<pre><code>(gdb) print sum  
$2 = {133, 155, 0, 0, 0, 0, 0, 0, 0, 0}  
(gdb) next  
  
Breakpoint 1, main () at gdb_example.c:25  
25          sum[i] = add(array1[i], array2[i]);  
(gdb) next  
23        for (i = 0; i &lt; 10; i++)  
(gdb) print sum  
$3 = {133, 155, 143, 0, 0, 0, 0, 0, 0, 0}  
</code></pre>
<p>当需要查看一段连续内存空间的值的时间，可以使用GDB的“@”操作符，“@”的左边是第一个内存地址，“@”的右边则是想查看内存的长度。例如如下动态申请的内存：</p>
<pre><code>int *array = (int *) malloc (len * sizeof (int));
</code></pre>
<p>在GDB调试过程中这样显示出这个动态数组的值：<code>p *array@len</code></p>
<p>print的输出格式包括：</p>
<ul>
<li><p>x 按十六进制格式显示变量。</p></li>
<li><p>d 按十进制格式显示变量。</p></li>
<li><p>u 按十六进制格式显示无符号整型。</p></li>
<li><p>o 按八进制格式显示变量。</p></li>
<li><p>t 按二进制格式显示变量。</p></li>
<li><p>a 按十六进制格式显示变量。</p></li>
<li><p>c 按字符格式显示变量。</p></li>
<li><p>f 按浮点数格式显示变量。</p></li>
</ul>
<p>我们可用<code>display</code>命令设置一些自动显示的变量，当程序停住时，或是单步跟踪时，这些变量会自动显示。 如果要修改变量，如x的值，可使用如下命令：<code>print x=4</code></p>
<p>当用GDB的print查看程序运行时的数据时，每一个print都会被GDB记录下来。GDB会以$1，$2，$3 …这样的方式为每一个print命令编号。我们可以使用这个编号访问以前的表达式，如$1。</p>
<h2>watch命令</h2>
<p>watch一般来观察某个表达式（变量也是一种表达式）的值是否有变化了，如果有变化，马上停住程序。我们有下面的几种方法来设置观察点：</p>
<ul>
<li><p><code>watch &lt;expr&gt;</code>：为表达式（变量）expr设置一个观察点。一量表达式值有变化时，马上停住程序。</p></li>
<li><p><code>rwatch &lt;expr&gt;</code>：当表达式（变量）expr被读时，停住程序。</p></li>
<li><p><code>awatch &lt;expr&gt;</code>：当表达式（变量）的值被读或被写时，停住程序。info watchpoints：列出当前所设置了的所有观察点。</p></li>
</ul>
<p>下面演示了观察i并在连续运行next时一旦发现i变化，i值就会显示出来的过程：</p>
<pre><code>(gdb) watch i  
Hardware watchpoint 3: i  
(gdb) next  
23        for (i = 0; i &lt; 10; i++)  
(gdb) next  
Hardware watchpoint 3: i  
  
Old value = 0  
New value = 1  
0x0804838d in main () at gdb_example.c:23  
23        for (i = 0; i &lt; 10; i++)  
(gdb) next  
  
Breakpoint 1, main () at gdb_example.c:25  
25          sum[i] = add(array1[i], array2[i]);  
(gdb) next  
23        for (i = 0; i &lt; 10; i++)  
(gdb) next  
Hardware watchpoint 3: i  
  
Old value = 1  
New value = 2  
0x0804838d in main () at gdb_example.c:23  
23        for (i = 0; i &lt; 10; i++)  
</code></pre>
<h2>examine命令</h2>
<p>我们可以使用<code>examine命令</code>（缩写为x）来查看内存地址中的值。examine命令的语法如下所示：</p>
<p><code>x/&lt;n/f/u&gt; &lt;addr&gt;</code> </p>
<p><code>&lt;addr&gt;</code>表示一个内存地址。“x/”后的n、f、u都是可选的参数，n 是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容；f 表示显示的格式，如果地址所指的是字符串，那么格式可以是s，如果地址是指令地址，那么格式可以是i；u 表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4字节。u参数可以被一些字符代替：b表示单字节，h表示双字节，w表示四字节，g表示八字节。当我们指定了字节长度后，GDB会从指定的内存地址开始，读写指定字节，并把其当作一个值取出来。n、f、u这3个参数可以一起使用，例如命令“x/3uh 0x54320”表示从内存地址0x54320开始以双字节为1个单位（h）、16进制方式（u）显示3个单位（3）的内存。 ==</p>
<p>譬如下面的例子：</p>
<pre><code>main()  
{  
        char *c = "hello world";  
        printf("%s\n", c);  
}  
</code></pre>
<p>我们在</p>
<pre><code>char *c = "hello world";  
</code></pre>
<p>下一行设置断点后：</p>
<pre><code>(gdb) l  
1    main()  
2    {  
3        char *c = "hello world";  
4        printf("%s\n", c);  
5    }  
(gdb) b 4  
Breakpoint 1 at 0x100000f17: file main.c, line 4.  
(gdb) r  
Starting program: /Users/songbarry/main  
Reading symbols for shared libraries +. done  
  
Breakpoint 1, main () at main.c:4  
4        printf("%s\n", c);  
</code></pre>
<p>可以通过多种方式看C指向的字符串：</p>
<ul>
<li>
<p>方法1：</p>
<pre><code>(gdb) p c  
$1 = 0x100000f2e "hello world"  
</code></pre>
</li>
<li>
<p>方法2：</p>
<pre><code>(gdb) x/s 0x100000f2e  
0x100000f2e:     "hello world"  
</code></pre>
</li>
<li>
<p>方法3：</p>
<pre><code>(gdb) p (char *)0x100000f2e  
$3 = 0x100000f2e "hello world"  
</code></pre>
</li>
<li>
<p>将第一个字符改为大写：</p>
<pre><code>(gdb) p *(char *)0x100000f2e='H'  
$4 = 72 'H'  
</code></pre>
</li>
<li>
<p>再看看C：</p>
<pre><code>(gdb) p c  
$5 = 0x100000f2e "Hello world"  
</code></pre>
</li>
</ul>
<h2>set命令</h2>
<ul>
<li>
<p>修改寄存器：</p>
<pre><code>(gdb) set $v0 = 0x004000000  
(gdb) set $epc = 0xbfc00000   
</code></pre>
</li>
<li>
<p>修改内存：</p>
<pre><code>(gdb) set {unsigned int}0x8048a51=0x0  
</code></pre>
</li>
<li>
<p>譬如对于第8节的例子：</p>
<pre><code>(gdb) set {unsigned int}0x100000f2e=0x0         
(gdb) x/10cb 0x100000f2e  
0x100000f2e:    0 '\0'  0 '\0'  0 '\0'  0 '\0'  111 'o' 32 ' '  119 'w' 111 'o'  
0x100000f36:    114 'r' 108 'l'  
(gdb) p c  
$10 = 0x100000f2e ""  
</code></pre>
</li>
</ul>
<h2>jump命令</h2>
<p>一般来说，被调试程序会按照程序代码的运行顺序依次执行，但是GDB也提供了乱序执行的功能，也就是说，GDB可以修改程序的执行顺序，从而让程序随意跳跃。这个功能可以由GDB的jump命令：<code>jump &lt;linespec&gt;</code> 来指定下一条语句的运行点。<code>&lt;linespec&gt;</code>可以是文件的行号，可以是<code>file:line</code>格式，也可以是+num这种偏移量格式，表示下一条运行语句从哪里开始。<code>jump &lt;address&gt;</code> 这里的<code>&lt;address&gt;</code>是代码行的内存地址。 注意，jump命令不会改变当前的程序栈中的内容，所以，如果使用jump从一个函数跳转到另一个函数，当跳转到的函数运行完返回，进行出栈操作时必然会发生错误，这可能导致意想不到的结果，所以最好只用jump在同一个函数中进行跳转。</p>
<h2>signal命令</h2>
<p>使用singal命令，可以产生一个信号量给被调试的程序，如中断信号“Ctrl+C”。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号的方法非常有利于程序的调试。 signal命令的语法是：<code>signal &lt;signal&gt;</code>，UNIX的系统信号量通常从1到15，所以<code>&lt;signal&gt;</code>取值也在这个范围。</p>
<h2>return命令</h2>
<p>如果在函数中设置了调试断点，在断点后还有语句没有执行完，这时候我们可以使用return命令强制函数忽略还没有执行的语句并返回。</p>
<pre><code>return  
return &lt;expression&gt;  
</code></pre>
<p>上述return命令用于取消当前函数的执行，并立即返回，如果指定了<code>&lt;expression&gt;</code>，那么该表达式的值会被作为函数的返回值。</p>
<h2>call命令</h2>
<p>call命令用于强制调用某函数： <code>call &lt;expr&gt;</code> 表达式中可以一是函数，以此达到强制调用函数的目的，它会显示函数的返回值（如果函数返回值不是void）。 其实，前面介绍的print命令也可以完成强制调用函数的功能。</p>
<h2>info命令</h2>
<p>info命令可以在调试时用来查看寄存器、断点、观察点和信号等信息。要查看寄存器的值，可以使用如下命令：</p>
<ul>
<li><p><code>info registers</code> （查看除了浮点寄存器以外的寄存器）</p></li>
<li><p><code>info all-registers</code> （查看所有寄存器，包括浮点寄存器）</p></li>
<li><p><code>info registers &lt;regname ...&gt;</code> （查看所指定的寄存器）</p></li>
</ul>
<p>要查看断点信息，可以使用如下命令：</p>
<ul>
<li><p><code>info break</code> 列出当前所设置的所有观察点</p></li>
<li><p>使用如下命令：<code>info watchpoints</code> 查看有哪些信号正在被GDB检测</p></li>
<li><p>使用如下命令：<code>info signals info handle</code> 也可以使用<code>info line</code>命令来查看源代码在内存中的地址。</p></li>
<li>
<p><code>info threads</code>可以看多线程。<code>info line</code>后面可以跟行号、函数名、文件名:行号、文件名:函数名等多种形式，例如下面的命令会打印出所指定的源码在运行时的内存地址：</p>
<pre><code>info line tst.c:func  
</code></pre>
</li>
</ul>
<h2>set scheduler-locking off|on|step</h2>
<ul>
<li><p><code>off</code> 不锁定任何线程，也就是所有线程都执行，这是默认值。</p></li>
<li><p><code>on</code> 只有当前被调试程序会执行。</p></li>
<li><p><code>step</code> 在单步的时候，除了next过一个函数的情况以外，只有当前线程会执行。</p></li>
</ul>
<p>与多线程调试相关的命令还包括：</p>
<ul>
<li><p><code>thread ID</code>，切换当前调试的线程为指定ID的线程。</p></li>
<li><p><code>break thread_test.c:123 thread all</code>，在所有线程中相应的行上设置断点</p></li>
<li><p><code>thread apply ID1 ID2 command</code>，让一个或者多个线程执行GDB命令command。</p></li>
<li><p><code>thread apply all command</code>，让所有被调试线程执行GDB命令command。</p></li>
</ul>
<h2>disassemble</h2>
<p>disassemble命令用于反汇编，它可被用来查看当前执行时的源代码的机器码，其实际上只是把目前内存中的指令dump出来。下面的示例用于查看函数func的汇编代码：</p>
<pre><code>(gdb) disassemble func  
Dump of assembler code for function func:  
0x8048450 &lt;func&gt;:       push   %ebp  
0x8048451 &lt;func+1&gt;:     mov    %esp,%ebp  
0x8048453 &lt;func+3&gt;:     sub    $0x18,%esp  
0x8048456 &lt;func+6&gt;:     movl   $0x0,0xfffffffc(%ebp)  
...  
End of assembler dump.  
</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003733061";}i:19;a:11:{s:5:"title";s:40:"Docker结合Jenkins的持续构建实践";s:4:"link";s:42:"http://segmentfault.com/a/1190000003732967";s:2:"id";s:42:"http://segmentfault.com/a/1190000003732967";s:7:"updated";s:25:"2015-09-10T20:46:27+08:00";s:9:"published";s:25:"2015-09-10T20:46:27+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:15:"刘阳龙Herman";s:10:"author_uri";s:37:"http://segmentfault.com/u/liuyanglong";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:4266:"
<p>docker和Jenkins不是什么新东西了，两者结合也不是什么稀奇的事情，也已经有很多Jenkins和docker相结合的文章，此文仅为自己的一点心得实践，如有不对的地方，欢迎大家纠正。</p>
<p>先贴上大致的流程图，逐步说明：<br><img src="/img/bVpPe0" alt="图片描述" title="图片描述"></p>
<h3>代码-Git：</h3>
<p>并没有什么好说明的，就是简单的使用了Git作为版本控制工具而已，通用使用规范不在细说。<br>此步的产出：<br><em>Git分支特定版本号</em></p>
<h3>Git-自动构建、自动构建-代码包：</h3>
<p>做法也很通用了，将project的Git钩子同Jenkins结合，达到特定分支有push时机触发自动构建，将代码包从Git拉取并打包为代码包。<br><img src="/img/bVpPhr" alt="图片描述" title="图片描述"></p>
<p>此步产出：<br><em>打包好的代码包：project.tar.gz</em></p>
<h3>代码包-Docker镜像</h3>
<p>在此步中，我们为每个project提供特定的测试环境，并且在此环境中执行项目代码镜像打包操作。在此步中，需要提前准备几样东西：</p>
<ol>
<li><p>测试环境：我们这里为一台干净的服务器（不要再问好奢侈，有钱就是任性），部署docker环境；</p></li>
<li><p>project的base镜像：对于一个成熟的项目，所依赖的环境是固定可知的，因此提前准备好其所依赖的base image是必要的。<br>   如，我们一个项目的base image的Dockerfile:</p></li>
</ol>
<pre><code>FROM centos:liuyanglong
MAINTAINER liuyanglong "liuyanglong@xxxx.com"
MAINTAINER version "online"

USER root
ADD php.ini /home/work/local/php/etc/
ADD php-fpm.conf /home/work/local/php/etc/

ONBUILD ADD project-code.tar.gz  /home/work/
ONBUILD ENTRYPOINT ["supervisord", "-c", "/etc/supervisord.conf", "-n"]</code></pre>
<p>注意最下面的两行<strong>ONBUILD</strong><br>而在每一次Jenkins的构建时，要做的仅仅是将代码包传入，并且执行docker build即可，此时build所使用的Dockerfile的内容只有一行：</p>
<pre><code>From this_project_image:base</code></pre>
<p>而执行build时只会根据base image中的两行ONBUILD执行两个命令：</p>
<pre><code>ADD project-code.tar.gz  /home/work/
ENTRYPOINT ["supervisord", "-c", "/etc/supervisord.conf", "-n"]</code></pre>
<p><strong>注意：此步仅仅在测试服务器做了docker build操作，并没有执行docker pull！！</strong></p>
<p>镜像打包完毕后，此步并没有结束！！</p>
<p>调用脚本，根据此构件号的版本docker image创建对应的容器，脚本的输出为其对应的访问方式，供QA同学测试使用。<br>这样，<strong>每个构建好的版本都有对应的测试环境，且互不冲突！</strong><br>鄙人的脚本地址为：<a href="https://github.com/Liuyanglong/docker-tools/blob/master/create_docker">https://github.com/Liuyanglong/docker-tools/blob/master/create_docker</a></p>
<p>此步的产出：</p>
<ol>
<li><p><em>docker build成功的project image，如以构建号为image版本号，叫做： project_dev:530</em></p></li>
<li><p><em>此版本代码的测试环境地址，如：172.30.40.2</em></p></li>
</ol>
<h3>生成线上镜像</h3>
<p>到上一步为止，测试构建环境已经结束，当QA同学确定要上线时，执行Jenkins的Promotion操作，这时触发 此步，将对应build版本对应的docker镜像推送到 <strong>私有docker registry</strong>。<br>所执行的操作自然为 ：</p>
<pre><code>docker tag project_dev:530  docker-registry.xxxxx.com/xxxxxxx/project_name:version
docker push docker-registry.xxxxx.com/xxxxxxx/project_name:version</code></pre>
<p>此步产出：<br><em>push好的线上镜像</em></p>
<h3>AB上线</h3>
<p>此为最后一步，同样是执行promotion操作后最后所执行的步骤，调用我们的内部接口，对线上应用执行AB上线，具体可参见文章：<a href="http://segmentfault.com/a/1190000002978115#articleHeader6">http://segmentfault.com/a/1190000002978115#articleHeader6</a></p>
<h2>总结</h2>
<p>上述就是我们在生产环境中的使用Jenkins和docker所构建的持续集成&amp;自动部署的逻辑架构。也欢迎各位大大拍砖指教。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003732967";}i:20;a:11:{s:5:"title";s:65:"「JavaScript」如何让你的插件兼容AMD, CMD 和 原生 JS";s:4:"link";s:42:"http://segmentfault.com/a/1190000003732752";s:2:"id";s:42:"http://segmentfault.com/a/1190000003732752";s:7:"updated";s:25:"2015-09-10T19:31:10+08:00";s:9:"published";s:25:"2015-09-10T19:31:10+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:9:"JasonKidd";s:10:"author_uri";s:35:"http://segmentfault.com/u/jasonkidd";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:2246:"
<h2>模块标准</h2>
<p>现在的前端模块化标准主要有两种，<code>CMD</code>, <code>AMD</code>。</p>
<h3>CMD</h3>
<p><code>CMD</code> 在模块定义当中有三个变量，分别是 <code>require</code>, <code>exports</code>, <code>module</code>。除了这三个变量可以辨识 <code>CMD</code> 外，<code>define</code> 函数还有一个公有属性 <code>define.cmd</code>。我们也可以检测这个值来判断是否是 <code>CMD</code>。</p>
<p>如果想要对外提供接口的话，可以将接口绑定到 <code>exports</code> （即 <code>module.exports</code>） 上。</p>
<pre><code class="javascript">function MyModule() {
    // ...
}

if(typeof module !== `undefined` &amp;&amp; typeof exports === `object` &amp;&amp; define.cmd) {
    module.exports = MyModule;
}</code></pre>
<blockquote><p>如果需要支持除了 <code>CMD</code> 之外的其他符合 <code>CommonJS</code> 的标准，请去掉 <code>define.cmd</code></p></blockquote>
<h3>AMD</h3>
<p><code>AMD</code> 规范中，<code>define</code> 函数同样有一个公有属性 <code>define.amd</code>。</p>
<p><code>AMD</code> 中的参数便是这个模块的依赖。那么如何在 <code>AMD</code> 中提供接口呢？它是返回一个对象，这个对象就作为这个模块的接口，故我们可以这样写：</p>
<pre><code class="javascript">function MyModule() {
    // ...
}

if(typeof define === `function` &amp;&amp; define.amd) {
    define(function() { return MyModule; });
}</code></pre>
<h2>总结</h2>
<p>我们除了提供 <code>AMD</code> 模块接口，<code>CMD</code> 模块接口，还得提供原生的 JS 接口，一个直接可以用的代码如下：</p>
<pre><code class="javascript">;(function(){
    function MyModule() {
        // ...
    }
    
    var moduleName = MyModule;
    if (typeof module !== 'undefined' &amp;&amp; typeof exports === 'object' &amp;&amp; define.cmd) {
        module.exports = moduleName;
    } else if (typeof define === 'function' &amp;&amp; define.amd) {
        define(function() { return moduleName; });
    } else {
        this.moduleName = moduleName;
    }
}).call(function() {
    return this || (typeof window !== 'undefined' ? window : global);
});
</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003732752";}i:21;a:11:{s:5:"title";s:29:"读 arale 源码之 class 篇";s:4:"link";s:42:"http://segmentfault.com/a/1190000003732073";s:2:"id";s:42:"http://segmentfault.com/a/1190000003732073";s:7:"updated";s:25:"2015-09-10T16:59:46+08:00";s:9:"published";s:25:"2015-09-10T16:59:46+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"honger05";s:10:"author_uri";s:34:"http://segmentfault.com/u/honger05";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:7496:"
<blockquote><p>arale 是阿里、开源社区明星人物--玉伯，开发的一套组件，代码相当优美，大赞玉伯的开源精神，我是您的粉丝。</p></blockquote>
<p>这里分享下我对这段源代码的感悟，若有错误的地方，烦请指正。=￣ω￣=</p>
<h3>先谈谈基于原型的继承。</h3>
<p>先看看 segementfault 上讨论的一道题。</p>
<pre><code class="js">function F() {}
Object.prototype.a = function() {}
Function.prototype.b = function() {}
var f = new F()
// F.a F.b f.a</code></pre>
<p>F 可以调用 a 和 b，因为 F 的原型链是这样的。(直观解释：F 是 Function 实例，F 继承自 Object)</p>
<pre><code class="js">F ----&gt; Function.prototype ----&gt; Object.prototype ----&gt; null

//既 F.__proto__ === Function.prototype
// Function.prototype.__proto__ === Object.prototype
// Object.prototype.__proto__ === null</code></pre>
<p>而 f 只能调用 a ， f 的原型链是这样的。（直观解释：f 是 F 的实例，一切皆对象，f 继承自 Object）</p>
<pre><code class="js">f ----&gt; F.prototype ----&gt; Object.prototype ----&gt; null

//既 f.__proto__ === F.prototype
// F.prototype.__proto__ === Object.prototype
// Object.prototype.__proto__ === null</code></pre>
<p>在 f 的原型链上并没有 Function.prototype . 因此访问不到 b 。</p>
<blockquote><p>注意，访问原型对象 <code>__proto__</code> 是非标准方法，ES5 标准方法是 Object.getPrototypeOf();</p></blockquote>
<p>到这里，基于原型链的继承已经很明显了，只需要</p>
<pre><code class="js">function Animal() {}

function Dog() {}

Dog.prototype.__proto__ = Animal.prototype;

var dog = new Dog();

// dog.__proto__ --&gt; Dog.prototype;
// dog.__proto__.__proto__ --&gt; Animal.prototype</code></pre>
<p>基于 ES5 标准写法是</p>
<pre><code class="js">Dog.prototype = Object.create(Animal.prototype);</code></pre>
<hr>
<h3>来看看 arale 的封装</h3>
<pre><code class="js">// 创建原型链
function Ctor() {};

var createProto = Object.__proto__ ? function(proto) {
  return {
    __proto__: proto
  }
} : function(proto) {
  Ctor.prototype = proto;
  return new Ctor();
}</code></pre>
<p>有三种写法可以实现原型链继承，但是我测试 new Ctor 是最慢的啊，Object.creaete 其次，<code>__proto__</code> 是最快的。</p>
<pre><code class="js">function Ctor() {}

function getProto1(proto, c) {
  Ctor.prototype = proto;
  var o = new Ctor();
  o.constructor = c;
  return o;
}

function getProto2(proto, c) {
  return Object.create(proto, {
    constructor: {
      value: c
    }
  })
}

function getProto3(proto, c) {
  return {
    __proto__: proto,
    constructor: c
  }
}</code></pre>
<p>接着往下看。。。</p>
<pre><code class="js">function Class(o) {
  if (!(this instanceof Class) &amp;&amp; isFunction(o)) {
    return classify(o);
  }
}

function classify(cls) {
  cls.extend = Class.extend;
  cls.implement = implement;
  return cls;
}</code></pre>
<p>这种写法是，当不使用 <code>new</code> 关键字调用时，将参数 <code>类化</code>，如：</p>
<blockquote><p>修改：是不支持 <code>new</code> 的方式调用。</p></blockquote>
<pre><code class="js">function Animal() {}
Animal.prototype.talk = function() {}

//Class(Animal); Animal 拥有了 extend 和 implement 方法
var Dog = Class(Animal).extend({
  swim: function() {}
})</code></pre>
<p>Class 的三个变种属性 <code>Extends</code> <code>Implements</code> <code>Statics</code></p>
<p>这三个属性会做特殊处理</p>
<pre><code class="js">Class.Mutators = {
  // 继承的方法，只支持单继承
  Extends: function(parent) {
    var existed = this.prototype;
    // 建立原型链来实现继承
    var proto = createProto(parent.prototype);
    mix(proto, existed);
    // 强制改变构造函数
    proto.constructor = this;
    this.prototype = proto;
    // 提供 superclass 语法糖，来调用父类属性
    this.superclass = parent.prototype;
  },
  // 混入属性，可以混入多个类的属性
  Implements: function(items) {
    // 将参数变成数组
    isArray(items) || (items = [ items ]);
    var proto = this.prototype, item;
    while (item = items.shift()) {
      // 无论参数是 类（Function），还是 对象（Object），都混入。
      mix(proto, item.prototype || item);
    }
  },
  Statics: function(staticProperties) {
    // 直接混入静态属性。
    mix(this, staticProperties);
  }
}</code></pre>
<p>再来看看 <code>implement</code> 方法, 它是用来混入属性的。</p>
<p>三个变种属性将被执行</p>
<pre><code class="js">function implement(properties) {
  var key, value;
  for (key in properties) {
    value = properties[key];
    if (Class.Mutators.hasOwnProperty(key)) {
      Class.Mutators[key].call(this, value);
    } else {
      this.prototype[key] = value;
    }
  }
}</code></pre>
<p>好了，最关键的方法 <code>Class.create</code> 来了，它是用来创建类的，可以指定父类。</p>
<pre><code class="js">Class.create = function(parent, properties) {
  // 如果没有指定父类，父类就是 Class
  if (!isFunction(parent)) {
    properties = parent;
    parent = null;
  }
  properties || (properties = {});
  // 如果指定了 Extends 属性， 父类就是它了
  parent || (parent = properties.Extends || Class);
  properties.Extends = parent;
  // 创建子类的构造函数
  function SubClass() {
    // 调用父类的构造函数
    parent.apply(this, arguments);
    // 仅调用自身的初始化方法，initialize
    if (this.constructor === SubClass &amp;&amp; this.initialize) {
      this.initialize.apply(this, arguments);
    }
  }
  // 指定父类的情况下，继承父类的属性
  if (parent !== Class) {
    Mix(SubClass, parent, parent.StaticsWhiteList);
  }
  // 为子类添加实例属性，三个特殊属性，在这里被执行
  implement.call(SubClass, properties);
  // 返回可继续 继承 的子类
  return classify(SubClass);
}</code></pre>
<p>最后来看看继承的方法 <code>Class.extend</code> ，被 classify 的类，都可以继续创建子类。</p>
<pre><code class="js">Class.extend = function(properties) {
  properties || (properties = {});
  // 指定父类为调用者
  properties.Extends = this;
  return Class.create(properties);
}</code></pre>
<p>最后的最后，简单介绍它的工具类，Helpers</p>
<pre><code class="js">// 属性混合，增加白名单限制
function mix(r, s, wl) {
  for (var p in s) {
    // 最佳实践：任何 for in 循环都要带上 hasOwnProperty。除非你想遍历原型
    if (s.hasOwnProperty(p)) {
      if (wl &amp;&amp; indexOf(wl, p) === -1) continue;
      if (p !== "prototype") {
        r[p] = s[p];
      }
    }
  }
}

// [].indexOf 是 ES5 加入的，并非所有浏览器都支持。
// 这里没有也不需要使用 polyfill 的方式。
var indexOf = Array.prototype.indexOf ? function(arr, item) {
  return arr.indexOf(item);
} : function(arr, item) {
  for (var i = 0, len = arr.length; i &lt; len; i++) {
    if (arr[i] === item) {
      return i;
    }
  }
  return -1;
}

// 这个很简单，只有 Object.prototype.toString 才能知道它的 [[class]]
var toString = Object.prototype.toString;
var isArray = Array.isArray || function(val) {
  return toString.call(val) === "[object Array]";
}
var isFunction = function(val) {
  return toString.call(val) === "[object Function]";
}</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003732073";}i:22;a:11:{s:5:"title";s:31:"为何CNAME和MX不能共存？";s:4:"link";s:42:"http://segmentfault.com/a/1190000003731463";s:2:"id";s:42:"http://segmentfault.com/a/1190000003731463";s:7:"updated";s:25:"2015-09-10T15:03:53+08:00";s:9:"published";s:25:"2015-09-10T15:03:53+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:9:"a84945345";s:10:"author_uri";s:33:"http://segmentfault.com/u/rockets";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:3993:"
<p>在设置<a>DNS</a>解析记录的时候很多站长朋友会碰到“系统提示MX和CNAME不能共存”的问题，今天我将以我自己用的CloudXNS为例子为大家解释一下这类问题如何解决，部分参考内容来源于CloudXNS官方。</p>
<hr>
<p><img src="/img/bVpOSd" alt="图片描述" title="图片描述"></p>
<p><strong>技术剖析</strong></p>
<p>RFC 1034（<a href="http://tools.ietf.org/pdf/rfc1034">http://tools.ietf.org/pdf/rfc1034</a>） 章节3.6.2中指出：</p>
<blockquote><p>If aCNAME RR is present at a node, no other data should be present;<br>this ensuresthat the data for a canonical name and its aliases cannot<br>be different.</p></blockquote>
<p>大意就是说如果CNAME资源记录出现在一个域名节点，为了确保不会出现不同的解析结果，这个域名节点将不再接受其他记录值。</p>
<p>我们来测试一下。</p>
<p>假设为DNS域chinatesters.cn注册了下面的两条记录：</p>
<pre><code>@ MX 10 mx.ym.163.com.

@ CNAME fastweb.com.cn.
</code></pre>
<p>下面是在递归服务器（不能使用该域的授权服务器）上dig查询的结果：</p>
<p>我们可以看到MX记录查询的结果与上文中注册记录并不一致，而为其CNAME记录值所配置的MX记录，即对CNAME记录做的递归查询得到的结果。</p>
<p>但如果在递归服务器的CNAME记录TTL过期后再来做查询，只是把查询的顺序颠倒， （即先查询MX记录，再查询CNAME记录）则有可能得到期望的正确结果。</p>
<p>总结一下，<strong>递归DNS服务器在查询某个常规域名记录（非CNAME记录）时，如果在本地cache中已有该域名有对应的CNAME记录，</strong><strong>则会开始用该别名记录来重启查询。</strong>上文中dig查询MX记录测试示例即对应于这种情况。</p>
<p>因此，即使某些域名解析系统网页上并未限制用户同时填写CNAME和MX的操作，但只要将CNAME和MX配置到一起，上述问题也一定是存在的，它会导致邮件服务偶尔出现异常。</p>
<p>实际上除了CNAME和MX不能共存外，已经注册了CNAME类型的域名记录是不能再注册除DNSSEC相关类型记录（RRSIG、NSEC等）之外的任何其他类型记录（包括MX、A、NS等记录）。理由同上，这里就不一一做演示了。<br><strong>解决方案</strong></p>
<p>我们CloudXNS系统在标准记录类型上的互斥关系设定及提醒是完全遵循DNS规范的，而这样的规范设定却对大家在域名配置上造成了一定困扰。</p>
<p>不过，细心的网友发现，CloudXNS具备隐式CNAME扩展记录类型（即LINK记录），它可以隐藏当前这一层的配置，直接接管下一层的结果。因此，CloudXNS也可以获得“将MX和CNAME共同配置”类似的解决方案。</p>
<p>如下图所示，在www下配置CNAME到CDN服务提供商，然后在@下配置MX和LINK记录，将www作为被LINK的域名。</p>
<p><img src="/img/bVpOSD" alt="图片描述" title="图片描述"><br>我们用dig验证一下：</p>
<p><img src="/img/bVpOSM" alt="图片描述" title="图片描述"></p>
<p>当然，这样的配置也同样会存在邮件服务偶尔失效的问题。</p>
<p>因此，CloudXNS系统即将为大家给出一个终极解决方案，可以完美的解决这个问题！届时，您的邮件服务可以永远正常使用，同时也可享受到网络加速的快感，可谓兼得鱼和熊掌。（就是云安全加速，该功能模块会整合@北京快网）CDN服务提供的部分核心内容，包括访问加速、网站防火墙、防盗链、DDOS防护、CC防护等多项加速及安全保护功能。届时您只需要给您的域名一个开关点击，一切即可高枕无忧。目前已经上线）</p>
<p><strong>参考文献</strong></p>
<pre><code>RFC 1034英文原版：http://tools.ietf.org/pdf/rfc1034

中文译文参考：http://download.csdn.net/detail/weicq2000/4627738
</code></pre>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003731463";}i:23;a:11:{s:5:"title";s:41:"centos配置静态IP地址、DNS、网关";s:4:"link";s:42:"http://segmentfault.com/a/1190000003731280";s:2:"id";s:42:"http://segmentfault.com/a/1190000003731280";s:7:"updated";s:25:"2015-09-10T14:29:22+08:00";s:9:"published";s:25:"2015-09-10T14:29:22+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"两仪";s:10:"author_uri";s:33:"http://segmentfault.com/u/liangyi";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:4380:"
<h2>获取网络设备名称</h2>
<p>由于默认安装时，dhcp自动获得ip，查看系统的ip，类似如下： (这步比较关键，找到对应的网络设备和配置文件）</p>
<pre><code>[root@xxx ~]# ifconfig
eth0 Link encap:Ethernet HWaddr 08:00:27:C1:E4:3D 
    inet addr:192.168.0.103  Bcast:192.168.0.255 Mask:255.255.255.0
    inet6 addr: fe80::a00:27ff:fec1:e43d/64 Scope:Link
    UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
    RX packets:108 errors:0 dropped:0 overruns:0 frame:0
    TX packets:32 errors:0 dropped:0 overruns:0 carrier:0
    collisions:0 txqueuelen:1000 
    RX bytes:12689 (12.3 KiB) TX bytes:5908 (5.7 KiB)

lo Link encap:Local Loopback 
    inet addr:127.0.0.1 Mask:255.0.0.0
    inet6 addr: ::1/128 Scope:Host
    UP LOOPBACK RUNNING MTU:16436 Metric:1
    RX packets:8 errors:0 dropped:0 overruns:0 frame:0
    TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
    collisions:0 txqueuelen:0 
    RX bytes:480 (480.0 b) TX bytes:480 (480.0 b)
</code></pre>
<h2>根据网络设备名找到相应的配置文件，并对它进行修改</h2>
<p>根据上面输入的命令的出的结果，我们知道有两个设备，分别是<code>eth0</code>和<code>lo</code>。那么在<code>/etc/sysconfig/network-scripts/</code>这个目录中存在这两个相对应的配置文件，名称分别是<code>ifcfg-eth0</code>和<code>ifcfg-lo</code>。在这里我们要操作的文件是<code>ifcfg-eth0</code>，下面的操作都是围绕这个文件开展的。</p>
<p>通过vim修改网卡配置，编辑。命令如下。</p>
<pre><code>vim /etc/sysconfig/network-scripts/ifcfg-eth0
</code></pre>
<p>常见的配置属性如下所示：</p>
<pre><code>DEVICE=eth0
TYPE=Ethernet
UUID=3b632061-7971-4a7e-aeb3-55b288afd66d
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=dhcp
HWADDR=14:DD:A9:ED:1B:7F
DEFROUTE=yes
PEERDNS=yes
PEERROUTES=yes
IPV4_FAILURE_FATAL=yes
IPV6INIT=no
NAME="System eth0"
LAST_CONNECT=1440797869
</code></pre>
<h3>常见属性说明</h3>
<blockquote>
<p>DEVICE=eth0 ##描述網卡對應的設備別名，例如ifcfg-eth0的文件中它爲eth0</p>
<p>BOOTPROTO=static ##設置網卡獲得ip地址的方式，可能的選項爲static，dhcp或bootp，分別對應靜態指定的ip地址，通過dhcp協議獲得的ip地址，通過bootp協議獲得的ip地址</p>
<p>BROADCAST=192.168.0.255 ##對應的子網廣播地址</p>
<p>HWADDR=00<img src="//static.segmentfault.com/build/global/img/emojis/07.png" class="emoji" title="07" alt="07">E9<img src="//static.segmentfault.com/build/global/img/emojis/05.png" class="emoji" title="05" alt="05">E8:B4 ##對應的網卡物理地址</p>
<p>IPADDR=192.168.1.2 ##如果設置網卡獲得 ip地址的方式爲靜態指定，此字段就指定了網卡對應的ip地址</p>
<p>NETMASK=255.255.255.0 ##網卡對應的網絡掩碼</p>
<p>NETWORK=192.168.1.0 ##網卡對應的網絡地址</p>
<p>ONBOOT=yes ##系統啓動時是否設置此網絡接口，設置爲yes時，系統啓動時激活此設備</p>
</blockquote>
<h3>修改后的配置</h3>
<pre><code>DEVICE=eth0
TYPE=Ethernet
UUID=3b632061-7971-4a7e-aeb3-55b288afd66d
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=static  ##修改
IPADDR=192.168.0.124   ##新增
NETMASK=255.255.255.0  ##新增
DNS1=192.168.0.1       ##新增
GATEWAY=192.168.0.1       ##新增
HWADDR=14:DD:A9:ED:1B:7F
DEFROUTE=yes
PEERDNS=yes
PEERROUTES=yes
IPV4_FAILURE_FATAL=yes
IPV6INIT=no
NAME="System eth0"
LAST_CONNECT=1440797869
</code></pre>
<h2>修改网关配置</h2>
<p>编辑文件</p>
<pre><code>vi /etc/sysconfig/network
</code></pre>
<p>在最下面增加一行:</p>
<pre><code>GATWAY=192.168.0.1
</code></pre>
<h2>修改DNS</h2>
<p>编辑文件</p>
<pre><code>vi /etc/resolv.conf
</code></pre>
<p>新增或修改后的文件如下所示：</p>
<pre><code>nameserver 114.114.114.114      ##DNS首选地址
nameserver 202.96.134.133        ##DNS备用地址
search localdomain
</code></pre>
<h2>重启网络服务</h2>
<pre><code>service network restart 
</code></pre>
<p>或者</p>
<pre><code>
/etc/init.d/network restart
</code></pre>
<h2>相关链接</h2>
<p>1.<a href="http://www.paipat.com/?post=47">http://www.paipat.com/?post=47</a><br>2.<a href="http://www.itkee.com/os/detail-28a7.html">http://www.itkee.com/os/detail-28a7.html</a><br>3.<a href="http://www.jbxue.com/LINUXjishu/14865.html">http://www.jbxue.com/LINUXjishu/14865.html</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003731280";}i:24;a:11:{s:5:"title";s:44:"利用Redis cache优化app查询速度实践";s:4:"link";s:42:"http://segmentfault.com/a/1190000003730722";s:2:"id";s:42:"http://segmentfault.com/a/1190000003730722";s:7:"updated";s:25:"2015-09-10T12:20:21+08:00";s:9:"published";s:25:"2015-09-10T12:20:21+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:11:"Yunba云巴";s:10:"author_uri";s:31:"http://segmentfault.com/u/yunba";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:8752:"
<p><em>注意：本篇文章译自<a href="http://www.sitepoint.com/speeding-up-existing-apps-with-a-redis-cache/">speeding up existing app with a redis cache</a>，如需要转载请注明出处。</em></p>
<h2>发现问题</h2>
<p>在应用解决方法之前，我们需要对我们面对的问题有一个清晰的认识。<br>App所遇到的问题是，当执行一个查询时，它会跑到<a href="http://www.sitepoint.com/turning-crawled-website-search-engine-php/">Diffbot’s API</a> 然后查询数据集。子集被返回并展示出来。根据Diffbot服务器的繁忙程度，可能需要花5秒左右的时间去完成这一过程。如果扩展计算机的能力这种情形无疑会改进，如果一个查询执行一次就被记住并且重复使用24小时，通常可以把这个过程看成刷新这个集合，并且这个方式会非常的高效。</p>
<p>你可能会怀疑“缓存一个查询有什么好处呢？”大多数人应该都不会只查询一个东西或者同样的事物。</p>
<p>呃...事实上，不仅调查表明人们经常查询一个事情或相同的事，他们通常也会去搜索多产作家（或自己）。考虑到事实上应用这一缓存方式并没有增加纸面上的成本（其实是通过减少服务器压力而减少成本），把这个加进来是一个容易的盈利点，即使它使用频率并没有我们希望那样高。但我们也没有任何理由不使用它----因为它可以给我们带来利益。</p>
<p>既然问题已经界定清楚，让我们先处理先决条件。</p>
<h2>配置环境</h2>
<p>首先，我们需要在开发和生产环境下安装Redis（需要注意的是，如果你把Homestead用于本地开发，Redis就已经安装好了，目前使用的是v3.0.1版本）</p>
<p>我们可以通过操作系统的包管理器来做这件事：</p>
<pre><code>sudo apt-get install redis-server
</code></pre>
<p>这是最简单也是最为推荐的方法，但我们也可以从头来安装并且手动配置。根据<a href="http://redis.io/download#installation">他们网上</a>的说明，我们可以如此配置：</p>
<pre><code>sudo apt-get install gcc make build-essential tcl
wget http://download.redis.io/releases/redis-3.0.2.tar.gz
tar xzf redis-3.0.2.tar.gz
cd redis-3.0.2
make
make test
sudo make install
</code></pre>
<p>如果你运行<code>make</code>遇到错误提示<code>jemalloc.h</code>那么运行<code>make distclean</code>然后在运行<code>make</code>。<code>make test</code>命令是选择性运行的，但是很有帮助。</p>
<p>注意：如果你看到这里，而3.0.2已经不是最新的版本，那么根据你的最新版本号去调节命令。</p>
<p>为了防止一些常见的警告（至少在Ubuntu上），我们还需要预防性的运行以下命令：</p>
<pre><code>sudo sh -c 'echo "vm.overcommit_memory=1" &gt;&gt; /etc/sysctl.conf'
sudo sh -c 'echo "net.core.somaxconn=65535" &gt;&gt; /etc/sysctl.conf'
sudo sh -c 'echo "never" &gt; /sys/kernel/mm/transparent_hugepage/enabled'
</code></pre>
<p>我们也要确保最后的命令在<code>exit 0</code>上被添加到了<code>/etc/rc.local</code>，因此能保证在每个重启的服务器上能重新发送。最后我们可以用<code>sudo reboot</code>重启服务器并且运行有<code>sudo redis-server</code>的Redis检查是否一切正常。</p>
<p>最后，我们要<a href="http://redis.io/topics/quickstart#installing-redis-more-properly">确保在服务器重启后Redis会启动</a>，所以我们要跟着官方的说明去完成配置。</p>
<h2>Predis</h2>
<p>我们之前说了一些关于<a href="http://www.sitepoint.com/an-introduction-to-redis-in-php-using-predis/">Predis的基础知识</a>，我们将要将其用到本文的例子中：</p>
<pre><code>composer require predis/predis
</code></pre>
<p>进一步的，假设我们已经了解之前叙述的关于Predis的知识。</p>
<p>和之前发表的关于Predis相比，虽然是有一些不同（比如过渡到命名空间），但我们需要的API几乎是一样的。</p>
<p>实施<br>要在我们app里运用Redis，我们需要遵循以下的程序：<br>    查看当前的缓存中是否有查询结果<br>    如果是，抓取他们<br>    如果没有，把他们拿来，储存，将他们发送到app的其他部分</p>
<p>因此，实施非常的简单：在“form submitted”下检查（寻找“search”参数），我们实例化Predis客户端，计算search查询的MD5 hash值，然后检查查询结果是否已经被缓存。如果失败，就在重复前面的流程。</p>
<pre><code>$result = ...
$info = ...
</code></pre>
<p>我们将查询结果序列化并直接保存到cache里。然后我们在模块外立即抓取他们，app的流程就和往常一样继续。而index.php改变的部分如下：</p>
<pre><code>// Check if the search form was submitted
if (isset($queryParams['search'])) {

    $redis = new Client();
    $hash = md5($_SERVER['QUERY_STRING']);
    if (!$redis-&gt;get($hash . '-results')) {

        $diffbot = new Diffbot(DIFFBOT_TOKEN);

        // Building the search string
        $searchHelper = new SearchHelper();
        $string = (isset($queryParams['q']) &amp;&amp; !empty($queryParams['q']))
            ? $queryParams['q']
            : $searchHelper-&gt;stringFromParams($queryParams);

        // Basics
        $search = $diffbot
            -&gt;search($string)
            -&gt;setCol('sp_search')
            -&gt;setStart(($queryParams['page'] - 1) * $resultsPerPage)
            -&gt;setNum($resultsPerPage);

        $redis-&gt;set($hash . '-results', serialize($search-&gt;call()));
        $redis-&gt;expire($hash . '-results', 86400);
        $redis-&gt;set($hash . '-info', serialize($search-&gt;call(true)));
        $redis-&gt;expire($hash . '-info', 86400);
    }

    $results = unserialize($redis-&gt;get($hash . '-results'));
    $info = unserialize($redis-&gt;get($hash . '-info'));
</code></pre>
<p>进过测试，我们可以看到它的魅力所在—如果我们刷新页面，或执行另一个查询，就会立即执行一次查询，然后会回到之前的那个。最后我们添加，提交，推动部署一下内容：</p>
<pre><code>git add -A
git commit -m "Added Redis cache [deploy:production]"
git push origin master
</code></pre>
<p>就是这么简单，我们的最新版的app已经上线，而且使用的Redis。</p>
<p>注意：如果你想知道我们是如何用一条命令从开发模式转到生产部署，你可以看<a href="http://www.sitepoint.com/deploying-php-apps-digitalocean-dploy-io/">这里</a>。</p>
<p>微调<br>为了进一步的提升性能，Predis推荐安装phpiredis，这是个PHP的扩展，目的是“降低序列化和解析Redis协议的成本”。可以看作我们完全控制了服务器，有什么理由不试试呢？</p>
<pre><code>cd ~
git clone https://github.com/redis/hiredis
cd hiredis
make
sudo make install
cd ~
git clone https://github.com/nrk/phpiredis
cd phpiredis
phpize &amp;&amp; ./configure --enable-phpiredis
make
sudo make install

sudo touch /etc/php5/mods-available/phpiredis.ini
sudo sh -c 'echo "extension=phpiredis.so" &gt; /etc/php5/mods-available/phpiredis.ini'
sudo php5enmod phpiredis
sudo service php5-fpm restart
</code></pre>
<p>以上是安装的前提，并且启用了扩展。现在我们要做的就是利用<a href="https://github.com/nrk/phpiredis">phpiredis</a>链接去配置Predis客户端。因此我们需要更换：</p>
<pre><code>$redis = new Client();
</code></pre>
<p>和</p>
<pre><code>$redis = new Client('tcp://127.0.0.1', [
        'connections' =&gt; [
            'tcp'  =&gt; 'Predis\Connection\PhpiredisStreamConnection',
            'unix' =&gt; 'Predis\Connection\PhpiredisSocketConnection',
        ],
    ]);
</code></pre>
<p>就是这么简单！现在我们的Redis安装会更快！</p>
<h2>总结：</h2>
<p>在本教程中，我们利用Redis结合Predis库来提升已部署的app的速度，我们平衡大数据海洋的水滴中可用的RAM来存储每天一次查询的结果，然后从缓存中返回这些结果，而不是重新运行一遍查询。但这确实意味着结果不会总是最新的，但就这边文章，其实查询结果没有被刷新的次数比这种情况多得多。</p>
<p>注：关于更多的有关Redis的知识可以参考<a>redisdoc.com</a> (此网站文档是 Redis Command Reference 和 Redis Documentation 的中文翻译版， 阅读这个文档可以帮助你了解 Redis 命令的具体使用方法， 并学会如何使用 Redis 的事务、持久化、复制、Sentinel、集群等功能。)<br>我们<a>云巴</a>的产品也是使用redis存储实践，大家也可以来交流学习~</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003730722";}i:25;a:11:{s:5:"title";s:58:"canvas 在高清屏下绘制图片变模糊的解决方法";s:4:"link";s:42:"http://segmentfault.com/a/1190000003730246";s:2:"id";s:42:"http://segmentfault.com/a/1190000003730246";s:7:"updated";s:25:"2015-09-10T10:58:46+08:00";s:9:"published";s:25:"2015-09-10T10:58:46+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"KevinYue";s:10:"author_uri";s:36:"http://segmentfault.com/u/scriptjava";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:4232:"
<blockquote><p>之前我在 SF 上回答过「<a href="http://segmentfault.com/q/1010000002391424">html5 canvas绘制图片模糊的问题</a>」，但是可能是由于我给出的答案过于简略，加上答案中的 demo 链接已经失效，很多人反映这种办法并不好使。但是我在给出答案之前是在小米2 和 iPhone 上测试过的，没有任何问题。下面我会一步一步地描述具体的步骤。</p></blockquote>
<h2>前提条件</h2>
<p>假设我们要在 canvas 中绘制一张 <code>300 x 90</code> 的图片，并且要保证它在高清屏中不模糊。那么我们首先要准备一张 <code>600 x 180</code> 的图片，处理过高清屏的同学应该会有这方面的经验。</p>
<h2>问题重现</h2>
<p>OK，我们先把问题重现一下，以便有一个更直观的了解。下面是相关的代码（为了简单起见，我把代码都写在了 HTML 文档里面）：</p>
<pre><code>&lt;!-- 通过 img 标签引入图片，以便绘制到 canvas 中 --&gt;
&lt;img src="html5rocks.png" alt="" width="300" height="90"&gt;

&lt;!-- canvas --&gt;
&lt;canvas width="300" height="90"&gt;&lt;/canvas&gt;

&lt;script&gt;
    function init() {
        var canvas = document.querySelector('canvas');
        var ctx = canvas.getContext('2d');
        ctx.drawImage(document.querySelector('img'), 0, 0, 300, 90);
    }
    window.onload = init;
&lt;/script&gt;</code></pre>
<p>代码很简单，没有做任何处理，具体的效果和完整的代码可以查看这个 <a href="http://happycoder.net/demo/canvas-retina/demo-normal.html">DEMO</a>，这个 demo 在高清屏的手机中会出现的问题：canvas 中的图片变模糊了！。</p>
<p>至于为什么会变模糊，这和浏览器处理 canvas 的方式有关，相关的文章可以参考这篇 <a href="http://www.html5rocks.com/en/tutorials/canvas/hidpi/">High DPI Canvas</a>，这里不作深入介绍。</p>
<h2>解决问题</h2>
<h3>首先，引入 <a href="https://github.com/jondavidjohn/hidpi-canvas-polyfill">hidpi-canvas-polyfill</a>
</h3>
<p>其实，不只是绘制图片时会出现模糊的问题，正常情况下，在高清屏的设备中，任何绘制在 canvas 中的图形（包括文字）都会出现模糊的问题。上面这个 polyfill 就是为了解决这个问题，但是它没有处理图片。</p>
<h3>接下来，修改绘制图片的代码</h3>
<p>将 <code>init</code> 函数修改成下面这样：</p>
<pre><code class="js">function init() {
    var canvas = document.querySelector('canvas');
    var ctx = canvas.getContext('2d');

    // polyfill 提供了这个方法用来获取设备的 pixel ratio
    var getPixelRatio = function(context) {
        var backingStore = context.backingStorePixelRatio ||
            context.webkitBackingStorePixelRatio ||
            context.mozBackingStorePixelRatio ||
            context.msBackingStorePixelRatio ||
            context.oBackingStorePixelRatio ||
            context.backingStorePixelRatio || 1;
    
        return (window.devicePixelRatio || 1) / backingStore;
    };

    var ratio = getPixelRatio(ctx);
    
    // 注意，这里的 width 和 height 变成了 width * ratio 和 height * ratio
    ctx.drawImage(document.querySelector('img'), 0, 0, 300 * ratio, 90 * ratio);
}</code></pre>
<p>可以点击<a href="http://happycoder.net/demo/canvas-retina/demo-retina.html">这里</a>查看完整的代码和效果，在高清屏的设备中打开，看看 cavans 中的图片是否完美显示。</p>
<h2>说明</h2>
<p>这个解决方案本质上和 <a href="/u/baiyi">@白一梓</a> 的答案是一样的：先放大 canvas，再用 CSS 将其限制回原始大小。</p>
<p>如果你看了 polyfill 的代码就会明白其中的原理了，这个 polyfill 的代码十分简短明了，它做了两件事：一是将 canvas 的高和宽分别乘以 ratio 将其放大，然后又用 CSS 将高和宽限制成初始的大小；二是 hack canvas 中常用的函数，如：<code>fillRect</code>, <code>clearRect</code>, <code>lineTo</code>, <code>arc</code> 等，将它们的参数都乘以 ratio，以方便我们可以像以前那样使用这些方法，而不用在传参的时候手动乘以 ratio。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003730246";}i:26;a:11:{s:5:"title";s:52:"php实战正则表达式（二）：提取html元素";s:4:"link";s:42:"http://segmentfault.com/a/1190000003728798";s:2:"id";s:42:"http://segmentfault.com/a/1190000003728798";s:7:"updated";s:25:"2015-09-09T23:36:01+08:00";s:9:"published";s:25:"2015-09-09T23:36:01+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:5:"totoo";s:10:"author_uri";s:31:"http://segmentfault.com/u/totoo";s:2:"re";a:1:{s:4:"rank";s:1:"4";}s:7:"summary";s:13085:"
<p>这篇文章通过提取html元素介绍了正则表达式中<em>模式修饰符</em>、<em>贪婪匹配</em>与<em>非贪婪匹配</em>、<em>Unicode模式</em>、<em>环视</em>等知识点。<br>在阅读这篇文章前最好把同系列文章<a href="http://segmentfault.com/a/1190000003696894">php实战正则表达式（一）：验证手机号</a>先仔细阅读一遍。</p>
<h2>基本提取</h2>
<p>有这样一个表格</p>
<table>
<thead><tr>
<th>用户名</th>
<th>职业</th>
</tr></thead>
<tbody>
<tr>
<td>Kobe Bryant</td>
<td>篮球运动员</td>
</tr>
<tr>
<td>Jay Chou</td>
<td>歌手、词曲创作人、制作人、演员、导演</td>
</tr>
<tr>
<td>Lionel Messi</td>
<td>足球运动员</td>
</tr>
</tbody>
</table>
<p>它的源码如下：</p>
<pre><code>&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;&lt;th&gt;用户名&lt;/th&gt;&lt;th&gt;职业&lt;/th&gt;&lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Kobe Bryant&lt;/td&gt;&lt;td&gt;篮球运动员&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Jay Chou&lt;/td&gt;&lt;td&gt;歌手、词曲创作人、制作人、演员、导演&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lionel Messi&lt;/td&gt;&lt;td&gt;足球运动员&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
<p>现在要提取<code>&lt;tbody&gt;</code>第一个<code>&lt;tr&gt;</code>元素。最简单的正则表达式应该是这样：</p>
<p><code>&lt;tbody&gt;\s+&lt;tr&gt;.*&lt;\/tr&gt;</code></p>
<p>其中</p>
<ul>
<li><p>\s是<a href="http://segmentfault.com/a/1190000003696894">php实战正则表达式（一）：验证手机号</a>介绍过的字符组简记法中的一个，代表回车符、空格、制表符等空白字符</p></li>
<li><p>量词<code>+</code>表示它所修饰的字符或字符组出现次数大于等于1</p></li>
<li><p><strong>点号字符</strong><code>.</code>在正则表达式中是一个特殊的元字符，它可以匹配“任意字符”</p></li>
<li><p>闭标签<code>&lt;/tr&gt;</code>中的斜线<code>/</code>在php的正则表达式中是模式分隔符，所以需要转义来表示斜线字符。</p></li>
</ul>
<p>但实际上这样一个表达式是无法从上面的<code>&lt;tbody&gt;</code>中提取第一个<code>&lt;tr&gt;</code>元素的</p>
<p><img src="/img/bVpOa2" alt="图片描述" title="图片描述"></p>
<p>这里主要的问题是在默认情况下点号字符<code>.</code>无法匹配换行符<code>\n</code>。有两个方法可以解决这个问题：</p>
<ul>
<li><p>使用模式修饰符<code>s</code>，正则表达式为<code>/&lt;tbody&gt;\s+&lt;tr&gt;.*&lt;\/tr&gt;/s</code>或<code>(?s)&lt;tbody&gt;\s+&lt;tr&gt;.*&lt;\/tr&gt;</code>。模式修饰符<code>s</code>的作用就是让点号字符<code>.</code>可以匹配换行符。</p></li>
<li><p>用<code>[\s\S]</code>或<code>[\w\W]</code>或<code>[\d\D]</code>代替点号字符<code>.</code>来匹配所有字符，正则表达式为<code>&lt;tbody&gt;\s+&lt;tr&gt;[\s\S]*&lt;\/tr&gt;</code></p></li>
</ul>
<p><img src="/img/bVpOa9" alt="图片描述" title="图片描述"></p>
<p>关于<strong>模式修饰符</strong>（Pattern Modifiers），这里需要详细介绍一下（<a href="http://php.net/manual/zh/reference.pcre.pattern.modifiers.php">点击这里查看php支持的所有模式修饰符</a>）。模式修饰符可以改变正则表达式的一些默认规则，常用的模式修饰符有i、s、U、u等，我们在后面会用到它们中的一些，这里不展开介绍每个模式修饰符的作用，后面用到了再具体介绍。这里主要对比一下/.../{modifier}与...(?{modifier})...两种表示方法的区别。</p>
<table>
<thead><tr>
<th>模式修饰符</th>
<th><code>/.../{modifier}</code></th>
<th><code>...(?{modifier})...</code></th>
</tr></thead>
<tbody>
<tr>
<td>示例</td>
<td><code>/&lt;tr&gt;.*&lt;\/tr&gt;/s</code></td>
<td><code>&lt;tr&gt;(?s).*&lt;\/tr&gt;</code></td>
</tr>
<tr>
<td>名称（php手册）</td>
<td>模式修饰符</td>
<td>模式内修饰符</td>
</tr>
<tr>
<td>名称（《正则指引》）</td>
<td>预定义常量</td>
<td>模式修饰符</td>
</tr>
<tr>
<td>作用范围</td>
<td>整个正则表达式</td>
<td>不在分组（子表达式）中时，对它后面的全部正则表达式起作用；如果在分组（子表达式）中，则对它分组中的剩余部分起作用。在没有分组，且放在整个正则表达式最前面的时候相当于<code>/.../{modifier}</code>
</td>
</tr>
<tr>
<td>支持程度</td>
<td>支持所有模式修饰符</td>
<td>支持部分模式修饰符</td>
</tr>
<tr>
<td>其他编程语言</td>
<td>可能不支持</td>
<td>一般都支持</td>
</tr>
</tbody>
</table>
<p>从上面的gif中可以看到提取的结果中有三个<code>tr</code>，而不是只有一个。这是因为正则表达式中量词默认是<strong>贪婪匹配</strong>，在这里，<code>.*</code>会匹配一切字符，直到最后没有字符再向前回溯，回溯到<code>&lt;tbody&gt;</code>中的最后一个<code>&lt;/tr&gt;</code>时与正则表达式中的<code>&lt;\/tr&gt;</code>相匹配，从而完成整个匹配过程，最后的结果也就是包含了三个<code>&lt;tr&gt;</code>。</p>
<p>可以使用模式修饰符<code>U</code>指定整个正则表达式为非贪婪模式，也可以使用<strong>非贪婪匹配量词</strong>指定某一个量词为非贪婪模式：</p>
<ul>
<li>
<p>指定整个正则表达式为非贪婪模式：</p>
<ul>
<li><p><code>/&lt;tbody&gt;\s+&lt;tr&gt;.*&lt;\/tr&gt;/Us</code></p></li>
<li><p>或<code>(?Us)&lt;tbody&gt;\s+&lt;tr&gt;.*&lt;\/tr&gt;</code></p></li>
</ul>
</li>
<li><p>非贪婪量词：<br><code>/&lt;tbody&gt;\s+&lt;tr&gt;.*?&lt;\/tr&gt;/s</code></p></li>
</ul>
<p><img src="/img/bVpObd" alt="图片描述" title="图片描述"></p>
<p>完整的贪婪量词（匹配优先量词）与非贪婪量词（忽略优先量词）见下表：</p>
<table>
<thead><tr>
<th>贪婪量词</th>
<th>非贪婪量词</th>
<th>限定次数</th>
</tr></thead>
<tbody>
<tr>
<td>*</td>
<td>*？</td>
<td>可能出现，可能不出现，出现次数没有上限</td>
</tr>
<tr>
<td>+</td>
<td>+？</td>
<td>至少出现1次，没有上限</td>
</tr>
<tr>
<td>?</td>
<td>??</td>
<td>出现0次或1次</td>
</tr>
<tr>
<td>{m,n}</td>
<td>{m,n}?</td>
<td>出现次数大于等于m，小于等于n</td>
</tr>
<tr>
<td>{m,}</td>
<td>{m,}?</td>
<td>至少出现m次，没有上限</td>
</tr>
<tr>
<td>{0,n}</td>
<td>{0,n}?</td>
<td>出现0次-n次</td>
</tr>
</tbody>
</table>
<h2>提取包含指定内容的行</h2>
<p>假设我们想把表格中有关于<strong>运动员</strong>的记录都提取出来，我们可能会使用<code>/&lt;tr&gt;.*运动员.*&lt;\/tr&gt;/s</code>这样的正则表达式。</p>
<p>这个表达式在Unicode编码环境下可以匹配出结果，但是在GBK环境下就未必了。我们可以通过模式修饰符<code>u</code>来指定Unicode模式：</p>
<p><code>/&lt;tr&gt;.*运动员.*&lt;\/tr&gt;/us</code></p>
<p>在Unicode模式下，我们甚至可以使用<strong>码值</strong>来代替汉字：</p>
<p><code>/&lt;tr&gt;.*\x{8fd0}\x{52a8}\x{5458}.*&lt;\/tr&gt;/us</code></p>
<p>php正则中使用<code>\x{hex}</code>的形式来表示Unicode字符的码值，使用码值的好处是可以结合字符组来表示一段范围，如<code>[\x{4e00}-\x{9fff}]</code>表示匹配所有汉字字符。</p>
<p><img src="/img/bVpObg" alt="图片描述" title="图片描述"></p>
<p>上面的表达式可以匹配出结果，但是却不正确。我们可以看到，它匹配了整个字符串的第一个<code>&lt;tr&gt;</code>到最后一个<code>&lt;/tr&gt;</code>。<br>直觉上，我们是想正则表达式先去匹配“运动员”，然后向左寻找最近的一个<code>&lt;tr&gt;</code>，向右寻找最近的一个<code>&lt;/tr&gt;</code>。但事实上，正则表达式是从左往右匹配的，即从<code>&lt;tr&gt;</code>开始寻找，整个正则表达式的匹配情况见下表（空白字符没有显示出来）。</p>
<table>
<thead><tr>
<th>表达式</th>
<th>匹配值</th>
</tr></thead>
<tbody>
<tr>
<td><code>/</code></td>
<td> </td>
</tr>
<tr>
<td><code>&lt;tr&gt;</code></td>
<td>&lt;tr&gt;</td>
</tr>
<tr>
<td><code>.*</code></td>
<td>&lt;th&gt;用户名&lt;/th&gt;&lt;th&gt;职业&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Kobe Bryant&lt;/td&gt;&lt;td&gt;篮球</td>
</tr>
<tr>
<td><code>运动员</code></td>
<td>运动员</td>
</tr>
<tr>
<td><code>.*</code></td>
<td>&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Jay Chou&lt;/td&gt;&lt;td&gt;歌手、词曲创作人、制作人、演员、导演&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Lionel Messi&lt;/td&gt;&lt;td&gt;足球运动员&lt;/td&gt;</td>
</tr>
<tr>
<td><code>&lt;\/tr&gt;</code></td>
<td>&lt;/tr&gt;</td>
</tr>
<tr>
<td><code>/us</code></td>
<td> </td>
</tr>
</tbody>
</table>
<p>这里两个<code>.*</code>匹配到的字符都比预期要多。第二个<code>.*</code>匹配字符比预期多的原因是正则表达式默认是贪婪匹配模式，它会匹配剩余字符串中的每个字符，直到字符串的末尾，然后再向前回溯到最后一个<code>&lt;/tr&gt;</code>，可以通过指定非贪婪匹配模式来解决这个问题。但是第一个<code>.*</code>匹配字符比预期多是正常现象，因为正则表达式是从左向右匹配的，表达式中的<code>&lt;tr&gt;</code>匹配字符串中第一个<code>&lt;tr&gt;</code>，后面的<code>.*</code>则匹配剩余的所有字符，直到字符串的末尾，然后再向前回溯到“运动员”。</p>
<p>我们先看看使用非贪婪匹配时的结果：</p>
<p><img src="/img/bVpOby" alt="图片描述" title="图片描述"></p>
<p>可以看到，第二个<code>.*</code>匹配的字符已经是我们想要的了。那么，对于第一个<code>.*</code>匹配字符比预期多这个问题怎么解决呢？</p>
<p>如果仅使用到目前为止我的文章中介绍的知识，也是有方法可以解决的。我们可以先从左到右匹配出所有的行（<code>&lt;tr&gt;...&lt;/tr&gt;</code>），方法是使用php中的<code>preg_match_all</code>函数结合非贪婪匹配模式；然后再遍历每一行，过滤出其中包含“运动员”的行即可。</p>
<p>当然，我们也可以通过纯粹的正则表达式来解决这个问题。如果有一定正则表达式使用经验的朋友可能很容易联想到<strong>排除型字符组</strong>，我们介绍过<strong>字符组</strong><code>[...]</code>，它表示在同一位置可能出现的字符。而<strong>排除型字符组</strong>则表示在同一位置不能出现的字符，它的形式是<code>[^...]</code>，通过紧跟在开方括号<code>[</code>后面的<code>^</code>来表示排除型字符组。例如，<code>[^\d]</code>表示匹配的字符是除了数字以外的任意字符。<br>如果有排除型子表达式，类似于<code>(^&lt;tr&gt;)*</code>，我们只需要指定第一个<code>.*</code>把<code>&lt;tr&gt;</code>排除就行了。但是很遗憾，正则表达式中没有排除型子表达式或者说排除型分组。这种情况下，我们只能使用<strong>环视</strong></p>
<p><code>/&lt;tr&gt;(.(?!&lt;tr&gt;))*运动员.*&lt;\/tr&gt;/Us</code></p>
<p><img src="/img/bVpObO" alt="图片描述" title="图片描述"></p>
<p>环视（look-around）不匹配任何字符，用来“停在原地，四处张望”。上面的表达式使用了<strong>否定顺序环视</strong>，它的形式是<code>(?!...)</code>。具体对于<code>(.(?!&lt;tr&gt;))*</code>来分析，每当<code>.</code>匹配了一个字符后，就向右看看，如果当前匹配字符的右边没有出现<code>&lt;tr&gt;</code>就匹配成功。</p>
<p>完整的环视有：</p>
<table>
<thead><tr>
<th>名字</th>
<th>记法</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>肯定顺序环视</td>
<td><code>(?=...)</code></td>
<td>向右看看，右边出现了环视中的内容才匹配</td>
</tr>
<tr>
<td>否定顺序环视</td>
<td><code>(?!...)</code></td>
<td>向右看看，右边不出现环视中的内容才匹配</td>
</tr>
<tr>
<td>肯定逆序环视</td>
<td><code>(?&lt;=...)</code></td>
<td>向左看看，左边出现了环视中的内容才匹配</td>
</tr>
<tr>
<td>否定逆序环视</td>
<td><code>(?&lt;!...)</code></td>
<td>向左看看，左边不出现环视中的内容才匹配</td>
</tr>
</tbody>
</table>
<p>由于上面的正则表达式有一个分组（子表达式），所以匹配的结果除了下标0，还有下标1，这里下标1的结果其实没有什么用，我们可以用之前介绍过的<strong>非捕获分组</strong>：</p>
<p><code>/&lt;tr&gt;(?:.(?!&lt;tr&gt;))*运动员.*&lt;\/tr&gt;/Us</code></p>
<p>我们的真正目的是提取所有包含“运动员”的行，而上面只提取了第一个，所以需要将<code>preg_match</code>函数换成<code>preg_match_all</code>。</p>
<p><img src="/img/bVpOb1" alt="图片描述" title="图片描述"></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003728798";}i:27;a:11:{s:5:"title";s:23:"Gearman 使用小知识";s:4:"link";s:42:"http://segmentfault.com/a/1190000003728682";s:2:"id";s:42:"http://segmentfault.com/a/1190000003728682";s:7:"updated";s:25:"2015-09-09T23:18:52+08:00";s:9:"published";s:25:"2015-09-09T23:18:52+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"Oooooooo";s:10:"author_uri";s:34:"http://segmentfault.com/u/oooooooo";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:4499:"
<p>众所周知，PHP要实现异步任务一般都是通过 <code>Gearman</code> <code>Beanstalkd</code> 等第三方来实现的。目前项目采用的是 <code>Gearman</code> 来实现异步任务。</p>
<h2>关于Gearman介绍</h2>
<p>通俗的来说</p>
<blockquote><p>Gearman是一个分发任务的程序框架,使用Gearman的应用通常有三部分组成：一个Client、一个Worker、一个 任务服务器。 Client的作用是提出一个 Job 任务 交给 Job Server 任务服务器。Job Server 会去寻找一个 合适的 Worker 来完成这项任务。</p></blockquote>
<p>Gearman官方网站地址 <a href="http://gearman.org/">Gearman官网</a></p>
<p>关于Gearman 安装和使用 请参考 <a href="http://segmentfault.com/a/1190000000494087">Gearman安装和使用</a></p>
<h2>PHP使用Gearman</h2>
<p><code>Gearman</code> 请求过程中 涉及的三个 <code>Client -&gt; Job -&gt; Worker</code>。</p>
<pre><code>Client 请求的发起者，可以是C，PHP，Perl，MySQL UDF等等。

Job：请求的调度者，用来负责协调把Client发出的请求转发给合适的Work。

Worker：请求的处理者，可以是C，PHP，Perl等等。</code></pre>
<p><strong>在这个过程中 <code>work</code>要长驻后台时刻准备着被<code>jobserver</code>调用来处理<code>job</code>，所以<code>worker</code>不能死掉</strong></p>
<h2>PHP使用Gream实例（单独函数实现）</h2>
<pre><code>client.php</code></pre>
<pre><code>&lt;?php
    $client= new GearmanClient();
    $client-&gt;addServer('127.0.0.1', 4730);
    $client-&gt;doBackground('say','hello world');</code></pre>
<pre><code>work.php</code></pre>
<pre><code>&lt;?php
    $worker= new GearmanWorker();
    $worker-&gt;addServer("127.0.0.1", 4730);
     $worker-&gt;addFunction("say", "hello");
     while ($worker-&gt;work());
     function hello () {
         //DO SOMETHING...
     }</code></pre>
<p>以上即是 <code>PHP</code> 调用 <code>Gearman</code> 简单的示例。</p>
<p>在我们实际的开发过程中，一般会采用框架进行项目的开发，如果采用以上方式进行调用，肯定会破坏项目原有的文件结构。 以下以<code>ThinkPHP 3.2</code> 版本进行<code>DEMO演示</code>，调用方式跟单文件调用没什么区别，区别在于 <code>work</code>的编写。</p>
<p>因为 <code>work</code>需要长驻后台运行，所以我们要声明文件以 <code>CLI</code> 模式运行。即：</p>
<p>方式一：</p>
<pre><code>&lt;?php
    namespace Sys\Controller；
    use Think\Controller;
    class DemoController extends Controller {
        protected $_config = array(
            'host' =&gt; 'XXXX',
            'port' =&gt; 'XXX'
        );
        public function __construct () {
            $sapi = php_sapi_name();
            if ($sapi != 'cli') {
                exit();
            }
        }
        
        protected function add_work ($job,$func) {
            $worker= new GearmanWorker();
            $worker-&gt;addServer($this-&gt;$_config['host'], $this-&gt;$_config['port']);
            $worker-&gt;addFunction($job, $func);
            while ($worker-&gt;work());
        }
        
        public function test () {
            $this-&gt;add_work('say','\Sys\Controller\DemoController ::say');
        }
        
        static public function say ($job) {
            $data = $job-&gt;workload();
            //DO SOMETHING...
        }
    }
    </code></pre>
<p>方式二：</p>
<pre><code>&lt;?php
    namespace Sys\Controller；
    use Think\Controller;
    class DemoController extends Controller {
        protected $_config = array(
            'host' =&gt; 'XXXX',
            'port' =&gt; 'XXX'
        );
        public function __construct () {
            $sapi = php_sapi_name();
            if ($sapi != 'cli') {
                exit();
            }
        }
        
        protected function add_work ($job,$func) {
            $worker= new GearmanWorker();
            $worker-&gt;addServer($this-&gt;$_config['host'], $this-&gt;$_config['port']);
            $worker-&gt;addFunction($job, $func);
            while ($worker-&gt;work());
        }
        
        public function test () {
            $this-&gt;add_work('say','\Sys\Controller\say');
        }
    }
    
    function say ($job) {
        $data = $job-&gt;workload();
        //DO SOMETHING.....
    }</code></pre>
<p>添加<code>work</code>到后台 格式为 <code>/var/www/index.php Sys/Demo/test </code></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003728682";}i:28;a:11:{s:5:"title";s:37:"DevOps 和技术债务偿还自动化";s:4:"link";s:42:"http://segmentfault.com/a/1190000003728355";s:2:"id";s:42:"http://segmentfault.com/a/1190000003728355";s:7:"updated";s:25:"2015-09-09T22:11:30+08:00";s:9:"published";s:25:"2015-09-09T22:11:30+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:18:"OneAPM蓝海讯通";s:10:"author_uri";s:41:"http://segmentfault.com/u/oneapm_official";s:2:"re";a:1:{s:4:"rank";s:1:"0";}s:7:"summary";s:3195:"
<p>当企业想要迁移到一个 DevOps 模型时，经常需要偿还高等级的<a href="http://martinfowler.com/bliki/TechnicalDebt.html">技术债务</a></p>
<p>说得更明确一点，机构往往陷入「技术债务的恶性循环」中，以至于任何迅速、敏捷的迁移方式都无法使用。这是技术债务中的希腊债务危机水平。</p>
<p>在多数情况下，机构会将层与层之间的流程和管理添加到软件开发生命周期，从而缓解低质量版本、生产等级缺陷、不稳定的环境、性能不佳等问题，然而这么做只能是治标不治本。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/cycle-1.png" alt="DevOps和技术债务偿还自动化" title="DevOps和技术债务偿还自动化"></p>
<p>那么，在企业丧失竞争之前，我们应该如何摆脱这个死亡漩涡，可以快速进行颠覆性创新，同时也腾出时间做一些别的事情。</p>
<p>如今，我们看到的一个整体趋势是，如果机构不断地在 DevOps 自动化上寻找空间，就必须打破这种恶性循环，重新开辟一个新的良性循环。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/virtuous-cycle-of-devops-technical-debt-repayment-2.png" alt="DevOps和技术债务偿还自动化" title="DevOps和技术债务偿还自动化"></p>
<p>如果可以自动完成一些常规的、容易出错的和时间密集型的任务，便可以利用效率和投资，也能将更多的时间和成本投入技术负债偿还中。</p>
<p>在技术债务偿还后，企业将得到一个质量更高、更稳定和更灵活的应用程序，从而可以重新在自动化工作上投入更多的时间，并启动下一个周期的改善和提升。</p>
<p>该途径已经在生产环境中得到验证，但是当下还存在两个注意点：</p>
<p>首先，需要取得产品负责人的承诺，将生产率的提高用于偿还技术债务，而不是无止尽的特性扩展（这很可能是导致当下困境的原因之一）。</p>
<p>同时这里并不存在捷径，事实上机构必须抱着这样的思想——技术债务就像穿过流沙般危险或者技术债务就像带着80磅的背包跑马拉松，那么这里才存在一线生机。</p>
<p>其次，DevOps 不仅仅是自动化，而是 Culture-Automation-Lean-Metrics-Sharing（CALMS），所以这里要做的不仅仅是「自动化的一些工作」，随后即「以产品为核心」的理念。但首先要让产品负责人清晰运营需求，远离经济驱动为中心的项目模型。</p>
<p>原文链接：<a href="http://blog.devopsguys.com/2015/07/31/devops-and-automating-the-repayment-of-technical-debt/"></a><a href="http://blog.devopsguys.com/2015/07/31/devops-and-automating-the-repayment-of-technical-debt/">http://blog.devopsguys.com/2015/07/31/devops-and-automating-the-repayment-of-technical-debt/</a></p>
<p><strong>本文系 |
a5c76229754730010e79b1e5d0e0b55b4
| 工程师编译整理。想阅读更多技术文章，请访问 OneAPM <a href="http://news.oneapm.com/?utm_source=TechCommunity&amp;utm_medium=TechArticle&amp;utm_campaign=JulSoftArti">官方博客</a>。</strong></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003728355";}i:29;a:11:{s:5:"title";s:50:"ReThought (一): 如何构建理想的开发团队";s:4:"link";s:42:"http://segmentfault.com/a/1190000003728329";s:2:"id";s:42:"http://segmentfault.com/a/1190000003728329";s:7:"updated";s:25:"2015-09-09T22:01:33+08:00";s:9:"published";s:25:"2015-09-09T22:01:33+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"phodal";s:10:"author_uri";s:32:"http://segmentfault.com/u/phodal";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:7697:"
<h2>ReThought (一): 如何构建理想的开发团队</h2>
<p><strong>引言</strong>: 过去，关于理想的开发团队似乎是一个热门的话题，所以我也来凑凑热闹。人们想要理想的开发团队，只是因为在传递知识的时候很痛苦。人们总在说，这个地球多你一个不多，少你一个不少。假想有一天你们团队中的主力走了，那么你们的团队会怎样?塞翁失马，焉知非福。</p>
<p>也许上个月我们团队里走了个汉子，来了一个萌妹子。也许下个月会走个老人，那必然也会来个新人。对于个人来说，这是件好事。但是对于团队来说，则有待商榷。于是，也将过去的一系列思考整理成一些文章，方便和以后的想法进行一些对比——有时候会发现最初的想法都挺好的，只是没有记录下来。</p>
<h2>最初的团队</h2>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/team.jpg" alt="Startup Team" title="Startup Team"></p>
<p>有时，我在想最理想的团队莫过于一些创业团队了—— 分工明确。那些还存活着的公司在过去都有着那样理想的团队，然而随着公司业务与团队人数的增长，离这一些越来越远。</p>
<p>在我认识的那些创业公司的前端人员中，多数可能还充当着后台 API、App的开发，原因可归类为:</p>
<ol>
<li><p>招不到人</p></li>
<li><p>没有钱</p></li>
<li><p>不知道招什么人 (他们自己并没有意识到自己不知道)</p></li>
</ol>
<p>如《REWORK》一书中所说的那样，只有在你真正受不了时才招人。如果同那些大公司一样，漫无目的地进行撒网，那么早晚会死在这条路上。通常在那些存活下来的团队(也包含没有存活下来的团队)里，一个人可能身兼多职，会有小部分的重叠，但是不会太多。</p>
<p>在这一个时期主导团队往往是Idea的所有者，Owner找来一个技术人员，这个技术人员再依照短处去寻找需要的人才。</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/mls.jpg" alt="mls" title="mls"></p>
<p>随着公司业务的发展，出于个人、家庭、团队因素，总有些人会离职(人总是有需求的，WiFi应该是最底层的吧)，总需要迎进新人。</p>
<h2>有序的团队</h2>
<p>最初整个宇宙是混乱的、整个系统是混乱的、整个组织是混乱的。通过不断地分门别类，整个系统看上去似乎有序了。</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/sort.jpg" alt="Sort" title="Sort"></p>
<p>在这样的团队里，A做着A应该去做的事，B做着B应该去做的事。</p>
<ol>
<li><p>如果A和B很熟悉，可能产生出ab —— 可能是一个新的系统，也可能是一个新的生物。</p></li>
<li><p>如果A和B不熟悉，那么通过公司的各种各样活动会帮ta们产生ab。</p></li>
<li><p>如果A和B不得已熟悉，那么我想这个ab可能是API。</p></li>
</ol>
<p>在最初的团队里，A和B可能只隔着10cm，后来他们越来越远。</p>
<p>职能分明的团队是一个解耦后的系统，他们间的沟通需要比原来花费更大的开销。在传统IT公司及大部分的互联网公司都有这样的"最后一公里"问题。引自之前的文章<a href="https://www.phodal.com/static/media/uploads/rethink/https://www.phodal.com/blog/knowledge-transfer-part-1/">《知识论(一): 知识传递》</a> :</p>
<blockquote><p>传统软件开发流程中，知识传递的方式主要在于文档，而我相信在网上已经有足够的证据可以表明，程序员既讨厌看文档，又讨厌写文档。</p></blockquote>
<p>无论是在系统集成环节，又或者是在交接环节，人们所做的一件事只是知识传递。因为职责让你不可能接触太多的东西，就好比原来你可以每天吃一点的药，突然要你在短期内吃完。</p>
<h2>理想团队</h2>
<p>团队类似于人物文明，更多地在于文化与知识的传承。人们想要一个理想的团队，但是他们往往并不知道他们真正的问题不在于团队本身——而在于团队是如何协作的。</p>
<h3>理想型A</h3>
<p>在多数的公司里，团队的组成方式类似于下图:</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/small.jpg" alt="Small Team" title="Small Team"></p>
<p>如果有一天大牛出车祸了，中牛roll off了，团队就剩下一堆绿帽子了...</p>
<p>在这样的团队里，我们可能会用下面的方式来教授团队的成员:</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/class-example.jpg" alt="Class Room" title="Class Room"></p>
<p>即类似于传统的授课制:</p>
<ol>
<li><p>你今天去把《Thinking Java》看一遍</p></li>
<li><p>你今天去把《设计模式》看一下</p></li>
<li><p>...</p></li>
</ol>
<p>在这时候，那些领悟力比较好的就在NB的路上了，但是每次只会有那么一两个人。</p>
<h3>理想型B</h3>
<p>在另外一个理想型的团队里，人们想要的是这样的结构。</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/full-stack.jpg" alt="Full Stack" title="Full Stack"></p>
<p>我想不到这样的团队还有怎样的知识可以传递。在这样的团队里，传递知识是相当于容易，因为大家很容易就懂得别人说的内容。</p>
<p>让团队中的每一个人都是全栈程序员的难度很大，然而这并不意味着这样的团队不可构建。</p>
<h2>构建理想团队</h2>
<p>在过去我们有师徒制，这样可以保证师徒间知识可以传递下来。而在多数的软件开发团队里，并不存在这样的制度，换句话说在这样的环境成长时，你只能依靠你自己。</p>
<blockquote><p><em>在一个团队里，当来了一个新人时你们会怎么做？</em></p></blockquote>
<p>如果你是一个新人，你来到这样的一个团队:</p>
<ol>
<li><p>A 教你如何使用各种快捷键。</p></li>
<li><p>B 教你使用一些特定语言的技巧。</p></li>
<li><p>C 教你一些基本的DevOps技能。</p></li>
<li><p>D 教你怎么追妹子。</p></li>
<li><p>......</p></li>
</ol>
<p>你会考虑加入这样的团队吗?</p>
<h3>结对编程</h3>
<p>或出于公司文化，或出于对自己的不明确认知，多数市场主导的公司并不会采用这样的方式来工作。这也导致了人们一直在追逐理想的开发团队时，一直找不到合适的时机。</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/pair.jpeg" alt="Pair Programming" title="Pair Programming"></p>
<p>这时，也许会有人提醒你，你多了个分号。我曾经在看别人的面试作业时因为多了分号，reject了一个人——因为语言是Python。</p>
<p>而这时候团队的组成，倾向于下图(图是盗的，上面的图也都是盗的 :) ):</p>
<p><img src="https://www.phodal.com/static/media/uploads/rethink/skill-radar.jpg" alt="Skill" title="Skill"></p>
<p>在这样的团队里，并非每个人的技能都需要是一样的。会出现重叠，一个比一个强，可能有一个的技能点数是最强的。项目在不断开发地过程中，总会有人离职，有新人进来。</p>
<p>然而，在这个结对编程的过程中，知识都在不断地传递。</p>
<p>(ps: 上面只是提到了结对编程会构成理想团队，更多内容请期待下文《ReThink2: 如何照顾团队中的新人》(9月10号))</p>
<p>转载保留: <a href="https://www.phodal.com/blog/rethink-one-build-dream-team/">ReThought (一): 如何构建理想的开发团队</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003728329";}i:30;a:11:{s:5:"title";s:60:"使用git和github管理自己的项目---基础操作学习";s:4:"link";s:42:"http://segmentfault.com/a/1190000003728094";s:2:"id";s:42:"http://segmentfault.com/a/1190000003728094";s:7:"updated";s:25:"2015-09-09T20:46:31+08:00";s:9:"published";s:25:"2015-09-09T20:46:31+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"xumenger";s:10:"author_uri";s:34:"http://segmentfault.com/u/xumenger";s:2:"re";a:1:{s:4:"rank";s:1:"5";}s:7:"summary";s:32172:"
<p>我是通过看<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000">廖雪峰的git教程</a>学习的，真的是极好的，以下是我学习过程中的总结，记录下来，方便自己参考以熟悉git和github的使用。</p>
<p>除了廖雪峰的教程，还比较推荐在看完廖雪峰的教程之后，再看这样一篇文章：<a href="http://segmentfault.com/a/1190000002413519">使用git和github进行协同开发流程</a>，和我的另一篇git的笔记：<a href="http://segmentfault.com/a/1190000003739324">使用git和github管理自己的项目---真实开发环境的策略</a> ，深入了解github和git怎么在具体的项目开发中管理项目、有什么好的规范！</p>
<p>我这里记录git的学习笔记，方便随时参考，具体的<strong>git的原理</strong>、<strong>github的原理</strong>、<strong>集中式和分布式版本控制的区别</strong>、<strong>版本控制的概念和原理</strong>、<strong>Git和其他版本控制工具比如SVN的区别</strong>、以及更多的相关<strong>概念讲解</strong>，请自己参见<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000">廖雪峰的git教程</a>。</p>
<blockquote><p>我强烈推荐先看廖雪峰的git教程来系统化认识和学习git，然后自己整理一份具体的步骤方便平时开发时快速参考，或者直接参考我的。</p></blockquote>
<p>先说一个比较好笑的事：廖雪峰的git教程中，刚开始的部分的浏览量有38万，但是最后一页教程的网页的浏览量是1万多。</p>
<p>以前因为觉得git、github比较难，所以一直拖着不学，现在去尝试学习，一晚上就OK了</p>
<ul>
<li><p>重点之一是找到全面的、详细的、生动的、高质量的教程。廖雪峰的git教程是我目前找到的最好的一个。之前找到的讲解git用法的书<a href="http://git-scm.com/book/zh/v1%E3%80%81">《pro git》</a>现在看来是没有必要再看了！</p></li>
<li><p>重点之二就是自己立即去学，其实没什么难的，不要被貌似难的表象、概念唬住。</p></li>
<li><p>重点之三是最好能自己做简单的、系统的整理，方便自己随时再回来查看、复习、参考，不至于出现这样的情况：学完以后过一段时间之后再用，但是这时候发现忘了差不多了！</p></li>
<li><p>重点之四就是立即动手去用，否则学完很快就忘了。</p></li>
</ul>
<blockquote><p>有钱的买mac，没钱的用ubuntu--或者其他的linux发行版、被逼无奈的用Windows--但是被逼之余的自主时间一定要远离Windows。</p></blockquote>
<p>现在我的测试环境是ubuntu。</p>
<p>以对一个文件的管理为例，简单说明git的使用。另外需要说明的是下面的实验过程主要是只针对一个文件、并且修改的次数往往只有一次，而在真正的项目中，往往有大量的文件，也可能多次修改后才合并，合并时候的冲突可能也不只一两个，等等。不过原理都是一样的，我想说的是，不要局限在这个教程的示例上，请自己通过教程掌握基本的远原理之后，自己推广、去大量的实践，最重要的是要制定一个好的版本控制的策略（合理分工、安排，还是尽可能的避免冲突为好），这个可以参考：<a href="http://segmentfault.com/a/1190000002413519">使用git和github进行协同开发流程</a>以及我的学习笔记<a href="http://segmentfault.com/a/1190000003739324">使用git和github管理自己的项目---真实开发环境的策略</a>。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013743256916071d599b3aed534aaab22a0db6c4e07fd0000">1.创建版本库</a></h2>
<ul>
<li><p><code>sudo apt-get install git</code> 先安装git</p></li>
<li><p>先创建目录，作为仓库</p></li>
<li><p><code>git init</code> 初始化仓库，可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了</p></li>
<li><p><code>vim readme.txt</code> 新建一个文本文件，比如往里面添加简单的一行字符串</p></li>
<li><p><code>git add readme.txt</code> 添加一个文件，比如readme.txt，如果目录里面的所有文件都要添加，可以<code>git add *</code></p></li>
<li><p><code>git commit-m "添加一个readme.txt文件"</code> 将文件提交到仓库，并加上说明（这时候是版本1）</p></li>
<li><p>如果是第一次使用git，那么git commit可能报错，所以需要你配置一些个人信息</p></li>
<li><p><code>git config --global user.email "you@example.com"</code> 配置邮件</p></li>
<li><p><code>git config --global user.name "Your Name"</code> 配置用户名</p></li>
<li><p>必须配置，否则后面的commit、push到远程库都会失败</p></li>
<li><p>然后再次<code>git commit -m "添加一个readme.txt文件"</code> 才会成功</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013743858312764dca7ad6d0754f76aa562e3789478044000">2.提交修改</a></h2>
<ul>
<li><p>假如此时<strong>第一次</strong>修改了readme.txt文件</p></li>
<li><p><code>git status</code> 让我们时刻掌握仓库当前的状态。这时告诉我们，readme.txt被修改过了，但还没有准备提交的修改。</p></li>
<li><p><code>git diff readme.txt</code> 查看对readme.txt做了什么修改</p></li>
<li><p><code>git add readme.txt</code> 提交修改和提交新文件是一样，先git add</p></li>
<li><p><code>git status</code> 可以再用git status查看仓库的当前状态，告诉我们，将要被提交的修改包括readme.txt</p></li>
<li><p><code>git commit-m "第一次修改"</code>  然后再git commit，并添加修改的描述（这时候是版本2）</p></li>
<li><p><code>git status</code> 可以再执行git status看仓库状态，因为所有的都提交了，Git告诉我们当前没有需要提交的修改，而且，工作目录是干净（working directory clean）的。</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013744142037508cf42e51debf49668810645e02887691000">3.版本回退</a></h2>
<ul>
<li><p>你可以像上面所说的那样不停的提交新的文件、提交对文件的修改</p></li>
<li><p>这时候第二次修改readme.txt文件</p></li>
<li><p><code>git add readme.txt</code> 先git add</p></li>
<li><p><code>git commit -m "第二次修改"</code>  提交第二次修改（这时候是版本3）</p></li>
<li><p><code>git log</code> 显示从最近到最远的提交日志，具体显示的内容自己试一试看看</p></li>
<li><p><code>git log --pretty=oneline</code> 如果嫌输出信息太多，看得眼花缭乱，试试加上--pretty=oneline参数</p></li>
<li><p>看<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013744142037508cf42e51debf49668810645e02887691000">这篇教程</a>去理解为什么Git的版本号要这么长，Git的版本号类似：3628164fb26d48395383f8f31179f24e0882e1e0 这样的特别长的十六进制数。</p></li>
<li><p><code>git reset --hard HEAD^</code> 会回退到上一个版本，也就是从版本3回退到版本2</p></li>
<li><p>在Git中，用HEAD表示当前版本，也就是最新的提交3628164...882e1e0（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100</p></li>
<li><p><code>vim readme.txt</code> 可以看到此时的readme.txt文件就是版本2时候的内容，回退成功！</p></li>
<li><p><code>git log</code> 此时看到版本3的信息没有了</p></li>
<li><p><code>git reset --hard 3628164</code> 通过命令行上的历史信息（假如你没清屏的话），找到版本3 的版本号，不一定要全部的版本号，就像这个命令的例子，只要前面的约7、8位这样就可以指定回到版本3</p></li>
<li><p><code>vim readme.txt</code> 看到的是第三版本的readme.txt文件的内容，所以又回来了</p></li>
<li><p>Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向你要回退的那个版本</p></li>
<li><p><code>git reflog</code> 记录你的每一次命令，最先显示的是这个命令执行之后的版本的版本号的前七位，这样就算你清屏了或者重启了，也能找到某个版本的版本号，就可以轻松回退到那个版本</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013745374151782eb658c5a5ca454eaa451661275886c6000">4.工作区、版本库和暂存区</a></h2>
<p><strong>工作区</strong>：就是你在电脑里能看到的目录，比如我的learngit文件夹就是一个工作区。</p>
<p><strong>版本库</strong>：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。</p>
<p><strong>暂存区</strong>：Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。</p>
<p>前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：</p>
<ol>
<li><p>第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；</p></li>
<li><p>第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。</p></li>
</ol>
<p>因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。</p>
<p>你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</p>
<p>详细知识见<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013745374151782eb658c5a5ca454eaa451661275886c6000">这篇教程</a>。必须理解暂存区、工作区、版本库。这些都是是Git非常重要的概念，弄明白了这些概念，就弄明白了Git的很多操作到底干了什么。<strong>没弄明白的话，请反复看！！</strong></p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374829472990293f16b45df14f35b94b3e8a026220c5000">5.管理修改</a></h2>
<p>为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。</p>
<p>什么是修改？比如你新增了一行，这就是一个修改，删除了一行，也是一个修改，更改了某些字符，也是一个修改，删了一些又加了一些，也是一个修改，甚至创建一个新文件，也算一个修改。</p>
<p>通过实例讲解什么叫跟踪修改，要想理解，请参考<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374829472990293f16b45df14f35b94b3e8a026220c5000">原文</a>结合暂存区的知识理解：</p>
<ul>
<li><p><code>vim readme.txt</code> 编辑文件，比如添加新的一行</p></li>
<li><p><code>git add readme.txt</code> 添加，但是不提交</p></li>
<li><p><code>vim readme.txt</code> 再编辑文件，比如再添加一行</p></li>
<li><p><code>git commit -m "修改两次，添一次，提交一次"</code> 提交</p></li>
<li><p><code>git status</code> 看到的效果是：只提交了第一次的修改，第二次的修改没有提交</p></li>
</ul>
<p>那怎么提交第二次修改呢？你可以继续<code>git add</code>再<code>git commit</code>，也可以别着急提交第一次修改，先<code>git add</code>第二次修改，再<code>git commit</code>，也就是<code>第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit</code>，就相当于把两次修改合并后一块提交了。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374831943254ee90db11b13d4ba9a73b9047f4fb968d000">6.撤销修改</a></h2>
<p><strong>第一种情况</strong></p>
<ul>
<li><p>修改了readme.txt文件，还没有git add 和git commit</p></li>
<li><p>但是在你提交之前发现这次修改有问题。既然错误发现得很及时，就可以很容易地纠正它。你可以手动把文件恢复到上一个版本的状态。</p></li>
<li><p><code>git checkout -- readme.txt</code> 也可以通过命令撤销修改，这条命令的意思就是，把readme.txt文件在工作区的修改全部撤销</p></li>
<li><p>无论是文件修改后值存在于工作区还没有放到暂存区，还是已经添加到暂存区，总之这个命令就是让这个文件回到最近一次git commit或git add时的状态。</p></li>
<li><p>查看文件，内容果然复原了。git checkout -- file命令中的<code>--</code>很重要，没有<code>--</code>，就变成了“切换到另一个分支”的命令，我们在后面的分支管理中会再次遇到git checkout命令。</p></li>
</ul>
<p><strong>第二种情况</strong></p>
<ul>
<li><p>修改了readme.txt文件，而且执行了<code>git add readme.txt</code></p></li>
<li><p>庆幸的是你在 git commit 之前发现了这个问题</p></li>
<li><p><code>git status</code> 查看一下，修改只是添加到了暂存区，还没有提交</p></li>
<li><p><code>git reset HEAD readme.txt</code> 可以把暂存区的修改撤销掉，重新放回工作区。git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。</p></li>
<li><p><code>git status</code> 查看一下，现在暂存区是干净的，工作区有修改</p></li>
<li><p><code>git checkout -- readme.txt</code> 还记得第一种情况中如何丢弃工作区的修改吧</p></li>
</ul>
<p><strong>第三种情况</strong></p>
<p>现在，假设你不但改错了东西，还从暂存区提交到了版本库，怎么办呢？还记得版本回退一节吗？可以回退到上一个版本。不过，这是有条件的，就是你还没有把自己的本地版本库推送到远程。</p>
<p>还记得Git是分布式版本控制系统吗？我们后面会讲到远程版本库，一旦你把错误的修改（如果是影响很大的错误）提交推送到远程版本库，你就真的惨了……</p>
<p>区别对待本地版本库和远程版本库！</p>
<h2>7.删除文件</h2>
<p>在Git中，删除也是一个修改操作</p>
<ul>
<li><p>添加一个新的文件 test.txt</p></li>
<li><p><code>git add test.txt</code></p></li>
<li><p><code>git commit test.txt -m "再次新增一个文件"</code></p></li>
<li><p>一般情况下，你通常会在文件管理器中把没用的文件删除，或者直接<code>rm test.txt</code></p></li>
<li><p><code>git status</code> 这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了</p></li>
<li><p>现在你有两个选择，一是确实从版本库中删除该文件，那就<code>git rm test.txt</code>，然后<code>git commit</code> 文件就从版本库中删除了</p></li>
<li><p>另一种情况是删除错了，因为版本库里还有，所以可以轻松地将误删除的文件恢复到最新版本<code>git checkout -- test.txt</code> git checkout其实使用版本库中的版本替换工作区的版本，无论工作区是修改还是删除，都可以'一键还原'</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013752340242354807e192f02a44359908df8a5643103a000">8.添加远程库</a></h2>
<p>要想学习这部分的知识，请先参考下面的：<strong>a.配置连接远程仓库Github</strong>。</p>
<ul>
<li><p>假如现在你已经配置好github，并且在github上添加了<code>learngit</code>仓库。</p></li>
<li><p><code>git remote add origin git@github.com:michaelliao/learngit.git</code>  这个命令是在本地的learngit仓库下执行的，前面通过learngit仓库为例我们已经讲过在本地创建和操作git仓库。这两个地方的仓库名不需要相同，因为会通过在本地的仓库目录下执行这条命令（命令中包含远程库的名字）已经将两者建立了联系</p></li>
<li><p>请千万注意，把上面的michaelliao替换成你自己的GitHub账户名，否则，你在本地关联的就是我的远程库，关联没有问题，但是你以后推送是推不上去的，因为你的SSH Key公钥不在我的账户列表中。</p></li>
<li><p><code>git push -u origin master</code> 把本地库的所有内容推送到远程库上。把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。</p></li>
<li><p>然后去Github对应的远程库看看，都已经推送上去了。</p></li>
<li><p>此后，每次本地提交后，只要有必要，就可以使用命令<code>git push origin master</code>推送最新修改。</p></li>
</ul>
<blockquote><p>这样你就可以在Github上托管你的项目代码、vim的配置文件和插件、重要的文档……</p></blockquote>
<p>现在我的vim的配置文件和插件已经同步到Github上了：<a href="https://github.com/xumenger/myVimConfig"></a><a href="https://github.com/xumenger/myVimConfig">https://github.com/xumenger/myVimConfig</a></p>
<p>另外推荐我的关于vim配置的文章：：<a href="http://segmentfault.com/a/1190000003722928"></a><a href="http://segmentfault.com/a/1190000003722928">http://segmentfault.com/a/1190000003722928</a></p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375233990231ac8cf32ef1b24887a5209f83e01cb94b000">9.从远程库克隆</a></h2>
<ul>
<li><p>假设我的github上面有一个远程库，但是本地没有，需要克隆到本地，远程库的名字叫'gitskills'</p></li>
<li><p><code>git clone git@github.com:michaelliao/gitskills.git</code> 克隆一个本地库</p></li>
<li><p><code>cd gitskills</code> 进入克隆下来的本地库，默认的名字是和github上的一样的</p></li>
<li><p><code>ls -al</code> 可以看到本地的克隆库里面是和远程库里面的一样的</p></li>
<li><p>如果有多个人协作开发，那么每个人各自从远程克隆一份就可以了。</p></li>
</ul>
<p>你也许还注意到，GitHub给出的地址不止一个，还可以用<a href="https://github.com/michaelliao/gitskills.git">https://github.com/michaelliao/gitskills.git</a>这样的地址。实际上，Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。</p>
<p>使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013743862006503a1c5bf5a783434581661a3cc2084efa000">10.分支管理</a></h2>
<p>分支在实际中有什么用呢？假设你准备开发一个新功能，但是需要两周才能完成，第一周你写了50%的代码，如果立刻提交，由于代码还没写完，不完整的代码库会导致别人不能干活了。如果等代码全部写完再一次提交，又存在丢失每天进度的巨大风险。</p>
<p>现在有了分支，就不用怕了。你创建了一个属于你自己的分支，别人看不到，还继续在原来的分支上正常工作，而你在自己的分支上干活，想提交就提交，直到开发完毕后，再一次性合并到原来的分支上，这样，既安全，又不影响别人工作。</p>
<p>其他版本控制系统如SVN等都有分支管理，但是用过之后你会发现，这些版本控制系统创建和切换分支比蜗牛还慢，简直让人无法忍受，结果分支功能成了摆设，大家都不去用。</p>
<p>但Git的分支是与众不同的，无论创建、切换和删除分支，Git在1秒钟之内就能完成！无论你的版本库是1个文件还是1万个文件。</p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375840038939c291467cc7c747b1810aab2fb8863508000">11.创建和合并分支</a></h2>
<p>首先教程中会详细讲解分支的原理（分支、指针、工作区……），一定要好好看！！看完之后你才能对你的创建分支和合并分支的操作不只是会用，更能在用的时候没有任何疑惑！反正能学到更多的知识，何乐而不为！</p>
<p>另外推荐这样的博客：<a href="http://segmentfault.com/a/1190000002413519">使用git和github进行协同开发流程</a>以及我的学习笔记<a href="http://segmentfault.com/a/1190000003739324">使用git和github管理自己的项目---真实开发环境的策略</a>。</p>
<p>在<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013744142037508cf42e51debf49668810645e02887691000">版本回退</a>里，你已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，我们练习的learngit，只有一条时间线，在Git里，这个分支叫主分支，即<code>master</code>分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。</p>
<p>开始实战：</p>
<ul>
<li><p><code>git checkout -b dev</code> 创建一个新的分支：dev，并且会切换到dev分支。所以这条命令有两个作用。git checkout命令加上-b参数表示创建并切换，相当于以下两条命令：<code>git branch dev</code> 和 <code>git checkout dev</code></p></li>
<li><p>补充：所有的git管理的项目刚开始时候默认有一条分支：master</p></li>
<li><p><code>git branch</code> 查看当前所在的分支。git branch命令会列出所有分支，当前分支前面会标一个*号。</p></li>
<li><p>因为切换到dev分支，所以我们现在可以在dev分支上正常提交，比如对readme.txt做一个修改</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "提交到dev分支"</code></p></li>
<li><p><code>git checkout master</code> 现在，dev分支的工作完成，我们就可以切换回master分支</p></li>
<li><p><em>*注意</em>:*切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变</p></li>
<li><p><code>git merge dev</code> 这是在master分支上执行的命令，作用是：把dev分支上的工作成果合并到master分支上</p></li>
<li><p>git merge命令用于合并指定分支到当前分支。合并后，再查看readme.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。当然，也不是每次合并都能Fast-forward，我们后面会将其他方式的合并。</p></li>
<li><p><code>git branch -d dev</code> 合并完成之后，可以放心的删除dev分支了</p></li>
<li><p><code>git branch</code> 删除后，查看branch，只剩下master了</p></li>
</ul>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375840202368c74be33fbd884e71b570f2cc3c0d1dcf000">12.解决冲突</a></h2>
<p>教程中有详细的图文说明，很形象，很好！一定要参考！</p>
<p>人生不如意之事十之八九，合并分支往往也不是一帆风顺的。</p>
<ul>
<li><p><code>git checkout -b feature1</code> 创建新的分支feature1，并且换到这个分支，进行新的实验</p></li>
<li><p>在feature1分支下，假如将readme.txt的最后一行由"test branch" 改为"test feature1"</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "在feature1上修改readme.txt的最后一行"</code> 在feature1分支上提交</p></li>
<li><p><code>git checkout master</code> 切换到master分支。Git还会自动提示我们当前master分支比远程的master分支要超前1个提交。</p></li>
<li><p>在master分支下，假如将readme.txt的最后一行由"test branch" 改为"test master"因为上面的是在feature1上进行的修改，所以切换回master之后，看到的文件并不是在feature1上修改后的文件</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "又在master上修改了readme.txt文件"</code>  在master上也提交修改</p></li>
<li><p>现在，master分支和feature1分支各自都分别有新的提交</p></li>
<li><p><code>git merge feature1</code> 在master分支上执行该命令，与feature1分支合并。这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突，果然冲突了！Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交</p></li>
<li><p><code>git status</code> git status也可以告诉我们冲突的文件</p></li>
<li><p>这时候使用vim等编辑器打开readme.txt文件可以看到已经在readme.txt文件中将冲突的信息已经添加到里面了，Git用<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>，<code>=======</code>，<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code>标记出不同分支的内容</p></li>
<li><p>然后我们编辑readme.txt文件，处理冲突，将内容改成我们想要的样子</p></li>
<li><p><code>git add readme.txt</code></p></li>
<li><p><code>git commit -m "解决冲突"</code> 在master上提交</p></li>
<li><p><code>git log --graph --pretty=oneline --abbrev-commit</code> 用带参数的git log可以看到分支的合并情况。用<code>git log --graph</code>命令可以看到分支合并图。</p></li>
<li><p><code>git branch -d feature1</code> 最后删除feature分支，完成工作。</p></li>
</ul>
<p>2015.09.09 今天就学到这里，实在太晚了，赶紧睡觉，明天还得工作！什么都没有身体重要！<br>明天继续：<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758410364457b9e3d821f4244beb0fd69c61a185ae0000">分支管理策略</a></p>
<h2><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374385852170d9c7adf13c30429b9660d0eb689dd43a000">a.配置连接远程仓库Github</a></h2>
<p>首先看这篇文章了解git和SVN的区别，毕竟现在必须在工作中使用的就是SVN，所以还是弄清楚两者的区别。</p>
<p>Git是分布式版本控制系统，同一个Git仓库，可以分布到不同的机器上。怎么分布呢？最早，肯定只有一台机器有一个原始版本库，此后，别的机器可以“克隆”这个原始版本库，而且每台机器的版本库其实都是一样的，并没有主次之分。</p>
<p>实际情况往往是这样，找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。</p>
<p>完全可以自己搭建一台运行Git的服务器，不过现阶段，为了学Git先搭个服务器绝对是小题大作。好在这个世界上有个叫GitHub的神奇的网站，从名字就可以看出，这个网站就是提供Git仓库托管服务的，所以，只要注册一个GitHub账号，就可以免费获得Git远程仓库。</p>
<p>在继续阅读后续内容前，请自行注册GitHub账号。由于你的本地Git仓库和GitHub仓库之间的传输是通过SSH加密的，所以，需要一点设置：</p>
<ol>
<li><p>创建SSH Key。在<code>用户目录</code>下，看看有没有<code>.ssh</code>目录，如果有，再看看这个目录下有没有<code>id_rsa</code>和<code>id_rsa.pub</code>这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key，输入命令<code>ssh-keygen -t rsa -C "youremail@example.com"</code>,你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可，由于这个Key也不是用于军事目的，所以也无需设置密码。如果一切顺利的话，可以在用户主目录里找到<code>.ssh</code>目录，里面有<code>id_rsa</code>和<code>id_rsa.pub</code>两个文件，这两个就是SSH Key的秘钥对，<code>id_rsa</code>是私钥，不能泄露出去，<code>id_rsa.pub</code>是公钥，可以放心地告诉任何人。</p></li>
<li><p>登陆GitHub，打开“Account settings”，“SSH Keys”页面.然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴<code>id_rsa.pub</code>文件的内容：<br><img src="/img/bVpN2Q" alt="图片描述" title="图片描述"></p></li>
<li><p>点“Add Key”，你就应该看到已经添加的Key：<br><img src="/img/bVpN2U" alt="图片描述" title="图片描述"></p></li>
</ol>
<p>注意现在的Github的页面的布局可能和图片中显示有细小的差别，不过相信你能找到对应的操作！</p>
<p>为什么GitHub需要SSH Key呢？因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。</p>
<p>当然，GitHub允许你添加多个Key。假定你有若干电脑，你一会儿在公司提交，一会儿在家里提交，只要把每台电脑的Key都添加到GitHub，就可以在每台电脑上往GitHub推送了。</p>
<p>最后友情提示，在GitHub上免费托管的Git仓库，任何人都可以看到喔（但只有你自己才能改）。所以，不要把敏感信息放进去。</p>
<p>如果你不想让别人看到Git库，有两个办法，一个是交点保护费，让GitHub把公开的仓库变成私有的，这样别人就看不见了（不可读更不可写）。另一个办法是自己动手，搭一个Git服务器，因为是你自己的Git服务器，所以别人也是看不见的。这个方法我们后面会讲到的，相当简单，公司内部开发必备。</p>
<p>现在的情景是，你已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作，真是一举多得。具体可以见<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013752340242354807e192f02a44359908df8a5643103a000">教程</a>。</p>
<p>首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库：<br><img src="/img/bVpN31" alt="图片描述" title="图片描述"></p>
<p>在Repository name填入<code>learngit</code>，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库：</p>
<p><img src="/img/bVpN39" alt="图片描述" title="图片描述"></p>
<p>目前，在GitHub上的这个learngit仓库还是空的，GitHub告诉我们，可以从这个仓库克隆出新的仓库，也可以把一个已有的本地仓库与之关联，然后，把本地仓库的内容推送到GitHub仓库。</p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003728094";}i:31;a:11:{s:5:"title";s:55:"MySQL主主复制+LVS+Keepalived实现MySQL高可用性";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727841";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727841";s:7:"updated";s:25:"2015-09-09T19:20:51+08:00";s:9:"published";s:25:"2015-09-09T19:20:51+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"bestvivi";s:10:"author_uri";s:34:"http://segmentfault.com/u/bestvivi";s:2:"re";a:1:{s:4:"rank";s:1:"2";}s:7:"summary";s:12978:"
<p><a href="http://bestvivi.com/2015/09/06/MySQL%E5%A4%8D%E5%88%B6%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%90%AD%E5%BB%BA">MySQL复制</a>能够保证数据的冗余的同时可以做读写分离来分担系统压力，如果是主主复制还可以很好的避免主节点的单点故障。但是MySQL主主复制存在一些问题无法满足我们的实际需要：未提供统一访问入口来实现负载均衡，如果其中master宕掉的话需要手动切换到另外一个master，而不能自动进行切换。</p>
<p>这篇文章下面要介绍如何通过LVS+Keepalived的方式来是实现MySQL的高可用性，同时解决以上问题。</p>
<h2>Keepalived和LVS介绍</h2>
<p>Keepalived是一个基于<a href="http://datatracker.ietf.org/wg/vrrp/documents/">VRRP</a>（虚拟路由冗余协议）可用来实现服务高可用性的软件方案，避免出现单点故障。Keepalived一般用来实现轻量级高可用性，且不需要共享存储，一般用于两个节点之间，常见有LVS+Keepalived、Nginx+Keepalived组合。</p>
<p><a href="http://www.linux-vs.org/index.html">LVS</a>(Linux Virtual Server)是一个高可用性虚拟的服务器集群系统。本项目在1998年5月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一。<br>LVS主要用于多服务器的负载均衡，作用于网络层。LVS构建的服务器集群系统中，前端的负载均衡层被称为Director Server；后端提供服务的服务器组层被称为Real Server。通过下图可以大致了解LVS的基础架构。<br><img src="http://blogyangwei.qiniudn.com/mysql_lvs_keep01.png" alt="abc" title="abc"></p>
<p>LVS有三种工作模式，分别是DR（Direct Routing 直接路由）、TUN(Tunneling IP隧道）、NAT（Network Address Translation 网络地址转换）。其中TUN模式能够支持更多的Real Server，但需要所有服务器支持IP隧道协议；DR也可以支持相当的Real Server，但需要保证Director Server虚拟网卡与物理网卡在同一网段；NAT扩展性有限，无法支持更多的Real Server，因为所有的请求包和应答包都需要Director Server进行解析再生，影响效率。 同时，LVS负载均衡有10中调度算法，分别是rr、wrr、lc、wlc、lblc、lblcr、dh、sh、sed、nq</p>
<p>详细的LVS说明请参见 <a href="http://bestvivi.com">传送门</a></p>
<p>本文中将利用LVS实现MySQL的读写负载均衡，Keepalived避免节点出现单点故障。</p>
<h2>LVS+Keepalived配置</h2>
<h4>环境准备</h4>
<p>LVS1：192.168.1.2</p>
<p>LVS2：192.168.1.11</p>
<p>MySQL Server1：192.168.1.5</p>
<p>MySQL Server2：192.168.1.6</p>
<p>VIP：192.168.1.100</p>
<p>OS: CentOS 6.4</p>
<p><img src="http://blogyangwei.qiniudn.com/mysql_lvs_keep04.png" alt="架构图" title="架构图"></p>
<p><strong>Keepalive安装</strong></p>
<p><a href="http://www.keepalived.org/software/">keepalived下载地址</a></p>
<p>需要安装以下软件包</p>
<pre><code># yum install -y kernel-devel openssl openssl-devel
</code></pre>
<p>解压keepalived到/usr/local/并进入目录执行配置编译</p>
<pre><code># ./configure --prefix=/usr/local/keepalived --with-kernel-dir=/usr/src/kernels/2.6.32-431.5.1.el6.x86_64/
Keepalived configuration
------------------------
Keepalived version       : 1.2.13
Compiler                 : gcc
Compiler flags           : -g -O2
Extra Lib                : -lssl -lcrypto -lcrypt 
Use IPVS Framework       : Yes
IPVS sync daemon support : Yes
IPVS use libnl           : No
fwmark socket support    : Yes
Use VRRP Framework       : Yes
Use VRRP VMAC            : Yes
SNMP support             : No
SHA1 support             : No
Use Debug flags          : No

# make &amp;&amp; make install
</code></pre>
<p>默认情况下keepalived启动时会去/etc/keepalived目录下找配置文件，将需要的配置文件拷贝到指定位置</p>
<pre><code>
# cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/
# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/
# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/
# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/
# chkconfig mysqld on
# chkconfig keepalived on
</code></pre>
<p><strong>LVS安装</strong></p>
<p><a href="http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz">ipvsadm下载地址</a></p>
<p>需要安装以下软件包</p>
<pre><code># yum install -y libnl* popt*
</code></pre>
<p>查看是否加载lvs模块</p>
<pre><code># modprobe -l |grep ipvs
</code></pre>
<p>解压安装</p>
<pre><code># ln -s /usr/src/kernels/2.6.32-431.5.1.el6.x86_64/ /usr/src/linux
# tar -zxvf ipvsadm-1.26.tar.gz
# make &amp;&amp; make install
</code></pre>
<p>LVS安装完成，查看当前LVS集群</p>
<pre><code># ipvsadm -L -n
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
</code></pre>
<h4>LVS+Keepalived配置</h4>
<p><strong>搭建MySQL主主复制</strong></p>
<p>这里不再赘述，请参考<a href="http://bestvivi.com/2015/09/06/MySQL%E5%A4%8D%E5%88%B6%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%90%AD%E5%BB%BA">MySQL复制</a></p>
<p><strong>配置Keepalived</strong></p>
<p>下面是LVS1节点（Keepalived主节点）上的Keepalived配置，LVS2类似</p>
<pre><code># vim /etc/keepalived/keepalived.conf    

! Configuration File for keepalived

global_defs {
   router_id LVS1
}

vrrp_instance VI_1 {
    state MASTER #指定instance初始状态，实际根据优先级决定.backup节点不一样
    interface eth0 #虚拟IP所在网
    virtual_router_id 51 #VRID，相同VRID为一个组，决定多播MAC地址
    priority 100 #优先级，另一台改为90.backup节点不一样
    advert_int 1  #检查间隔
    authentication {
        auth_type PASS  #认证方式，可以是pass或ha
        auth_pass 1111  #认证密码
    }
    virtual_ipaddress {
        192.168.1.100  #VIP
    }
}

virtual_server 192.168.1.100 3306 {
    delay_loop 6  #服务轮询的时间间隔
    lb_algo wrr  #加权轮询调度，LVS调度算法 rr|wrr|lc|wlc|lblc|sh|sh
    lb_kind DR   #LVS集群模式 NAT|DR|TUN，其中DR模式要求负载均衡器网卡必须有一块与物理网卡在同一个网段
    #nat_mask 255.255.255.0
    persistence_timeout 50  #会话保持时间
    protocol TCP  #健康检查协议

     ## Real Server设置，3306就是MySQL连接端口
    real_server 192.168.1.5 3306 {
        weight 3  ##权重
        TCP_CHECK {
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
            connect_port 3306
        }
    }
    real_server 192.168.1.6 3306 {
        weight 3
        TCP_CHECK {
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
            connect_port 3306
        }
    }
}
</code></pre>
<p><strong>配置LVS</strong></p>
<p>编写LVS启动脚本/etc/init.d/realserver</p>
<pre><code>#!/bin/sh
VIP=192.168.1.100
. /etc/rc.d/init.d/functions

case "$1" in
# 禁用本地的ARP请求、绑定本地回环地址
start)
    /sbin/ifconfig lo down
    /sbin/ifconfig lo up
    echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore
    echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce
    echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore
    echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce
    /sbin/sysctl -p &gt;/dev/null 2&gt;&amp;1
    /sbin/ifconfig lo:0 $VIP netmask 255.255.255.255 up #在回环地址上绑定VIP，设定掩码，与Direct Server（自身）上的IP保持通信
    /sbin/route add -host $VIP dev lo:0
    echo "LVS-DR real server starts successfully.\n"
    ;;
stop)
    /sbin/ifconfig lo:0 down
    /sbin/route del $VIP &gt;/dev/null 2&gt;&amp;1
    echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore
    echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce
    echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore
    echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce
echo "LVS-DR real server stopped.\n"
    ;;
status)
    isLoOn=`/sbin/ifconfig lo:0 | grep "$VIP"`
    isRoOn=`/bin/netstat -rn | grep "$VIP"`
    if [ "$isLoON" == "" -a "$isRoOn" == "" ]; then
        echo "LVS-DR real server has run yet."
    else
        echo "LVS-DR real server is running."
    fi
    exit 3
    ;;
*)
    echo "Usage: $0 {start|stop|status}"
    exit 1
esac
exit 0
</code></pre>
<p>将lvs脚本加入开机自启动</p>
<pre><code># chmod +x /etc/init.d/realserver
# echo "/etc/init.d/realserver" &gt;&gt; /etc/rc.d/rc.local
</code></pre>
<p>分别启动LVS和keepalived</p>
<pre><code># service realserver start
# service keepalived start</code></pre>
<p>注意此时网卡的变化，可以看到虚拟网卡已经分配到了realserver上。</p>
<p>此时查看LVS集群状态，可以看到集群下有两个Real Server，调度算法，权重等信息。ActiveConn代表当前Real Server的活跃连接数</p>
<pre><code># ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.1.100:3306 wrr persistent 50
  -&gt; 192.168.1.5:3306             Route   3      4          1         
  -&gt; 192.168.1.6:3306             Route   3      0          2    
</code></pre>
<p>此时LVS+Keepalived+MySQL主主复制已经搭建完成。</p>
<h4>测试验证</h4>
<p><strong>功能性验证</strong></p>
<p>关闭MySQL Server2</p>
<pre><code># service mysqld stop</code></pre>
<p>在LVS1查看/var/log/messages中关于keepalived日志，LVS1检测到了MySQL Server2宕机，同时LVS集群自动剔除了故障节点</p>
<pre><code>Sep  9 13:50:53 192.168.1.2 Keepalived_healthcheckers[18797]: TCP connection to [192.168.1.6]:3306 failed !!!
Sep  9 13:50:53 192.168.1.2 Keepalived_healthcheckers[18797]: Removing service [192.168.1.6]:3306 from VS [192.168.1.100]:3306
</code></pre>
<p>从新启动MySQL Server2后自动将故障节点自动加入LVS集群</p>
<pre><code>Sep  9 13:51:41 192.168.1.2 Keepalived_healthcheckers[18797]: TCP connection to [192.168.1.6]:3306 success.
Sep  9 13:51:41 192.168.1.2 Keepalived_healthcheckers[18797]: Adding service [192.168.1.6]:3306 to VS [192.168.1.100]:3306
</code></pre>
<p>关闭LVS1上的Keepalived（模拟宕机操作），查看LVS1上的日志，可以看到Keepalived移出了LVS1上的VIP</p>
<pre><code>Sep  9 14:01:27 192.168.1.2 Keepalived[18796]: Stopping Keepalived v1.2.13 (09/09,2014)
Sep  9 14:01:27 192.168.1.2 Keepalived_healthcheckers[18797]: Removing service [192.168.1.5]:3306 from VS [192.168.1.100]:3306
Sep  9 14:01:27 192.168.1.2 Keepalived_healthcheckers[18797]: Removing service [192.168.1.6]:3306 from VS [192.168.1.100]:3306
Sep  9 14:01:27 192.168.1.2 Keepalived_vrrp[18799]: VRRP_Instance(VI_1) sending 0 priority
Sep  9 14:01:27 192.168.1.2 Keepalived_vrrp[18799]: VRRP_Instance(VI_1) removing protocol VIPs.
</code></pre>
<p>同时查看LVS2上日志，可以看到LVS2成为了Master，并接管了VIP</p>
<pre><code>Sep  9 14:11:24 192.168.1.11 Keepalived_vrrp[7457]: VRRP_Instance(VI_1) Transition to MASTER STATE
Sep  9 14:11:25 192.168.1.11 Keepalived_vrrp[7457]: VRRP_Instance(VI_1) Entering MASTER STATE
Sep  9 14:11:25 192.168.1.11 Keepalived_vrrp[7457]: VRRP_Instance(VI_1) setting protocol VIPs.
Sep  9 14:11:25 192.168.1.11 Keepalived_vrrp[7457]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.1.100
Sep  9 14:11:25 192.168.1.11 Keepalived_healthcheckers[7456]: Netlink reflector reports IP 192.168.1.100 added
Sep  9 14:11:25 192.168.1.11 avahi-daemon[1407]: Registering new address record for 192.168.1.100 on eth0.IPv4.
Sep  9 14:11:30 192.168.1.11 Keepalived_vrrp[7457]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.1.100
</code></pre>
<p>在LVS2上查看LVS集群状态，一切正常。</p>
<pre><code># ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.1.100:3306 wrr persistent 50
  -&gt; 192.168.1.5:3306             Route   3      2          0         
  -&gt; 192.168.1.6:3306             Route   3      1          0 
</code></pre>
<h2>总结</h2>
<ul>
<li><p>MySQL主主复制是集群的基础，组成Server Array，其中每个节点作为Real Server。</p></li>
<li><p>LVS服务器提供了负载均衡的作用，将用户请求分发到Real Server，一台Real Server故障并不会影响整个集群。</p></li>
<li><p>Keepalived搭建主备LVS服务器，避免了LVS服务器的单点故障，出现故障时可以自动切换到正常的节点。</p></li>
</ul>
<p>原文参考<br><a href="http://bestvivi.com/2015/09/09/MySQL%E4%B8%BB%E4%B8%BB%E5%A4%8D%E5%88%B6+LVS+Keepalived%E5%AE%9E%E7%8E%B0MySQL%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7">"http://bestvivi.com/2015/09/09/MySQL主主复制+LVS+Keepalived实现MySQL高可用性"</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727841";}i:32;a:11:{s:5:"title";s:66:" PHP 性能分析与实验（二）——PHP 性能的微观分析";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727793";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727793";s:7:"updated";s:25:"2015-09-09T19:04:16+08:00";s:9:"published";s:25:"2015-09-09T19:04:16+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:18:"OneAPM蓝海讯通";s:10:"author_uri";s:41:"http://segmentfault.com/u/oneapm_official";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:40368:"
<p><strong>【编者按】此前，阅读过了很多关于 PHP 性能分析的文章，不过写的都是一条一条的规则，而且，这些规则并没有上下文，也没有明确的实验来体现出这些规则的优势，同时讨论的也侧重于一些语法要点。本文就改变 <a href="http://www.oneapm.com/ai/php.html?utm_source=Community&amp;utm_medium=Article&amp;utm_term=phpexperi&amp;utm_campaign=SeptArti&amp;from=matefisppe">PHP 性能分析</a>的角度，并通过实例来分析出 PHP 的性能方面需要注意和改进的点。</strong></p>
<p><a href="http://news.oneapm.com/php-apm-opcode/">PHP 性能分析与实验——性能的宏观分析</a></p>
<p>在上一篇文章中，我们从 PHP 是解释性语言、动态语言和底层实现等三个方面，探讨了 PHP 性能的问题。本文就深入到 PHP 的微观层面，我们来了解 PHP 在使用和编写代码过程中，性能方面，可能需要注意和提升的地方。</p>
<p>在开始分析之前，我们得掌握一些与性能分析相关的函数。这些函数让我们对程序性能有更好的分析和评测。</p>
<h2>一、性能分析相关的函数与命令</h2>
<h3>1.1、时间度量函数</h3>
<p>平时我们常用 time() 函数，但是返回的是秒数，对于某段代码的内部性能分析，到秒的精度是不够的。于是要用 microtime 函数。而 microtime 函数可以返回两种形式，一是字符串的形式，一是浮点数的形式。不过需要注意的是，在缺省的情况下，返回的精度只有4位小数。为了获得更高的精确度，我们需要配置 precision。</p>
<p>如下是 microtime 的使用结果。</p>
<pre><code>    $start= microtime(true);
    echo $start."\n";
    $end = microtime(true);
    echo $end."\n";
    echo ($end-$start)."\n";</code></pre>
<p>输出为：</p>
<pre><code>    bash-3.2# phptime.php

    1441360050.3286
    1441360050.3292
    0.00053000450134277</code></pre>
<p>而在代码前面加上一行：</p>
<pre><code>        ini_set("precision", 16);</code></pre>
<p>输出为：</p>
<pre><code>    bash-3.2# phptime.php

    1441360210.932628
    1441360210.932831
    0.0002031326293945312</code></pre>
<p>除了 microtime 内部统计之外， 还可以使用 getrusage 来取得用户态的事长。在实际的操作中，也常用 time 命令来计算整个程序的运行时长，通过多次运行或者修改代码后运行，得到不同的时间长度以得到效率上的区别。 具体用法是：time phptime.php ，则在程序运行完成之后，不管是否正常结束退出，都会有相关的统计。</p>
<pre><code>    bash-3.2# time phptime.php

    1441360373.150756
    1441360373.150959
    0.0002031326293945312

    real    0m0.186s
    user    0m0.072s
    sys     0m0.077s</code></pre>
<p>因为本文所讨论的性能问题，往往分析上百万次调用之后的差距与趋势，为了避免代码中存在一些时间统计代码，后面我们使用 time 命令居多。</p>
<h3>1.2、内存使用相关函数</h3>
<p>分析内存使用的函数有两个：memory_ get_ usage、memory_ get_ peak_usage，前者可以获得程序在调用的时间点，即当前所使用的内存，后者可以获得到目前为止高峰时期所使用的内存。所使用的内存以字节为单位。</p>
<pre><code>    $base_memory= memory_get_usage();
    echo "Hello,world!\n";
    $end_memory= memory_get_usage();
    $peak_memory= memory_get_peak_usage();

    echo $base_memory,"\t",$end_memory,"\t",($end_memory-$base_memory),"\t", $peak_memory,"\n";</code></pre>
<p>输出如下：</p>
<pre><code>    bash-3.2# phphelloworld.php

    Hello,world!
    224400  224568  168     227424</code></pre>
<p>可以看到，即使程序中间只输出了一句话，再加上变量存储，也消耗了168个字节的内存。</p>
<p>对于同一程序，不同 PHP 版本对内存的使用并不相同，甚至还差别很大。</p>
<pre><code>    $baseMemory= memory_get_usage();
    class User
    {
    private $uid;
    function __construct($uid)
        {
    $this-&gt;uid= $uid;
        }
    }
    
    for($i=0;$i&lt;100000;$i++)
    {
    $obj= new User($i);
    if ( $i% 10000 === 0 )
        {
    echo sprintf( '%6d: ', $i), memory_get_usage(), " bytes\n";
        }
    }
    echo "  peak: ",memory_get_peak_usage(true), " bytes\n";</code></pre>
<p>在 PHP 5.2 中，内存使用如下：</p>
<pre><code>    [root@localhostphpperf]# php52 memory.php


    0: 93784 bytes
    10000: 93784 bytes
    ……
    80000: 93784 bytes
    90000: 93784 bytes
    peak: 262144 bytes</code></pre>
<p>PHP 5.3 中，内存使用如下</p>
<pre><code>    [root@localhostphpperf]# phpmemory.php


    0: 634992 bytes
    10000: 634992 bytes
    ……
    80000: 634992 bytes
    90000: 634992 bytes
    peak: 786432 bytes</code></pre>
<p>可见 PHP 5.3 在内存使用上要粗放了一些。</p>
<p>PHP 5.4 - 5.6 差不多，有所优化：</p>
<pre><code>    [root@localhostphpperf]# php56 memory.php


    0: 224944 bytes
    10000: 224920 bytes
    ……
    80000: 224920 bytes
    90000: 224920 bytes
    peak: 262144 bytes</code></pre>
<p>而 PHP 7 在少量使用时，高峰内存的使用，增大很多。</p>
<pre><code>    [root@localhostphpperf]# php7 memory.php


    0: 353912 bytes
    10000: 353912 bytes
    ……
    80000: 353912 bytes
    90000: 353912 bytes
    peak: 2097152 bytes</code></pre>
<p>从上面也看到，以上所使用的 PHP 都有比较好的垃圾回收机制，10万次初始化,并没有随着对象初始化的增多而增加内存的使用。PHP7 的高峰内存使用最多，达到了接近 2M。</p>
<p>下面再来看一个例子，在上面的代码的基础上，我们加上一行，即如下加粗的一行：</p>
<pre><code>    $obj-&gt;self = $obj;</code></pre>
<p>代码如下：</p>
<pre><code>    $baseMemory= memory_get_usage();
    class User
    {
    private $uid;
    function __construct($uid)
        {
    $this-&gt;uid= $uid;
        }
    }
    
    for($i=0;$i&lt;100000;$i++)
    {
    $obj= new User($i);
    $obj-&gt;self = $obj;
    if ( $i% 5000 === 0 )
        {
    echo sprintf( '%6d: ', $i), memory_get_usage(), " bytes\n";
        }
    }
    echo "  peak: ",memory_get_peak_usage(true), " bytes\n";</code></pre>
<p>这时候再来看看内存的使用情况，中间表格主体部分为内存使用量，单位为字节。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/QQ--20150908172552-2.png" alt="PHP性能分析与实验" title="PHP性能分析与实验"></p>
<p>图表如下：</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/QQ--20150908172731-3.png" alt="PHP性能分析与实验" title="PHP性能分析与实验"></p>
<p>PHP 5.2 并没有合适的垃圾回收机制，导致内存使用越来越多。而5.3 以后内存回收机制导致内存稳定在一个区间。而也可以看见 PHP7 内存使用最少。把 PHP 5.2 的图形去掉了之后，对比更为明显。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/QQ--20150908172827-4.png" alt="PHP性能分析与实验" title="PHP性能分析与实验"></p>
<p>可见 PHP7 不仅是在算法效率上，有大幅度的提升，在大批量内存使用上也有大幅度的优化（尽管小程序的高峰内存比历史版本所用内存更多）。</p>
<h3>1.3、垃圾回收相关函数</h3>
<p>在 PHP 中，内存回收是可以控制的，我们可以显式地关闭或者打开垃圾回收，一种方法是通过修改配置，<code>zend.enable_gc=Off</code> 就可以关掉垃圾回收。缺省情况下是 <code>On</code> 的。另外一种手段是通过 <code>gc _enable()和gc _disable()</code>函数分别打开和关闭垃圾回收。</p>
<p>比如在上面的例子的基础上，我们关闭垃圾回收，就可以得到如下数据表格和图表。</p>
<p>代码如下：</p>
<pre><code>    gc_disable();
    $baseMemory= memory_get_usage();
    class User
    {
    private $uid;
    function __construct($uid)
        {
    $this-&gt;uid= $uid;
        }
    }
    
    for($i=0;$i&lt;100000;$i++)
    {
    $obj= new User($i);
    $obj-&gt;self = $obj;
    if ( $i% 5000 === 0 )
        {
    echo sprintf( '%6d: ', $i), memory_get_usage(), " bytes\n";
        }
    }
    echo "  peak: ",memory_get_peak_usage(true), " bytes\n";</code></pre>
<p>分别在 PHP 5.3、PHP5.4 、PHP5.5、PHP5.6 、PHP7 下运行，得到如下内存使用统计表。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/QQ--20150908173102-5.png" alt="PHP性能分析与实验" title="PHP性能分析与实验"></p>
<p>图表如下，PHP7 还是内存使用效率最优的。</p>
<p><img src="http://news.oneapm.com/content/images/2015/09/QQ--20150909100407-777.png" alt="" title=""></p>
<p>从上面的例子也可以看出来，尽管在第一个例子中，PHP7 的高峰内存使用数是最多的，但是当内存使用得多时，PHP7 的内存优化就体现出来了。</p>
<p>这里值得一提的是垃圾回收，尽管会使内存减少，但是会导致速度降低，因为垃圾回收也是需要消耗 CPU 等其他系统资源的。Composer 项目就曾经因为在计算依赖前关闭垃圾回收，带来成倍性能提升，引发广大网友关注。详见：</p>
<p><a href="https://github.com/composer/composer/commit/ac676f47f7bbc619678a29deae097b6b0710b799"></a><a href="https://github.com/composer/composer/commit/ac676f47f7bbc619678a29deae097b6b0710b799">https://github.com/composer/composer/commit/ac676f47f7bbc619678a29deae097b6b0710b799</a></p>
<p>在常见的代码和性能分析中，出了以上三类函数之外，还常使用的有堆栈跟踪函数、输出函数，这里不再赘述。</p>
<h2>二、<a href="http://www.oneapm.com/ai/php.html">PHP 性能分析</a>10则</h2>
<p>下面我们根据小程序来验证一些常见的性能差别。</p>
<h3>2.1、使用 echo 还是 print</h3>
<p>在有的建议规则中，会建议使用 echo ，而不使用 print。说 print 是函数，而 echo 是语法结构。实际上并不是如此，print 也是语法结构，类似的语法结构，还有多个，比如 list、isset、require 等。不过对于 PHP 7 以下 PHP 版本而言，两者确实有性能上的差别。如下两份代码：</p>
<pre><code>    for($i=0; $i&lt;1000000; $i++)
    {
    echo("Hello,World!");
    }
    
    for($i=0; $i&lt;1000000; $i++)
    {
    print ("Hello,World!");
    }</code></pre>
<p>在 PHP 5.3 中运行速度分别如下（各2次）：</p>
<pre><code>    [root@localhostphpperf]# time php echo1.php  &gt; /dev/null


    real    0m0.233s
    user    0m0.153s
    sys     0m0.080s
    [root@localhostphpperf]# time php echo1.php  &gt; /dev/null


    real    0m0.234s
    user    0m0.159s
    sys     0m0.073s
    [root@localhostphpperf]# time phpecho.php&gt; /dev/null


    real    0m0.203s
    user    0m0.130s
    sys     0m0.072s
    [root@localhostphpperf]# time phpecho.php&gt; /dev/null


    real    0m0.203s
    user    0m0.128s
    sys     0m0.075s</code></pre>
<p>在 PHP5.3 版中效率差距10%以上。而在 PHP5.4 以上的版本中，区别不大，如下是 PHP7 中的运行效率。</p>
<pre><code>    [root@localhostphpperf]# time php7 echo.php&gt; /dev/null


    real    0m0.151s
    user    0m0.088s
    sys     0m0.062s
    [root@localhostphpperf]# time php7 echo.php&gt; /dev/null


    real    0m0.145s
    user    0m0.084s
    sys     0m0.061s

    [root@localhostphpperf]# time php7 echo1.php  &gt; /dev/null


    real    0m0.140s
    user    0m0.075s
    sys     0m0.064s
    [root@localhostphpperf]# time php7 echo1.php  &gt; /dev/null


    real    0m0.146s
    user    0m0.077s
    sys     0m0.069s</code></pre>
<p>正如浏览器前端的一些优化准则一样，没有啥特别通用的原则，往往根据不同的情况和版本，规则也会存在不同。</p>
<h3>2.2、require 还是 require_once？</h3>
<p>在一些常规的优化规则中，会提到，建议使用 require_ once 而不是 require，现由是 require_ once 会去检测是否重复，而 require 则不需要重复检测。</p>
<p>在大量不同文件的包含中，require_ once 略慢于 require。但是 require_ once 的检测是一项内存中的行为，也就是说即使有数个需要加载的文件，检测也只是内存中的比较。而 require 的每次重新加载，都会从文件系统中去读取分析。因而 require_ once 会比 require 更佳。咱们也使用一个例子来看一下。</p>
<pre><code>    str.php

    global$str;
    $str= "China has a large population";
    
    require.php
    for($i=0; $i&lt;100000; $i++) {
    require "str.php";
    }
    
    require_once.php
    for($i=0; $i&lt;100000; $i++) {
    require_once"str.php";
    }</code></pre>
<p>上面的例子，在 PHP7 中，require_ once.php 的运行速度是 require.php 的30倍！在其他版本也能得到大致相同的结果。</p>
<pre><code>    [root@localhostphpperf]# time php7 require.php


    real    0m1.712s
    user    0m1.126s
    sys     0m0.569s
    [root@localhostphpperf]# time php7 require.php


    real    0m1.640s
    user    0m1.113s
    sys     0m0.515s
    [root@localhostphpperf]# time php7 require_once.php


    real    0m0.066s
    user    0m0.063s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 require_once.php
  

    real    0m0.057s
    user    0m0.052s
    sys     0m0.004s</code></pre>
<p>从上可以看到，如果存在大量的重复加载的话，require_ once 明显优于 require，因为重复的文件不再有 IO 操作。即使不是大量重复的加载，也建议使用 require_ once，因为在一个程序中，一般不会存在数以千百计的文件包含，100次内存比较的速度差距，一个文件包含就相当了。</p>
<h3>2.3、单引号还是双引号？</h3>
<p>单引号，还是双引号，是一个问题。一般的建议是能使用单引号的地方，就不要使用双引号，因为字符串中的单引号，不会引起解析，从而效率更高。那来看一下实际的差别。</p>
<pre><code>    classUser
    {
    private $uid;
    private $username;
    private $age;
    
    function  __construct($uid, $username,$age){
    $this-&gt;uid= $uid;
    $this-&gt;username = $username;
    $this-&gt;age = $age;
        }
    function getUserInfo()
        {
    return "UID:".$this-&gt;uid." UserName:".$this-&gt;username." Age:".$this-&gt;age;
        }
    function getUserInfoSingle()
        {
    return 'UID:'.$this-&gt;uid.' UserName:'.$this-&gt;username.' Age'.$this-&gt;age;
        }
    
    function getUserInfoOnce()
        {
    return "UID:{$this-&gt;uid}UserName:{$this-&gt;username} Age:{$this-&gt;age}";
        }
    
    function getUserInfoSingle2()
        {
    return 'UID:{$this-&gt;uid} UserName:{$this-&gt;username} Age:{$this-&gt;age}';
        }
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = new User($i, "name".$i, $i%100);
    $user-&gt;getUserInfoSingle();
    }</code></pre>
<p>在上面的 User 类中，有四个不同的方法,完成一样的功能，就是拼接信息返回，看看这四个不同的方法的区别。</p>
<p>第一个、<code>getUserInfo</code> ，使用双引号和属性相拼接</p>
<pre><code>    [root@localhostphpperf]# time php7 string.php


    real    0m0.670s
    user    0m0.665s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 string.php


    real    0m0.692s
    user    0m0.689s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 string.php


    real    0m0.683s
    user    0m0.672s
    sys     0m0.004s</code></pre>
<p>第二个、<code>getUserInfoSingle</code> ，使用单引号和属性相拼接</p>
<pre><code>    [root@localhostphpperf]# time php7 string.php

    real    0m0.686s
    user    0m0.683s
    sys     0m0.001s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.671s
    user    0m0.666s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 string.php
 
    real    0m0.669s
    user    0m0.666s
    sys      0m0.002s</code></pre>
<p>可见在拼接中，单双引号并无明显差别。</p>
<p>第三个、<code>getUserInfoOnce</code>，不再使用句号<code>.</code>连接，而是直接引入在字符串中解析。</p>
<pre><code>    [root@localhostphpperf]# time php7 string.php

    real    0m0.564s
    user    0m0.556s
    sys     0m0.006s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.592s
    user    0m0.587s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.563s
    user    0m0.559s
    sys     0m0.003s</code></pre>
<p>从上面可见，速度提高了0.06s-0.10s，有10%-20%的效率提升。可见连缀效率更低一些。</p>
<p>第四个、<code>getUserInfoSingle2</code> 虽然没有达到我们真正想要的效果，功能是不正确的，但是在字符串中，不再需要解析变量和获取变量值，所以效率确实有大幅度提升。</p>
<pre><code>    [root@localhostphpperf]# time php7 string.php

    real    0m0.379s
    user    0m0.375s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.399s
    user    0m0.394s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.377s
    user    0m0.371s
    sys     0m0.004s</code></pre>
<p>效率确实有了大的提升，快了50%。</p>
<p>那么这个快，是由于不需要变量引用解析带来的，还是只要加入<code>$</code>天然的呢？我们再试着写了一个方法。</p>
<pre><code>    functiongetUserInfoSingle3()
    {
    return "UID:{\$this-&gt;uid} UserName:{\$this-&gt;username} Age:{\$this-&gt;age}";
    }</code></pre>
<p>得到如下运行时间：</p>
<pre><code>    [root@localhostphpperf]# time php7 string.php

    real    0m0.385s
    user    0m0.381s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.382s
    user    0m0.380s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 string.php

    real    0m0.386s
    user    0m0.380s
    sys     0m0.004s</code></pre>
<p>发现转义后的字符串，效率跟单引号是一致的，从这里也可以看见，单引号还是双引号包含，如果不存在需要解析的变量，几乎没有差别。如果有需要解析的变量，你也不能光用单引号，要么使用单引号和连缀，要么使用内部插值，所以在这条规则上，不用太过纠结。</p>
<h3>2.4、错误应该打开还是关闭？</h3>
<p>在 PHP 中，有多种错误消息，错误消息的开启是否会带来性能上的影响呢？从直觉觉得，由于错误消息，本身会涉及到 IO 输出，无论是输出到终端或者 error_log，都是如此，所以肯定会影响性能。我们来看看这个影响有多大。</p>
<pre><code>    error_reporting(E_ERROR);
    for($i=0; $i&lt;1000000;$i++) {
    $str= "通常，$PHP中的垃圾回收机制，仅仅在循环回收算法确实运行时会有时间消耗上的增加。但是在平常的(更小的)脚本中应根本就没有性能影响。
    然而，在平常脚本中有循环回收机制运行的情况下，内存的节省将允许更多这种脚本同时运行在你的服务器上。因为总共使用的内存没达到上限。";
    }</code></pre>
<p>在上面的代码中，我们涉及到一个不存在的变量，所以会报出 Notice 错误:</p>
<p><strong>Notice: Undefined variable: PHP 中的垃圾回收机制，仅仅在循环回收算法确实运行时会有时间消耗上的增加。但是在平常的 in xxxx/string2.php on line 10</strong></p>
<p>如果把 E_ ERROR 改成 E_ ALL 就能看到大量的上述错误输出。</p>
<p>我们先执行 E_ ERROR 版，这个时候没有任何错误日志输出。得到如下数据：</p>
<pre><code>    [root@localhostphpperf]# time php7 string2.php 

    real    0m0.442s
    user    0m0.434s
    sys     0m0.005s
    [root@localhostphpperf]# time php7 string2.php 

    real    0m0.487s
    user    0m0.484s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 string2.php 

    real    0m0.476s
    user    0m0.471s
    sys     0m0.003s</code></pre>
<p>再执行 E_ ALL 版，有大量的错误日志输出，我们把输出重定向到<code>/dev/null</code></p>
<pre><code>    [root@localhostphpperf]# time php7 string2.php  &gt; /dev/null

    real    0m0.928s
    user    0m0.873s
    sys     0m0.051s
    [root@localhostphpperf]# time php7 string2.php  &gt; /dev/null

    real    0m0.984s
    user    0m0.917s
    sys     0m0.064s
    [root@localhostphpperf]# time php7 string2.php  &gt; /dev/null

    real    0m0.945s
    user    0m0.887s
    sys     0m0.056s</code></pre>
<p>可见慢了将近一倍。</p>
<p>如上可见，即使输出没有正式写入文件，错误级别打开的影响也是巨大的。在线上我们应该将错误级别调到 E_ ERROR 这个级别，同时将错误写入 error_ log，既减少了不必要的错误信息输出，又避免泄漏路径等信息，造成安全隐患。</p>
<h3>2.5、正则表达式和普通字符串操作</h3>
<p>在字符串操作中，有一条常见的规则，即是能使用普通字符串操作方法替代的，就不要使用正则表达式来处理，用 C 语言操作 PCRE 做过正则表达式处理的童鞋应该清楚，需要先 compile，再 exec，也就是说是一个相对复杂的过程。现在就比较一下两者的差别。</p>
<p>对于简单的分隔，我们可以使用 explode 来实现，也可以使用正则表达式，比如下面的例子：</p>
<pre><code>    ini_set("precision", 16);
    function microtime_ex()
    {
    list($usec, $sec) = explode(" ", microtime());
    return $sec+$usec;
    }
    
    for($i=0; $i&lt;1000000; $i++) {
    microtime_ex();
    }</code></pre>
<p>耗时在0.93-1S之间。</p>
<pre><code>    [root@localhostphpperf]# time php7 pregstring.php

    real    0m0.941s
     user    0m0.931s
    sys     0m0.007s
     [root@localhostphpperf]# time php7 pregstring.php

    real    0m0.986s
    user    0m0.980s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 pregstring.php

    real    0m1.004s
    user    0m0.998s
    sys     0m0.003s</code></pre>
<p>我们再将分隔语句替换成：</p>
<pre><code>    list($usec, $sec) = preg_split("#\s#", microtime());</code></pre>
<p>得到如下数据，慢了近10-20%。</p>
<pre><code>    [root@localhostphpperf]# time php7 pregstring1.php 

    real    0m1.195s
    user    0m1.182s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 pregstring1.php 
 
    real    0m1.222s
    user    0m1.217s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 pregstring1.php 

    real    0m1.101s
    user    0m1.091s
    sys     0m0.005s</code></pre>
<p>再将语句替换成：</p>
<pre><code>    list($usec, $sec) = preg_split("#\s+#", microtime());</code></pre>
<p>即匹配一到多个空格，并没有太多的影响。除了分隔外，查找我们也来看一个例子。</p>
<p>第一段代码：</p>
<pre><code>    $str= "China has a Large population";
    for($i=0; $i&lt;1000000; $i++) {
    if(preg_match("#l#i", $str))
        {
        }
    }</code></pre>
<p>第二段代码：</p>
<pre><code>    $str= "China has a large population";
    for($i=0; $i&lt;1000000; $i++) {
    if(stripos($str, "l")!==false)
        {
        }
    }</code></pre>
<p>这两段代码达到的效果相同，都是查找字符串中有无 l 或者 L 字符。</p>
<p>在 PHP 7 下运行效果如下：</p>
<pre><code>    [root@localhostphpperf]# time php7 pregstring2.php 

    real    0m0.172s
    user    0m0.167s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 pregstring2.php 

    real    0m0.199s
    user    0m0.196s
    sys     0m0.002s
    [root@localhostphpperf]# time php7 pregstring3.php 

    real    0m0.185s
    user    0m0.182s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 pregstring3.php 
 
    real    0m0.184s
    user    0m0.181s
    sys     0m0.003s</code></pre>
<p>两者区别不大。再看看在 PHP5.6 中的表现。</p>
<pre><code>    [root@localhostphpperf]# time php56 pregstring2.php 

    real    0m0.470s
    user    0m0.456s
    sys     0m0.004s
    [root@localhostphpperf]# time php56 pregstring2.php 

    real    0m0.506s
    user    0m0.500s
    sys     0m0.005s
    [root@localhostphpperf]# time php56 pregstring3.php 

    real    0m0.348s
    user    0m0.342s
    sys     0m0.004s
    [root@localhostphpperf]# time php56 pregstring3.php 

    real    0m0.376s
    user    0m0.364s
    sys     0m0.003s</code></pre>
<p>可见在 PHP 5.6 中表现还是非常明显的，使用正则表达式慢了20%。PHP7 难道是对已使用过的正则表达式做了缓存？我们调整一下代码如下：</p>
<pre><code>    $str= "China has a Large population";
    
    for($i=0; $i&lt;1000000; $i++) {
    $pattern = "#".chr(ord('a')+$i%26)."#i";
    if($ret = preg_match($pattern, $str)!==false)
        {
        }
   }</code></pre>
<p>这是一个动态编译的 pattern。</p>
<pre><code>    $str= "China has a large population";
    
    for($i=0; $i&lt;1000000; $i++) {
    $pattern = "".chr(ord('a')+$i%26)."";
    if($ret = stripos($str, $pattern)!==false)
        {
        }
    }</code></pre>
<p>在 PHP7 中，得到了如下结果：</p>
<pre><code>    [root@localhostphpperf]# time php7 pregstring2.php 

    real    0m0.351s
    user    0m0.346s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 pregstring2.php 

    real    0m0.359s
    user    0m0.352s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 pregstring3.php 

    real    0m0.375s
    user    0m0.369s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 pregstring3.php 

    real    0m0.370s
    user    0m0.365s
    sys     0m0.005s</code></pre>
<p>可见两者并不明显。而在 PHP 5.6 中，同样的代码：</p>
<pre><code>    [root@localhostphpperf]# time php56 pregstring2.php 

    real    0m1.022s
    user    0m1.015s
    sys     0m0.005s
    [root@localhostphpperf]# time php56 pregstring2.php 
 
    real    0m1.049s
    user    0m1.041s
    sys     0m0.005s
    [root@localhostphpperf]# time php56 pregstring3.php 
 
    real    0m0.923s
    user    0m0.821s
    sys     0m0.002s
    [root@localhostphpperf]# time php56 pregstring3.php 
  
    real    0m0.838s
    user    0m0.831s
    sys     0m0.004s</code></pre>
<p>在 PHP 5.6 中，stripos 版明显要快于正则表达式版，由上两例可见，PHP7对正则表达式的优化还是相当惊人的。其次也建议，能用普通字符串操作的地方，可以避免使用正则表达式。因为在其他版本中，这个规则还是适用的。某 zend 大牛官方的分享给出如下数据：</p>
<p><code>stripos(‘http://’, $website)</code> 速度是<code>preg_match(‘/http:\/\//i’, $website)</code> 的两倍</p>
<p><code>ctype_alnum()</code>速度是<code>preg_match(‘/^\s*$/’)</code>的5倍;</p>
<p><code>“if ($test == (int)$test)”</code> 比 <code>preg_match(‘/^\d*$/’)</code>快5倍</p>
<p>可以相见，正则表达式是相对低效的。</p>
<h3>2.6、数组元素定位查找</h3>
<p>在数组元素的查找中，有一个关键的注意点就是数组值和键的查找速度，差异非常大。了解过 PHP 扩展开发的朋友，应该清楚，数组在底层其实是 Hash 表。所以键是以快速定位的，而值却未必。下面来看例子。</p>
<p>首先们构造一个数组：</p>
<pre><code>    $a= array();
    for($i=0;$i&lt;100000;$i++){
    $a[$i] = $i;
    }</code></pre>
<p>在这个数组中，我们测试查找值和查找键的效率差别。</p>
<p>第一种方法用 array_ search，第二种用 array_ key_ exists，第三种用 isset 语法结构。<br>代码分别如下：</p>
<pre><code>    //查找值
    foreach($a as $i)
    {
    array_search($i, $a);
    }
    //查找键
    foreach($a as $i)
    {
    array_key_exists($i, $a);
    }
    //判定键是否存在
    foreach($a as $i)
    {
    if(isset($a[$i]));
    }</code></pre>
<p>运行结果如下：</p>
<pre><code>    [root@localhostphpperf]# time php7 array.php

    real    0m9.026s
    user    0m8.965s
    sys     0m0.007s
    [root@localhostphpperf]# time php7 array.php

    real    0m9.063s
    user    0m8.965s
    sys     0m0.005s
    [root@localhostphpperf]# time php7 array1.php 
 
    real    0m0.018s
    user    0m0.016s
    sys     0m0.001s
    [root@localhostphpperf]# time php7 array1.php 

    real    0m0.021s
    user    0m0.015s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 array2.php 

    real    0m0.020s
    user    0m0.014s
    sys     0m0.006s
    [root@localhostphpperf]# time php7 array2.php 

    real    0m0.016s
    user    0m0.009s
    sys     0m0.006s</code></pre>
<p>由上例子可见，键值查找的速度比值查找的速度有百倍以上的效率差别。因而如果能用键值定位的地方，尽量用键值定位，而不是值查找。</p>
<h3>2.7、对象与数组</h3>
<p>在 PHP 中，数组就是字典，字典可以存储属性和属性值，而且无论是键还是值，都不要求数据类型统一，所以对象数据存储，既能用对象数据结构的属性存储数据，也能使用数组的元素存储数据。那么两者有何差别呢？</p>
<p>使用对象：</p>
<pre><code>    classUser
    {
    public $uid;
    public $username;
    public $age;
    function getUserInfo()
        {
    return "UID:".$this-&gt;uid." UserName:".$this-&gt;username." Age:".$this-&gt;age;
        }
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = new User();
    $user-&gt;uid= $i;
    $user-&gt;age = $i%100;
    $user-&gt;username="User".$i;
    $user-&gt;getUserInfo();
    }</code></pre>
<p>使用数组：</p>
<pre><code>    functiongetUserInfo($user)
    {
    return "UID:".$user['uid']." UserName:".$user['username']." Age:".$user['age'];
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = array("uid"=&gt;$i,"age" =&gt;$i%100,"username"=&gt;"User".$i);
    getUserInfo($user);
    }</code></pre>
<p>我们分别在 PHP5.3、PHP 5.6 和 PHP 7 中运行这两段代码。</p>
<pre><code>    [root@localhostphpperf]# time phpobject.php

    real    0m2.144s
    user    0m2.119s
    sys     0m0.009s
    [root@localhostphpperf]# time phpobject.php

    real    0m2.106s
    user    0m2.089s
    sys     0m0.013s
    [root@localhostphpperf]# time php object1.php 

    real    0m1.421s
    user    0m1.402s
    sys     0m0.016s
    [root@localhostphpperf]# time php object1.php 
 
    real    0m1.431s
    user    0m1.410s
    sys     0m0.012s</code></pre>
<p>在 PHP 5.3 中，数组版比对象版快了近30%。</p>
<pre><code>    [root@localhostphpperf]# time php56 object.php

    real    0m1.323s
    user    0m1.319s
    sys     0m0.002s
    [root@localhostphpperf]# time php56 object.php

    real    0m1.414s
    user    0m1.400s
    sys     0m0.006s
    [root@localhostphpperf]# time php56 object1.php 

    real    0m1.356s
    user    0m1.352s
    sys     0m0.002s
    [root@localhostphpperf]# time php56 object1.php 

    real    0m1.364s
    user    0m1.349s
    sys     0m0.006s
    [root@localhostphpperf]# time php7 object.php

    real    0m0.642s
    user    0m0.638s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 object.php

    real    0m0.606s
    user    0m0.602s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 object1.php 
    
    real    0m0.615s
    user    0m0.613s
    sys     0m0.000s
    [root@localhostphpperf]# time php7 object1.php 
 
    real    0m0.615s
    user    0m0.611s
    sys     0m0.003s</code></pre>
<p>到了 PHP 5.6 和 PHP7 中，两个版本基本没有差别，而在 PHP7 中的速度是 PHP5.6 中的2倍。在新的版本中，差别已几乎没有，那么为了清楚起见我们当然应该声明类，实例化类来存储对象数据。</p>
<h3>2.8、getter 和 setter</h3>
<p>从 Java 转过来学习 PHP 的朋友，在对象声明时，可能习惯使用 getter 和 setter，那么，在 PHP 中，使用 getter 和 setter 是否会带来性能上的损失呢？同样，先上例子。</p>
<p>无 setter版：</p>
<pre><code>    classUser
    {
    public $uid;
    public $username;
    public $age;
    function getUserInfo()
        {
    return "UID:".$this-&gt;uid." UserName:".$this-&gt;username." Age:".$this-&gt;age;
        }
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = new User();
    $user-&gt;uid= $i;
    $user-&gt;age = $i%100;
    $user-&gt;username="User".$i;
    $user-&gt;getUserInfo();
    }

有 setter版：

    classUser
    {
    public $uid;
    private $username;
    public $age;
    function setUserName($name)
        {
    $this-&gt;username = $name;
        }
    function getUserInfo()
        {
    return "UID:".$this-&gt;uid." UserName:".$this-&gt;username." Age:".$this-&gt;age;
        }
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = new User();
    $user-&gt;uid= $i;
    $user-&gt;age = $i%100;
    $user-&gt;setUserName("User".$i);
    $user-&gt;getUserInfo();
    }</code></pre>
<p>这里只增加了一个 setter。运行结果如下：</p>
<pre><code>    [root@localhostphpperf]# time php7 object.php

    real    0m0.607s
    user     0m0.602s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 object.php
 
    real    0m0.598s
     user    0m0.596s
    sys     0m0.000s
    [root@localhostphpperf]# time php7 object2.php 

    real    0m0.673s
    user    0m0.669s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 object2.php 

    real    0m0.668s
    user    0m0.664s
    sys     0m0.004s</code></pre>
<p>从上面可以看到，增加了一个 setter，带来了近10%的效率损失。可见这个性能损失是相当大的，在 PHP 中，我们没有必要再来做 setter 和 getter了。需要引用的属性，直接使用即可。</p>
<h3>2.9、类属性该声明还是不声明</h3>
<p>PHP 本身支持属性可以在使用时增加，也就是不声明属性，可以在运行时添加属性。那么问题来了，事先声明属性与事后增加属性，是否会有性能上的差别。这里也举一个例子探讨一下。</p>
<p>事先声明了属性的代码就是2.8节中，无 setter 的代码，不再重复。而无属性声明的代码如下：</p>
<pre><code>    classUser
    { 
    function getUserInfo()
        {
    return "UID:".$this-&gt;uid." UserName:".$this-&gt;username." Age:".$this-&gt;age;
        }
    }
    
    for($i=0; $i&lt;1000000;$i++) {
    $user = new User();
    $user-&gt;uid= $i;
    $user-&gt;age = $i%100;
    $user-&gt;username="User".$i;
    $user-&gt;getUserInfo();
    }</code></pre>
<p>两段代码，运行结果如下：</p>
<pre><code>    [root@localhostphpperf]# time php7 object.php

    real    0m0.608s
    user    0m0.604s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 object.php

    real    0m0.615s
    user    0m0.605s
    sys     0m0.003s
    [root@localhostphpperf]# time php7 object3.php 


     real    0m0.733s
    user    0m0.728s
    sys     0m0.004s
    [root@localhostphpperf]# time php7 object3.php 


    real    0m0.727s
    user    0m0.720s
    sys     0m0.004s</code></pre>
<p>从上面的运行可以看到，无属性声明的代码慢了20%。可以推断出来的就是对于对象的属性，如果事先知道的话，我们还是事先声明的好，这一方面是效率问题，另一方面，也有助于提高代码的可读性呢。</p>
<h3>2.10、图片操作 API 的效率差别</h3>
<p>在图片处理操作中，一个非常常见的操作是将图片缩放成小图。缩放成小图的办法有多种，有使用 API 的，有使用命令行的。在 PHP 中，有 imagick 和 gmagick 两个扩展可供操作，而命令行则一般使用 convert 命令来处理。我们这里来讨论使用 imagick 扩展中的 API 处理图片的效率差别。</p>
<p>先上代码：</p>
<pre><code>    function imagick_resize($filename, $outname)
    {
    $thumbnail = new Imagick($filename);
    $thumbnail-&gt;resizeImage(200, 200, imagick::FILTER_LANCZOS, 1);
    $thumbnail-&gt;writeImage($outname);
    unset($thumbnail);
    }
    
    function imagick_scale($filename, $outname)
    {
    $thumbnail = new Imagick($filename);
    $thumbnail-&gt;scaleImage(200, 200);
    $thumbnail-&gt;writeImage($outname);
    unset($thumbnail);
    }
    
    
    function convert($func)
    {
    $cmd= "find /var/data/ppt |grep jpg";
    $start = microtime(true);
    exec($cmd, $files);
    $index = 0;
    foreach($files as $key =&gt;$filename)
        {
    $outname= " /tmp/$func"."_"."$key.jpg";
    $func($filename, $outname);
    $index++;
        }
    $end = microtime(true);
    echo "$func $index files: " . ($end- $start) . "s\n";
    }
    
    convert("imagick_resize");
    convert("imagick_scale");</code></pre>
<p>在上面的代码中，我们分别使用了 resizeImage 和 scaleImage 来进行图片的压缩，压缩的是常见的 1-3M 之间的数码相机图片，得到如下运行结果：</p>
<pre><code>    [root@localhostphpperf]# php55 imagick.php


    imagick_ resize 169 files: 5.0612308979034s
    imagick_ scale 169 files: 3.1105840206146s

    [root@localhostphpperf]# php55 imagick.php


    imagick_ resize 169 files: 4.4953861236572s
    imagick_ scale 169 files: 3.1514940261841s

    [root@localhostphpperf]# php55 imagick.php


    imagick_ resize 169 files: 4.5400381088257s
    imagick_ scale 169 files: 3.2625908851624s</code></pre>
<p>169张图片压缩，使用 resizeImage 压缩，速度在4.5S以上，而使用 scaleImage 则在 3.2S 左右，快了将近50%，压缩的效果，用肉眼看不出明显区别。当然 resizeImage 的控制能力更强，不过对于批量处理而言，使用 scaleImage 是更好的选择，尤其对头像压缩这种频繁大量的操作。本节只是例举了图片压缩 API 作为例子，也正像 explode 和 preg_ split 一样，在 PHP 中，完成同样一件事情，往往有多种手法。建议采用效率高的做法。</p>
<p>以上就是关于 PHP 开发的10个方面的对比，这些点涉及到 PHP 语法、写法以及 API 的使用。有些策略随着 PHP 的发展，有的已经不再适用，有些策略则会一直有用。</p>
<p>有童鞋也许会说，在现实的开发应用中，上面的某些观点和解决策略，有点「然并卵」。为什么这么说呢？因为在一个程序的性能瓶颈中，最为核心的瓶颈，往往并不在 PHP 语言本身。即使是跟 PHP 代码中暴露出来的性能瓶颈，也常在外部资源和程序的不良写法导致的瓶颈上。于是为了做好性能分析，我们需要向 PHP 的上下游戏延伸，比如延伸到后端的服务上去，比如延伸到前端的优化规则。在这两块，都有了相当多的积累和分析，雅虎也据此提出了多达35条前端优化规则，这些同 PHP 本身的性能分析构成了一个整体，就是降低用户的访问延时。</p>
<p>所以前面两部分所述的性能分析，只是有助于大家了解 PHP 开发本身，写出更好的 PHP 程序，为你成为一个资深的 PHP 程序员打下基础，对于实际生产中程序的效率提升，往往帮助也不是特别显著，因为大家也看到，在文章的实例中，很多操作往往是百万次才能看出明显的性能差别。在现实的页面中，每一个请求很快执行完成，对这些基础代码的调用，往往不会有这么多次调用。不过了解这些，总是好的。</p>
<p>那么，对于一个程序而言，其他的性能瓶颈可能存在哪里？我们将深入探讨。所以在本系列的下两篇，我们将探讨 PHP 程序的外围效源的效率问题和前端效率问题，敬请期待。</p>
<p><a href="http://news.oneapm.com/php-apm-opcode/">PHP 性能分析与实验——性能的宏观分析</a></p>
<p><strong>本文系 |
c51143676ca57db0bcf4c7cc254287ca26
| 工程师编译整理。想阅读更多技术文章，请访问 OneAPM <a href="http://news.oneapm.com/?utm_source=TechCommunity&amp;utm_medium=TechArticle&amp;utm_campaign=JulSoftArti">官方博客</a>。</strong></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727793";}i:33;a:11:{s:5:"title";s:57:"[Tips on Ember 2] UI 布局与应用状态的关系处理";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727746";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727746";s:7:"updated";s:25:"2015-09-09T18:40:53+08:00";s:9:"published";s:25:"2015-09-09T18:40:53+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"nightire";s:10:"author_uri";s:34:"http://segmentfault.com/u/nightire";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:24372:"
<h2>引子</h2>
<p>SPA（单页面应用）的核心是什么？</p>
<p>自该类型应用诞生以来我最多思考的问题就是这个。现在前端 SPA 框架满天飞，许多不是框架的也被称作框架，究竟有什么代表性的层（layer）能让一个系统称得上是框架？</p>
<p>我的答案是路由，而路由的本质就是一个状态管理器。没有路由机制的系统不能称之为框架，而路由机制做得不好的框架也算不上好框架（但可以算是好的工具集合，比如 Angular——详见<a href="https://ruby-china.org/topics/24646?page=1#reply29">我在 Ruby China 上曾经吐过的槽</a>）。</p>
<p>为什么这么说呢？我们都知道 HTML 是无状态的（stateless），做一堆 HTML 页面拼在一起那不叫“应用”，顶多称之为“内容系统”；在以前，HTML 网站上的状态管理是由后端的 Session 加前端的 Cookies 协作完成的，到了 SPA 的时代 Session 不是必须的了（尽管传统的 Session 机制也是可用的），UI 上的状态转移到了前端由 JavaScript 完全管控（由于 SPA 前后分离的特点），所以前端工程师担负起了更多的业务逻辑职责，相应的整个技术链上也必须有一个可靠的环节来帮助他们做状态管理这件事情。</p>
<p>在前端框架的发展过程中路由的诞生是水到渠成的（基于一些新技术的成熟，比如 <a href="http://diveintohtml5.info/history.html">HTML5 的History API</a> 等等），但是应用开发工程师对于路由的理解和重视却还远远不够。如果说传统的前端开发是以页面为中心来入手的话，那么现代的 SPA 应用开发就是以状态为中心来着手设计和开发的。</p>
<p>Ember 就是一款非常重视路由组件的 SPA 框架，本文借由一个实现 UI 布局的例子来谈谈 UI 编程与路由的关系，尽管这只是涉及到路由特性的一部分却也足够说明一些问题了。希望这个例子能让更多前端工程师认识和理解路由的重要性，从而更好的设计与实现 SPA 应用的各种功能场景。</p>
<h2>场景描述</h2>
<p>多数应用都有如下所述的 UI 设计：</p>
<ol>
<li><p>多数视图在一个通用的布局内呈现，比如典型的 Header + Main 的布局</p></li>
<li><p>个别视图需要一个特定的布局，比如登录和注册页面不需要 Header 等等</p></li>
</ol>
<p>对于这些场景来说，那些重复的 HTML 结构（如 Header 和 Footer）肯定需要某种方式的抽象使得它们可以复用或者指定渲染还是不渲染。后端渲染技术使用了一些机制（如 helpers 等） 来帮助开发者在视图层实现这些逻辑，等到返回给浏览器的时候已经是完整的 HTML 了（当然也有 Turbolinks 这样融合了部分前端路由特性的新技术，本文不做进一步描述），这显然是不适合前端应用的场景的，因为对于 SPA 应用来说用户更换 URLs 时需要在浏览器端即时拼装最终的完整视图，并不存在“预先渲染好的页面一起交付过来”这么一说。我们需要先思考一下高层设计，看看有什么机制可以利用的。</p>
<h3>初步分析</h3>
<p>路由是怎么管理状态的？复杂的话题简单说：</p>
<blockquote><p>In Ember.js, each of the possible states in your application is represented by a URL.<br>在 Ember.js 中，应用的每一个可能的状态都是通过 URL 体现的。</p></blockquote>
<p>这是<a href="http://guides.emberjs.com/v2.0.0/routing/">官方文档里所总结的</a>，我来试着举例表述一下：</p>
<p>假设当前有如下路由定义：</p>
<pre><code class="javascript">let Router = Ember.Router.extend()

Router.map(function() {
    this.route('dashboard', { path: '/dashboard' })
    this.route('signin', { path: '/signin' })
})</code></pre>
<p>于是，当用户——</p>
<ol>
<li><p>进入 <code>/dashboard</code> URL 的时候，对应的 <code>dashboard</code> 路由开始接管应用的当前状态</p></li>
<li><p>进入 <code>/signin</code> URL 的时候，对应的 <code>signin</code> 路由开始接管应用的当前状态</p></li>
<li>
<p><strong>但更重要的是：所有的路由都有一个共有的顶级路由——<code>application</code> 路由</strong>，其重要性主要体现在:</p>
<ol>
<li><p>它是唯一一个靠谱的可以用来管理全局范围状态的路由</p></li>
<li><p>它为所有子路由的视图渲染提供了模板的入口（outlet）</p></li>
</ol>
</li>
</ol>
<p>接着问题来了：如果说状态通过 URL 来体现，那么 UI 布局的不同如何体现呢？比如：</p>
<ol>
<li><p>进入 <code>/dashboard</code> URL 的时候，我们需要 Header + Main 的布局</p></li>
<li><p>进入 <code>/signin</code> URL 的时候，我们不需要 Header</p></li>
<li><p>无论何种情形，<code>application</code> 路由在其中的作用……？</p></li>
</ol>
<h2>第一次尝试</h2>
<p>因为每一个路由都会渲染自己的模版，我们可以做一个最简单的尝试：</p>
<pre><code class="handlebars">{{!app/pods/application/template.hbs}}
{{outlet}}</code></pre>
<pre><code class="handlebars">{{!app/pods/dashboard/template.hbs}}
&lt;header&gt;...&lt;/header&gt;
&lt;main&gt;
    ...
    {{outlet}}
&lt;/main&gt;</code></pre>
<pre><code class="handlebars">{{!app/pods/signin/template.hbs}}
&lt;main&gt;
    ...
    {{outlet}}
&lt;/main&gt;</code></pre>
<p>虽然这么做可以奏效，然而问题也是显而易见的：如果出现多个和 <code>dashboard</code> 一样的布局结构，我们将不得不多次重复 <code>&lt;header&gt;&lt;/header&gt;</code>；曾经 Ember 有 <code>{{partial}}</code> 这样的 helper 来做模版片段复用，但是第一，以后没有 <code>{{partial}}</code> 了，二来用 <code>{{partial}}</code> 做布局是错误的选择。</p>
<h3>问题分析</h3>
<p>如果我们可以把问题场景简化为只有一种可能，例如“所有的视图都用 Header + Main 的布局”，那么解决方案可以简化为：</p>
<pre><code class="handlebars">{{!app/pods/application/template.hbs}}
&lt;header&gt;...&lt;/header&gt;
&lt;main&gt;
    {{outlet}}
&lt;/main&gt;
&lt;footer&gt;...&lt;/footer&gt;</code></pre>
<pre><code class="handlebars">{{!app/pods/dashboard/template.hbs}}
...
{{outlet}}</code></pre>
<pre><code class="handlebars">{{!app/pods/signin/template.hbs}}
...
{{outlet}}</code></pre>
<p>那么再次恢复原来的场景要求，问题变成了：“进入 <code>/signin</code> 之后，如何隐藏 <code>application</code> 模版里的 <code>&lt;header&gt;&lt;/header&gt;</code>？</p>
<h2>第二次尝试</h2>
<p>隐藏模版里的片段，最简单的方法可以这么做：</p>
<pre><code class="handlebars">{{!app/pods/application/template.hbs}}
{{#if showNavbar}}
&lt;header&gt;...&lt;/header&gt;
{{/if}}

&lt;main&gt;
    {{outlet}}
&lt;/main&gt;</code></pre>
<p>我们知道模版内可访问的变量可以通过控制器来设置，但此时我不打算创建 <code>ApplicationController</code>，因为路由里有一个 <code>setupController</code> 的钩子方法能帮我们设置控制器的（更重要的原因是很快 Routable Components 将取代现在的 route + controller + template 的分层体系，所以从现在开始最好尽可能少的依赖 controller），试试看：</p>
<pre><code class="javascript">// app/pods/application/route.js
export default Ember.Route.extend({
    setupController(controller) {
        this._super(...arguments)
        controller.set('showNavbar', true)
    }),
})</code></pre>
<p>现在所有的状态都会显示 <em>header</em> 部分了，那怎么让 <code>/signin</code> 不显示呢？或许这样……？</p>
<pre><code class="javascript">// app/pods/signin/route.js
export default Ember.Route.extend({
    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set('showNavbar', false)
    }),
})</code></pre>
<p>以下是测试结果（这里建议先写 Acceptance Test，省时间且不易错漏），在每次刷新页面后：</p>
<table>
<thead><tr>
<th>从...</th>
<th>到...</th>
<th>结果</th>
</tr></thead>
<tbody>
<tr>
<td><code>/</code></td>
<td><code>/dashboard</code></td>
<td>成功</td>
</tr>
<tr>
<td><code>/dashboard</code></td>
<td><code>/</code></td>
<td>成功</td>
</tr>
<tr>
<td> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td><code>/</code></td>
<td><code>/signin</code></td>
<td>成功</td>
</tr>
<tr>
<td><code>/signin</code></td>
<td><code>/</code></td>
<td>失败</td>
</tr>
<tr>
<td> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td><code>/dashboard</code></td>
<td><code>/signin</code></td>
<td>成功</td>
</tr>
<tr>
<td><code>/signin</code></td>
<td><code>/dashboard</code></td>
<td>失败</td>
</tr>
<tr>
<td> </td>
<td> </td>
<td> </td>
</tr>
<tr>
<td><code>/signin</code></td>
<td><code>/dashboard</code></td>
<td>失败</td>
</tr>
<tr>
<td><code>/dashboard</code></td>
<td><code>/signin</code></td>
<td>失败</td>
</tr>
</tbody>
</table>
<p>我们在测试中增加了 <code>/dashboard</code> 的访问，但是我们并没有定义位于 <code>DashboardRoute</code> 里的 <code>setupController</code> 钩子，这是因为我们期望 <code>/dashboard</code> 能够继承 <code>/</code> 的状态，否则所有的路由都要设置类似的 <code>setupController</code> 会把人累死，然而测试结果可能会让初学者觉得摸不着头脑，我们试着分析一下好了：</p>
<ol>
<li><p><code>/</code> 和 <code>/dashboard</code> 都需要 <code>showNavbar === true</code>，所以正反都可以；</p></li>
<li><p>当自 <code>/signin</code> 刷新页面的时候，先执行了 <code>ApplicationRoute</code> 然后才是 <code>SigninRoute</code>，等到进入 <code>/</code> 的时候，<code>setupController</code> 不会再次执行的；</p></li>
<li><p>同上;</p></li>
<li><p>同上。</p></li>
</ol>
<h3>问题分析</h3>
<p>这里最明显的问题就是 <code>ApplicationRoute#setupController</code> 这个钩子方法是不可靠的，你只能保证它的第一次运行，一旦变成了在路由之间来回跳转就无效了。</p>
<blockquote><p>实际上，<code>setupController</code> 的作用是将 <code>model</code> 钩子返回的结果绑定在对应的控制器上的，你可以扩展这个逻辑但也仅限于数据层面的设置。只有当调用了 <code>route#render()</code> 且返回了与之前不同的 model 时 <code>setupController</code> 才会再次被调用。</p></blockquote>
<p>于是问题又变成了：有哪一个钩子方法能保证在路由发生变化的时候都可用？</p>
<h4>路由的生命周期</h4>
<p>这是一个非常重要但又很无趣的主题，我不想在这里重复那些可以通过阅读文档和亲测就可以得出的答案，不过我可以给出一份测试路由生命周期的完整代码片段：</p>
<p><a href="https://gist.github.com/nightire/f766850fd225a9ec4aa2">https://gist.github.com/nightire/f766850fd225a9ec4aa2</a></p>
<p>把它们放进你的路由当中然后仔细观察吧。顺便给你一些经验之谈：</p>
<ol>
<li><p>这个测试不要错过 <code>ApplicationRoute</code>，因为它是最特殊的一个</p></li>
<li><p>其他的路由至少要同时测试两个，比如 <code>IndexRoute</code> 和 <code>TestRoute</code></p></li>
<li><p>不要只测试页面刷新后的生命周期，还要尝试各种路由之间的相互过渡</p></li>
</ol>
<p>测试完之后，你就会对整个路由系统有一个非常全面的了解了，这些体验会带给你一个重要的技能，即是在将来你可以很容易的决断出实现一个功能应该从哪里入手。对于我们这个例子来说，比较重要的结论如下：</p>
<ol>
<li><p><code>ApplicationRoute</code> 是所有路由的共同先祖，当你第一次进入应用程序——无论是从 <code>/</code> 进入还是从 <code>/some/complicated/state</code> 进入——<code>ApplicationRoute</code> 都是第一个实例化的路由，并且它 <code>activated</code> 就不会 <code>deactivated</code> 了（除非你手动刷新浏览器）。因此我们可以把 <code>ApplicationRoute</code> 作为一个特殊的永远激活的路由</p></li>
<li><p>如果你有应用逻辑依存于 <code>ApplicationRoute#setupController</code>，那么第一次进入就是唯一靠谱的机会——你不能指望这个钩子会在路由来回切换的时候触发</p></li>
<li><p>但是其他路由上的 <code>#setupController</code> 钩子是会在每次过渡进来的时候重新执行的</p></li>
</ol>
<h2>第三次尝试</h2>
<p>基于以上分析，我们可以调整我们的代码了：</p>
<pre><code class="javascript">// app/pods/application/route.js
export default Ember.Route.extend()</code></pre>
<pre><code class="javascript">// app/pods/index/route.js and app/pods/dashboard/route.js
export default Ember.Route.extend({
    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set('showNavbar', true)
    },
})</code></pre>
<pre><code class="javascript">// app/pods/signin/route.js
export default Ember.Route.extend({
    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set('showNavbar', false)
    },
})</code></pre>
<p>我们把 <code>ApplicationRoute#setupController</code> 里的逻辑转移到了 <code>IndexRoute#setupController</code> 里去，就是因为当你访问 <code>/</code> 的时候，<code>ApplicationRoute#setupController</code> 只会触发一次（第一次刷新的时候），而 <code>IndexRoute#setupController</code> 则可以保证每次都触发。现在，我们设想的场景可以实现了。</p>
<p>这个设定一开始看起来非常古怪，很多初学者都在这里被搞晕掉：“为什么要有 <code>IndexRoute</code>？为什么不直接用 <code>ApplicationRoute</code>？”</p>
<h3>抽象路由</h3>
<p>当我们刚开始接触前端的路由机制时，我们很容易把 <code>ApplicationRoute</code> 和 <code>/</code> 关联起来，可实际上真正和 <code>/</code> 关联的是 <code>IndexRoute</code>。如果你没有自行创建 <code>IndexRoute</code>，Ember 会帮你创建一个，但不管怎样 <code>IndexRoute</code> 都是必不可少的。</p>
<p>那么 <code>ApplicationRoute</code> 到底扮演着一个什么样的角色呢？</p>
<p>先记住这个结论：<strong>在路由系统中，路由树中任何一个当前激活的路径都会至少包括两个路由节点，并且其中一个必然是 <code>ApplicationRoute</code>，</strong>这也正是 <code>ApplicationRoute</code> 永远处于 <code>activated</code> 而永远不会 <code>deactivate</code> 的原因所在。</p>
<p>举几个例子：</p>
<ol>
<li><p>当访问 '/' 时，路由树中当前激活的路径为：<code>application =&gt; index</code></p></li>
<li><p>当访问 '/users/new' 时，路由树中当前激活的路径为：<code>application =&gt; users =&gt; new</code></p></li>
<li><p>当访问 '/posts/1/comments/1' 时，路由树中当前激活的路径为：<code>application =&gt; post =&gt; index =&gt; comment =&gt; index</code>，也可能是：<code>application =&gt; posts =&gt; show =&gt; comments =&gt; show</code> ——取决于你的路由规则的写法</p></li>
<li><p>等等……</p></li>
</ol>
<p>Ember 并没有为这个特殊的 |
41b8a0714e572ed059c0e52d0e3c676c91
| 做一个明确的定义（但是|
41b8a0714e572ed059c0e52d0e3c676c92
|），不过在其他类似的路由系统里我们可以找到等价物——比如来自 |
41b8a0714e572ed059c0e52d0e3c676c93
|（Angular 生态圈里最优秀的路由系统）里的<a href="https://github.com/angular-ui/ui-router/wiki/Nested-States-and-Nested-Views#abstract-states">抽象路由（Abstract Route）</a>。</p>
<p>Ember 的 <code>ApplicationRoute</code> 和 ui.router 的抽象路由非常相似，它们的共性包括：</p>
<ol>
<li><p>都能够拥有子路由</p></li>
<li><p>自身都不能被直接激活（不能位于路由树中当前激活路径的顶点）</p></li>
<li><p>不能直接过渡，也就是 transition to；Ember 里会等价于过渡到 <code>IndexRoute</code>，ui.router 则会抛出异常</p></li>
<li><p>都有对应的模版、控制器、数据入口、生命周期钩子等等</p></li>
<li><p>当其下的任意子路由被激活，作为父节点的抽象路由都会被激活</p></li>
</ol>
<p>当然，它们也有不同，比如说：你可以在 ui.router 的路由树中任意定义抽象路由，不受数量和节点深度的限制，只要保证抽象路由不会位于某条路径的顶点就是了；而 Ember Router 只有一个抽象路由（而且并没有明确的定义语法，只是行为类似——典型的鸭子类型设计嘛）且只能是 <code>ApplicationRoute</code>，你可以手动创建别的路由来模拟，但是 Ember Router 不会阻止你过渡到这些路由，不像 ui.router 会抛出异常（这一点很容易让初学者碰壁）</p>
<p>实际上当你对 Ember Router 的理解日渐深入之后你会发现<a href="http://guides.emberjs.com/v2.0.0/routing/defining-your-routes/#toc_the-index-route">所有的嵌套路由（包括顶层路由）都是抽象路由</a>，因为它们都会隐式的创建对应的 |
41b8a0714e572ed059c0e52d0e3c676c98
| 作为该路径的顶节点，访问它们就等于访问它们的 |
41b8a0714e572ed059c0e52d0e3c676c99
|。我认为 Ember Router 的这个设计与 ui.router 相比有利有弊：</p>
<ul>
<li><p>利：设计精巧简单，可以避免大量的 boilerplate 代码，路由的定义相对清晰简洁</p></li>
<li><p>弊：对于初学者来说，由于不存在抽象路由的概念，很难深刻理解父子节点，特别是隐式 <code>IndexRoute</code> 的存在价值</p></li>
</ul>
<h3>这个方案足够完美了吗？</h3>
<p>不，还差一些。试想：当我们需要很多路由来组织应用程序的结构时，类似的 <code>#setupController</code> 岂不是要重复定义很多次？如何抽象这一逻辑让其变得易于复用和维护？</p>
<h4>Thinking in Angular way(w/ ui.router)</h4>
<p>在开发 Angular 应用的时候，类似场景的路由定义一般是这样的：</p>
<pre><code class="text">                   +----&gt; layoutOne(with header) +----&gt; childrenRoutes(like dashboard, etc.)       
                   |
                   |
application(root) -|
                   |
                   |
                   +----&gt; layoutTwo(without header) +----&gt; childrenRoutes(like signin, etc.)
</code></pre>
<p>我们用 Ember Router 也可以模拟这样的路由定义，实现同样的结果，代码类似：</p>
<pre><code class="javascript">// app/router.js
let Router = Ember.Router.extend({
  location: config.locationType,
})

Router.map(function() {
    // provide layout w/ &lt;header&gt;&lt;/header&gt;
    this.route('layoutOne', { path: '/' }, function() {
        this.route('dashboard', { resetNamespace: true })
        // ...
    })

    // provide layout w/o &lt;header&gt;&lt;/header&gt;
    this.route('layoutTwo', { path: '/' }, function() {
        this.route('signin', { resetNamespace: true })
        // ...
    })
})</code></pre>
<p>但是个人非常不喜欢也不推崇这么做，原因是：</p>
<ol>
<li><p>这样的路由定义写多了会很恶心</p></li>
<li>
<p>为了避免类似 <code>/layoutOne/dashboard</code> 这样的 URLs，不得不重复设定 <code>path: '/'</code> 来覆盖</p>
<ul><li><p>ui.router 解决此问题依靠的是 url pattern inheritence，由于每一个路由的定义都必须指明 url 属性，所以也就习惯了</p></li></ul>
</li>
<li>
<p>为了避免类似 <code>layoutTwo.signin</code> 这样的路由名字，不得不重复设定 <code>resetNamespace: true</code></p>
<ul><li><p>ui.router 解决此问题依靠的是路由定义里的 parent 属性，所以子路由是可以分开定义的，不用嵌套也就无需 resetNamespace</p></li></ul>
</li>
</ol>
<p>对比两家的路由定义语法，各有优缺点吧，但是 Ember Router 向来都是以简明扼要著称的，真心不喜欢为了这个小小需求而把路由定义写得一塌糊涂</p>
<p>另外这样的路由设计还会导致 <code>application</code> 这个模版变成一个废物，除了 <code>{{outlet}}</code> 它啥也做不成，生成的 DOM Tree 里平白多一个标签看的人直恶心～</p>
<h4>Thinking in Ember way</h4>
<p>既然问题的本质是 <code>#setupController</code> 钩子需要重复定义，那么有没有 Ember 风格办法来解决这一问题呢？</p>
<p>首先我们来考量一下 Mixin，你可以这么做：</p>
<pre><code class="javascript">// app/mixins/show-navbar.js
export default Ember.Mixin.create({
    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set('showNavbar', true)
    },
})

// app/mixins/hide-navbar.js
export default Ember.Mixin.create({
    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set('showNavbar', false)
    },
})</code></pre>
<pre><code class="javascript">// app/pods/index/route.js and app/pods/dashboard/route.js
import ShowNavbarMixin from '../../mixins/show-navbar'

export default Ember.Route.extend(ShowNavbarMixin, {
    // ...
})

// app/pods/signin/route.js
import HideNavbarMixin from '../../mixins/hide-navbar'

export default Ember.Route.extend(HideNavbarMixin, {
    // ...
})</code></pre>
<p>这么做倒也不是不行，但是——明显很蠢嘛——这和抽取两个方法然后到处调用没有什么本质的区别，看起来我们需要的是某种程度上的继承与重写才对：</p>
<pre><code class="javascript">// somewhere in app/app.js
Ember.Route.reopen({
    // show navbar by default, can be overwriten when define a specific route
    withLayout: true,

    setupController() {
        this._super(...arguments)
        this.controllerFor('application').set(
            'showNavbar', this.get('withLayout')
        )
    },
})</code></pre>
<pre><code class="javascript">// app/pods/index/route.js and app/pods/dashboard/route.js
// Do nothing if showNavbar: true is expected

// app/pods/signin/route.js
export default Ember.Route.extend({
    withLayout: false,
})</code></pre>
<p>这样就行了，不需要额外的路由体系设计，就用 Ember 的对象系统便足够完美。本文所描述的这个例子其实非常简单，我相信略有 Ember 经验的开发者都能做出来，但是我的重点不在于这个例子，而在于对路由系统的一些阐述和理解。这个例子来源自真实的工作，为了给同事解释清楚最初的方案为什么不行着实费了我好大功夫，于是我把整个梳理过程记录下来，希望对初学者——特别是对 SPA 的核心尚未了解的初学者能有所助益吧。</p>
<h3>基于事件的解决方案</h3>
<p>这个问题其实还有多种解法，基于事件响应的解法我就在现实里演示了两种，不过相比于上面的最终方案，它们还是略微糙了些。在这里我写其中一种比较少见的，里面涉及到一些 Ember 的内部机制，权当是一个借鉴吧，思路我就不多解释了。</p>
<pre><code class="javascript">// app/mixins/hide-navbar.js
export default Ember.Mixin.create({
    hideNavbar: function() {
        this.set('showNavbar', false)
    }.on('init'),
})</code></pre>
<pre><code class="javascript">// app/router.js
let Router = Ember.Router.extend({
    location: config.locationType,

    didTransition() {
        this._super(...arguments)

        let currentRoute = this.get('container')
        .lookup(`route:${this.get('currentRouteName')}`)

        this.get('container').lookup('controller:application').set(
            'showNavbar', _.isUndefined(currentRoute.get('showNavbar'))
        )
    }
})</code></pre>
<pre><code class="javascript">// app/pods/signin/route.js
import HideNavbarMixin from '../../mixins/hide-navbar'

export default Ember.Route.extend(HideNavbarMixin, {
    // only use this mixin when you need to hide the Header
})</code></pre>
<hr>
<blockquote><p>原文首发于 <a href="https://ruby-china.org/topics/27258">Ruby China 社区</a>，转载请注明。</p></blockquote>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727746";}i:34;a:11:{s:5:"title";s:67:"[Tips on Ember 2] Ember CLI 和 Sass (及其周边) 的协同工作";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727742";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727742";s:7:"updated";s:25:"2015-09-09T18:39:31+08:00";s:9:"published";s:25:"2015-09-09T18:39:31+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"nightire";s:10:"author_uri";s:34:"http://segmentfault.com/u/nightire";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:13510:"
<p>今天这篇主要讲讲 Ember CLI 里关于样式开发的一些前期准备工作，主要是 Sass 和 Bootstrap。</p>
<blockquote><p><a href="http://www.emberaddons.com/">Ember Addons</a> 是寻找各种组件的绝佳场所，下文将要介绍的一些都可以在这里找到，没事的时候多探索一下会有很多惊喜。</p></blockquote>
<h2>关于 Sass</h2>
<p>Sass 的演变和使用在前端开发领域真是个又臭又长的话题，如果你是自行搭建构建系统你就明白我说的意思了。还好 Ember CLI 的生态系统比较完备，也有一个广大的社区做后盾可以为我们省去很多功夫。</p>
<p>对于 Sass 的基础使用，我们只需要安装 |
3822741913b0abccece813de6916a2f41
| 就好了，它默认使用 <a href="https://www.npmjs.com/package/node-sass">node-sass</a>，支持 SourceMaps 和 IncludePaths 等功能选项，比较省心。较新的 Ember CLI 应该是直接内置了 ember-cli-sass 的，推荐升级哦。</p>
<p>对于不太熟悉 Sass 的程序员，IncludePaths 值得一讲，我见到有些人啊为了方便的 import，把许多第三方的 sass 文件拷过来拷过去的，其实大可不必哦～就拿 <a href="https://github.com/twbs/bootstrap-sass">bootstrap-sass</a> 为例好了：</p>
<p>安装 bootstrap-sass：</p>
<pre><code>$ npm install bootstrap-sass --save</code></pre>
<p>完后呢，入口文件的路径在 <code>node_modules/bootstrap-sass/assets/stylesheets</code> 这里，因为通常 <code>node_modules/</code> 和 <code>bower_components/</code> 这些目录是不会被包含在项目里的（包含在 Git 或 HTTP Server Root 下），所以才会有手工拷贝到别处的做法。在 Ember CLI 里，你可以这样设置一下：</p>
<pre><code class="javascript">// ember-cli-build.js or Brocfile.js
var app = new EmberApp(defaults, {
    sassOptions: {
        includePaths: [
            'node_modules/bootstrap-sass/assets/stylesheets'
        ]
    }
})</code></pre>
<p>之后在项目的 sass 文件内直接 <code>@import "bootstrap";</code> 就好了，那是一个数组所以你懂的，你可以设置很多路径，sass 在编译的时候会挨个儿去找。</p>
<h3>关于 POD</h3>
<p>如果你跟我一样喜欢 POD 文件结构，那么还有一个 <a href="https://www.npmjs.com/package/ember-cli-sass-pods">ember-cli-sass-pods</a> 也可以用用，这个东西能让你这样生成 sass 文件：</p>
<pre><code class="shell">$ ember generate style [name] -p</code></pre>
<p>生成的文件会保存在同名的 POD 目录下，不过我一向都是手动创建文件的，所以并没有实际测试它。对于样式文件在 POD 架构下的导入我是这样做的：</p>
<ol>
<li><p>创建 <code>app/styles/_pods.scss</code> 文件</p></li>
<li><p>在 <code>app/styles/app.scss</code> 文件里添加一句 <code>@import "pods";</code></p></li>
<li><p>在 <code>includePaths</code> 那里添加 <code>app/pods</code> 这一项</p></li>
<li><p>新增加的 PODs 样式在 <code>app/styles/_pods.scss</code> 内这样引用：`@import "name/style;"</p></li>
</ol>
<p>后来我注意到 ember-cli-sass-pods 也是这么做的，英雄所见略同嘛～</p>
<h2>关于 Bootstrap w/ sass</h2>
<p>前面提到了用 |
3822741913b0abccece813de6916a2f415
| 来引用 Bootstrap 的方法，不过在 Ember CLI 项目里，我还是推荐你用 <a href="https://www.npmjs.com/package/ember-cli-bootstrap-sassy">ember-cli-bootstrap-sassy</a> 来辅助你做这件事，因为这个 addon 额外做了几件好事：</p>
<ol>
<li><p><a href="https://github.com/lifegadget/ember-cli-bootstrap-sassy/blob/master/blueprints%2Fember-cli-bootstrap-sassy%2Findex.js?ts=240px#L11">添加了 bower 版的 bootstrap-sass</a>，省去了你人工寻找和安装的过程</p></li>
<li><p><a href="https://github.com/lifegadget/ember-cli-bootstrap-sassy/blob/master/index.js?ts=240px#L54">完成了 <code>includePaths</code> 的设置</a>，免得你忘记了</p></li>
<li><p>完成了 |
3822741913b0abccece813de6916a2f420
| 和 <a href="https://github.com/lifegadget/ember-cli-bootstrap-sassy/blob/master/index.js?ts=240px#L25">脚本文件的导入</a>，好省心呐</p></li>
<li><p>Bootstrap 自带的字体图标可以选择不导入，JavaScript 的模块可以选择性的导入或者完全不要，具体设置如下所示：</p></li>
</ol>
<pre><code class="javascript">var app = new EmberApp(defaults, {
    // ...
    'ember-cli-bootstrap-sassy': {
        glyphicons: false,
        js: ['transition', 'collapse']
    }
})</code></pre>
<h3>使用／定制 Bootstrap 的正确姿势</h3>
<p>关于这个话题我简直可以写本小说出来了，在我带实习生的过程里被问到和发现最多问题的就是 Bootstrap 的用法，限于篇幅我在这里只将一些前期的要点：</p>
<h4>别直接用 <code>_bootstrap.scss</code>
</h4>
<p>大多数人是这样用的：直接在主样式文件里 <code>@import "bootstrap";</code>，然后遇到需要定制的就开始覆盖覆盖覆盖……别这么搞！</p>
<p>看一下 |
3822741913b0abccece813de6916a2f424
| 以及 <a href="https://github.com/twbs/bootstrap-sass/blob/master/assets%2Fstylesheets%2F_bootstrap.scss?ts=240px">源码</a> 便知道人家本来就是模块化开发的，既然用了 sass 咱就应该把它当成级别高点的编程语言来对待。我是这么做的：</p>
<ol>
<li><p>创建 <code>app/styles/_custom-bootstrap.scss</code> 文件</p></li>
<li><p>在 <code>app/styles/app.scss</code> 里 <code>@import "custom-bootstrap";</code>，一般来说这个应该是第一个导入的模块</p></li>
</ol>
<h5>
<code>_custom-bootstrap.scss</code> 怎么用？</h5>
<p>一开始你可以把原来的 <code>_bootstrap.scss</code> 内容原封不动拷贝进来，由于 <code>includePaths</code> 的作用，所有导入的路径都可以不变。</p>
<p>然后把所有的模块导入都注释掉，此时你的项目里等于完全没有 Bootstrap。</p>
<p>之后一般会分两种情况来定制：</p>
<ul><li><p><strong>需要用到且可以直接沿用的模块</strong></p></li></ul>
<p>这个简单，把注释的部分去掉就好了嘛。曾经有徒弟质疑我：“师傅，人家官网上有自定义模块构建的功能，咱为啥不用那个？”</p>
<p>图样图森破，那个功能就是拿来秀的，一点实用性都没有。有多少人自定义构建之后从头用到尾刚刚好既不多又不少的？神都预测不到你会用到哪些组件的，难道你一遍又一遍的去构建定制版本啊？那是菜鸟的用法。</p>
<ul><li><p><strong>需要用到但得修改／定制的模块</strong></p></li></ul>
<p>这里又可以大致分出两种情形，比较简单的改动——比如变量，你可以把其定义写在 <code>@import "bootstrap/variables";</code> 的前面（特别是覆盖默认变量的，一定注意顺序）；我会做的比较彻底，直接创建一个 <code>app/styles/_custom-variables.scss</code> 并且作为第一个模块导入进去。另外，自定义的变量不需要写尾部的 <code>!default</code>。</p>
<p>第二种情形就比较进阶一些了，我举个例子，以前经常看见这样的写法：</p>
<pre><code class="html">&lt;button type="button" class="btn btn-default btn-block btn-purple"&gt;...&lt;/button&gt;</code></pre>
<p>我说你写这么多 class 不累啊？人家 Bootstrap 是为了可重用性才定义了这种粒度很细的 helper classes，如果你是做一个 rapid prototype 那我没意见，但是正式的产品这样写问题就大了：</p>
<ol>
<li><p>像 <code>btn-purple</code> 这样的命名是很糟糕的，完全没有语义性，万一将来要换个色彩主题怎么办？可维护性也很差，万一将来维护的是个色盲怎么办？（开个玩笑）</p></li>
<li><p>重复的写一串 class 可读性也很差，如果将来要进行微调，不熟悉这些 class 的人会被折腾死</p></li>
</ol>
<p>该怎么写？</p>
<pre><code class="html">&lt;button type="button" class="button-main button-block"&gt;...&lt;/button&gt;</code></pre>
<pre><code class="scss">/// app/styles/_custom-buttons.scss

// Overwrite for more semantic button class names
.button {
    @extend .btn;

    // Bootstrap doesn't give buttons transition effects by default,
    // so we simply extend it here. You can use some mixin instead.
    transition: all .2s ease-out;
}

@each $name in default, primary, success, warning, danger, info, block {
    .button-#{$name} {
        @extend .btn-#{$name};
    }
}

// Define site-wide main button colors
$button-main-color:  #fff;
$button-main-bg:     $violet;
$button-main-border: darken($violet, 5%);

.button-main {
    @extend .button;
    @include button-variant(
        $button-main-color, $button-main-bg, $button-main-border
    );
}</code></pre>
<p>这是个例子，我从最近的一个项目里扒出来的，仅就这一例子而言或许有点小题大做，但如果考虑一个大型的项目，这样的改造绝对是有必要的。好的习惯要从小养成，正确的姿势得贯彻始终。</p>
<p>类似的技巧还有好多，鉴于这里的主题是 Ember CLI 呢便就此打住了，我也是想：既然选择了 Ember 这么靠谱的前端框架，相应的前端技术也应该靠谱起来吧，所以抛砖引玉一下。</p>
<h3>还有什么值得一用？</h3>
<p>Bootstrap 绝对不完美，只会用它的前端工程师绝对不是合格的前端工程师，针对 Bootstrap 不完善的地方 sass 社区还有非常多的组件值得一用。在这里我先推荐几个，以后还可以再补充。</p>
<h4>Susy</h4>
<p>Bootstrap 的 Grid 系统很一般（虽说对它的定位而言也够用），定死的 12 栅格并非时时够用；嵌套时的 gutter 无法灵活调整；需要手动覆盖 row 两端 cols 的 padding（当你需要边缘与 container 对齐的时候，如 gallery 布局）……等等槽点都被喷了好几年了。</p>
<blockquote><p>Bootstrap v4 将使用 flex 做 Grid 系统，这是好事</p></blockquote>
<p>所以我推荐你试一下 <a href="http://susy.oddbird.net/">Susy</a>，做布局——专业的！用在 Ember CLI 里也很简单，|
3822741913b0abccece813de6916a2f436
|，然后设定一下 |
3822741913b0abccece813de6916a2f437
| 就好，非常轻量，非常好用</p>
<h4>Bourbon</h4>
<p>Bootstrap 自己定义了一些 |
3822741913b0abccece813de6916a2f439
| 善用它们会令你事半功倍，然而习惯了 compass 的开发者大概还是会觉得不够用吧？因此我向你推荐 <a href="http://bourbon.io/">Bourbon</a>，ThoughtBot 出品，Ruby 社区应该不陌生的，品质一流。</p>
<p>总的来说 Compass 就不要再用了，又大又笨而且连亲爹都准备放弃它了，未来将是小快灵组件协同工作的大趋势，Bourbon 就是可以用来替代 |
3822741913b0abccece813de6916a2f441
| 的组件库。另外它的兄弟 <a href="http://neat.bourbon.io/">Neat</a> 也不错，只是功能上和我们上述的工具集合有冲突了，不是很有必要。</p>
<h4>Breakpoint</h4>
<p>这个推荐一下，可以选用，主要是用来辅助响应式设计开发的，比 Bootstrap 自带的那点特性强大多了。<a href="http://breakpoint-sass.com/">http://breakpoint-sass.com/</a></p>
<h2>关于后期处理</h2>
<p>前面说的一大堆综合起来都是做 CSS 的前期处理的（也就是 pre-processing），现在前端也很重视后期处理（post-processing），关于这个话题呢推荐看一下 <a href="http://pleeease.io/">pleeease</a> 也就差不多了。</p>
<p>样式的后期处理有很多范畴，综合考虑我认为目前唯一称得上必须要做的那就是 <a href="https://github.com/postcss/autoprefixer">Autoprefixer</a>，这个东西的特点及用法概括如下：</p>
<ol>
<li><p>有了它，你再也不用去写 <a href="http://webdesign.about.com/od/css/a/css-vendor-prefixes.htm">vendor prefixes</a>，连想都不要去想（如果你用到的第三方组件越俎代庖了也没关系，Autoprefixer 会自动筛选一遍）</p></li>
<li><p>当你构建的时候，它会自动分析你的样式，然后添加必要的 vendor prefixes</p></li>
<li><p>你可以指定针对的浏览器品牌，版本，受众地区等等参量，从而让它知道哪些 vendor prefixes 是需要加的</p></li>
<li><p>它通过 <a href="http://caniuse.com/">Can I Use</a> 提供的技术数据来完成最终的工作</p></li>
</ol>
<p><a href="https://github.com/kimroen/ember-cli-autoprefixer">ember-cli-autoprefixer</a> 可以帮助你把它集成到 Ember CLI 项目中，简单好用。以下是一个配置的范例代码：</p>
<pre><code class="javascript">var app = new EmberApp(defaults, {
    // ...
    autoprefixer: {
        browsers: ['&gt; 5% in CN', 'last 2 versions']
    }
})</code></pre>
<p>仔细阅读一下 Autoprefixer 的文档，你会发现配置它所用到的 <a href="https://github.com/ai/browserslist">DSL（BrowserList）</a> 还蛮有趣的。</p>
<hr>
<p>得，今天就说到这里，本来这篇早就写得差不多了，只是这两天一直在挖／填 Ember2 的一些坑没顾上整理，耽误了。到此前期的周边打造就差不多了，下篇开始我打算重点写一些和 Ember 的特性密切相关的东东，maybe 先从路由开始。</p>
<hr>
<blockquote><p>原文首发于 <a href="https://ruby-china.org/topics/27246">Ruby China 社区</a>，转载请注明。</p></blockquote>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727742";}i:35;a:11:{s:5:"title";s:41:"[Tips on Ember 2] Ember CLI with Webstorm";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727722";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727722";s:7:"updated";s:25:"2015-09-09T18:36:17+08:00";s:9:"published";s:25:"2015-09-09T18:36:17+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"nightire";s:10:"author_uri";s:34:"http://segmentfault.com/u/nightire";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:10074:"
<blockquote><p>Tips on Ember 2 对我来说是没什么计划性的写作，我只是把它当做是每天工作的总结日志，一个很重要的目的是为团队做一些技术事务的整理，以帮助一些新人快速成长起来。如果有些内容不能满足各位看官的胃口，提前说声抱歉并且请不要担心，随着项目的逐渐开展，好戏会在后头。</p></blockquote>
<h5>补充上篇的内容</h5>
<p><a href="https://ruby-china.org/topics/27155#%E9%87%8D%E5%86%99%E6%97%A7%E7%9A%84%20components">上一篇我提到了暂时使用 <code>Ember.GlimmerComponent</code> 取代 <code>Ember.Component</code></a> 的事情，虽然有效但是却不得不改变编写 Component 的接口，着实挺烦的。其实我们可以直接替换掉旧的 |
0e610412be5446ac40810dba92904e3c2
| 便好，于是我加了很简单的一句：</p>
<pre><code class="javascript">// app/app.js
// ...

Ember.MODEL_FACTORY_INJECTIONS = true

Ember.GlimmerComponent.reopenClass({
  isComponentFactory: true
})
Ember.Component = Ember.GlimmerComponent

App = Ember.Application.extend({...})</code></pre>
<p>这样你 Component 该怎么写就怎么写，不用再改了。</p>
<h3>不喜欢 Ember 和 Ember CLI 的 Webstorm</h3>
<p>我是 Vim 党，很少折腾复杂笨重的 IDEs，然而小伙伴们不高兴了，纷纷表示 Vim 太难学还是要用 Webstorm（也有选择 Sublime／Atom 的，由于配置比较简单，略过）。好，你用就用吧，各种问题自己也不会看文档问谷歌，成天怨声载道的（不得不吐槽一下现在的年轻人……）。没办法，我自己来一遍配置，填掉所有的坑！</p>
<p>Webstorm 以前用 Angular 的时候也试过，总体上还行，代码补全比较优秀，就是稍微有点慢；然而我是那种不依赖自动补全，就是喜欢手打的类型，所以还是轻便迅捷的 Editor 合我的胃口。这次换成搭配 Ember 和 Ember CLI 了，好家伙～各种小问题层出不穷，官方就是不支持你也没有办法，最终我只能整理一下力所能及的配置过程了——</p>
<h3>项目特定</h3>
<h4>文件夹标记</h4>
<p>在 Webstorm 导入 Ember CLI 创建好的项目之后，打开［Preferences -&gt; Project -&gt; Directories］，然后针对项目里的各种目录打一些必要的标记；如图：</p>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/444d69f57bd9b870917974cb18b35939.png" alt="directories" title="directories"></p>
<p>简要解释一下这三个标记的作用：</p>
<ul>
<li><p><strong>Tests：</strong>标记测试文件所在的根路径；对于很多测试框架来说这是 Webstorm 给它们指示测试文件位置的标志，然而由于并不支持 Ember CLI 所以没什么鸟用——当然你可以尝试绕过 Ember CLI 直接配置基于 QUnit 的测试环境，难～</p></li>
<li><p><strong>Excluded：</strong>该标记作用下的文件夹会被 Webstorm 内部的各种机制排除在外，比如说代码补全、状态监视（版本控制）、项目结构解析（常用于重构等）等等；主要的作用就是提速——你把 <code>tmp/</code> 去掉这个标记试试看！</p></li>
<li><p><strong>Resource Root：</strong>标记静态资源的位置；之后在代码内但凡出现相对路径的资源索引，都会从这里面来找，比如说 HTML 里面的 <code>src</code> 属性和 CSS 里面的 <code>url()</code> 等等……</p></li>
</ul>
<p>OK，后面两个其实是调整 Webstorm 性能与功能的关键平衡点，标记的过少会导致很多智能特性发挥不了用处，反之则会严重降低 IDE 的运行性能。我 09 年的老爷机通过合理配置（和上图那个 Demo 不完全一样，需要自己摸索）之后跑得比最新的 MBP 还顺畅我会随便乱讲？</p>
<h3>语言与框架</h3>
<h4>Javascript</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/60f405736e99f0ab4261a3fa2305e0f3.png" alt="javascript" title="javascript"></p>
<ul>
<li><p>目前版本的 Ember CLI 已经全面支持 ES6 了，所以这里的选择是理所当然的；</p></li>
<li><p>严格模式不用选，因为 Ember CLI 创建的代码都是基于 ES6 Modules 的，默认都是严格模式，不需要 IDE 检查；</p></li>
<li><p>最后一个选项决定了自动代码补全结果的丰富程度，不选会给你找出更多的补全项，但也意味着杂乱和性能损耗。</p></li>
</ul>
<h4>Node.js and NPM</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/2fc6ea1d1876b8f24d95f72432f637e3.png" alt="node-and-npm" title="node-and-npm"></p>
<ul>
<li><p>先跳到 node.js 和 npm 的配置，由于我们统一使用的是 io.js，所以如上图所示对应的路径。</p></li>
<li>
<p>以前呢，io.js 的 sources 是不能在这里获取到的，最近的版本应该是修正了这个问题。不过下载下来的 sources 被命名为 <em>Node.js v3.2.0 Core Modules</em> 由于我手动改了它的名字（后面会讲到），所以上图里看起来还是未下载和配置 sources 的样子。</p>
<ul>
<li><p>这个 sources 有什么用？当你开发 node.js/io.js 模块时，如果能有对核心库的代码补全、分析、调试、文档等功能那自然是很爽。但是 node.js/io.js 把核心库都封装在了二进制运行命令中，IDE 无法直接获取到，因此这些 sources 就是用来做上述功能的。</p></li>
<li><p>对于 Ember 应用程序开发来说，以上是非必需的，没有配置也没什么影响。只不过 Ember CLI 是工作于 node.js/io.js 环境下的，如果你经常需要看相关模块的代码，或是 debugging 它们，这就派上用场了。</p></li>
</ul>
</li>
</ul>
<blockquote><p><strong>为什么使用 io.js？</strong>有关 node.js 和 io.js 的纠结历史可以去谷歌一下，此处不再啰嗦；最根本的原因就是 io.js 对 ES6 的支持更好，更新和维护也更勤快。好消息是不久以后当 io.js 进入 v4 的时候，node.js 和 io.js 将再次合并，从此以后将只有一个 node.js v4 了。</p></blockquote>
<h4>Libraries</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/cfeefeb013df9f156041e28d92fa55c5.png" alt="libraries" title="libraries"></p>
<p>node.js 和 npm 那边配置好以后呢，在这里会出现 <em>Node.js v3.2.0 Core Modules</em>，如上图所示我已经把它更名为 <em>io.js v3.2.0 Core Modules</em> 了。最上面那个 <em>ember-DefinitelyTyped</em> 是 TypeScript 社区提供的 API Stubs，有助于快速的代码补全提示。TS Community 还提供了大量的 JS 库或框架的 API Stubs，非常便利。这些都可以在这个界面里搜索和安装。</p>
<h4>JSHint</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/a297a0d4f182d324979995e009e5ffb3.png" alt="jshint" title="jshint"></p>
<p>Ember CLI 集成了代码质量控制工具 JSHint，Webstorm 也有很棒的内部支持，不过配置要跟着上图来，否则是没有用的。</p>
<h4>Templates</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/78ac3351c18394f64c69d9e3991f159b.png" alt="templates" title="templates"></p>
<p>这些是关于模版引擎的支持，现在 Ember 已经使用了全新的模版引擎：HTMLBars，目前没什么 IDE 有完整支持的，最贴近的还是 Handlebars 插件（可能需要自行安装或开启，见［Preferences -&gt; Plugins］）。</p>
<ul>
<li><p>前两个选项完全是看个人偏好</p></li>
<li><p>第三个不要选！选了之后会使用内置的格式控制，但实际上并没有针对 Handlebars 的格式控制调整，因此据我观察还是复用了 HTML 那一套，然而并不好用；Ember CLI 继承了 EditorConfig（Webstorm 有对应的插件支持），因此还是交给插件自己去控制，这样可以获得相对漂亮的代码格式控制</p></li>
<li><p>第四个选项其实没啥用处（在 Ember 项目里全是 <code>.hbs</code>，没有 <code>.html</code> 什么事情），选不选都一样</p></li>
<li><p>最后的注释还是选择 Handlebars 风格比较好</p></li>
</ul>
<h4>Bower</h4>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/d37f7563220cdbe3bf0daa925e19a0b3.png" alt="bower" title="bower"></p>
<p>Bower 的支持配置很简单，路径选对就是了。</p>
<hr>
<p>就这些，Webstorm 对 Ember 和 Ember CLI 的支持也就这样了，真心很有限，感觉有点对不起它的名声呀，我觉得你们大家还是投入到 Vim 的怀抱来吧！</p>
<p>最后奉送一个 tip，在 v2.3 的 Routable Components 到来之前有用的：</p>
<h3>修改 toplevel component/view 的方法</h3>
<p>什么是 toplevel component/view 呢？就是应用初始化后在 <code>&lt;body&gt;</code> 标签里插入的第一个 DOM 元素，它通常是这样的：</p>
<pre><code class="html">&lt;body&gt;
  &lt;div id="ember-xxx" class="ember-view"&gt;...&lt;/div&gt;
&lt;/body&gt;</code></pre>
<p>它看起来和其他的 components 差不多，唯一的问题是如果你想改它的 <em>tagName</em>/<em>elementId</em>/<em>classNames</em> 等属性的时候该怎么办？</p>
<p>创建一个 ApplicationComponent？没用……创建一个 ApplicationView？对不起，View 已经没了……</p>
<p>在 Routable Components 出来之前（其实这就是一个典型的 Routable Component），唯一修改它的办法其实是创建一个叫 ApplicationView 的 Component——啥意思？看下面：</p>
<pre><code class="bash">$ ember generate view application</code></pre>
<p>然后编辑 <code>app/views/application.js</code></p>
<pre><code class="javascript">import Ember from 'ember'

export default Ember.Component.extend({
    tagName: 'main',
    classNames: ['application']
    ...
})</code></pre>
<p>如上，它是一个 Component，但要保存在 <code>app/views</code> 下面，否则是找不到的。</p>
<hr>
<blockquote><p>原文首发于 <a href="https://ruby-china.org/topics/27174">Ruby China 社区</a>，转载请注明。</p></blockquote>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727722";}i:36;a:11:{s:5:"title";s:54:"[Tips on Ember 2] 如何尝试 angle-bracket component";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727708";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727708";s:7:"updated";s:25:"2015-09-09T18:33:50+08:00";s:9:"published";s:25:"2015-09-09T18:33:50+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:8:"nightire";s:10:"author_uri";s:34:"http://segmentfault.com/u/nightire";s:2:"re";a:1:{s:4:"rank";s:1:"1";}s:7:"summary";s:7974:"
<blockquote><p>Ruby China 的朋友大概都知道我很喜欢 Ember，然而我用 Ember 的经历其实远比不上 Angular 那么丰富（Ember 业余爱好，Angular 做正儿八经的项目）。最近我换工作了，终于可以在新的项目里主导使用 Ember 来开发 Web App，恰逢 Ember 进入了 2.0 时代，许多东西和当初自己瞎玩的时候相比变化都很大。于是我就想把接下来在实际工作中的一些经验技巧都记录下来发在 Ruby China，希望对喜欢 Ember，关注前端开发的朋友们有所帮助。</p></blockquote>
<p>来到新的公司新的团队，终于可以彻彻底底的使用 Ember 了，由于接下来有了发挥的空间和自由，所以我特别想先尝试尝试那些“传说中了好久”的新特性，第一个想到的就是 angle-bracket component（也就是尖括号形式的 component，写起来如同 HTML 一样，这也是 Angular／React 等框架创造 component 的形式，一度是 Angular 的主推卖点）。</p>
<p>虽然 Ember 2.0 已经发布了，但是 angle-bracket component 还要等到 ~2.1 才能在正式版本里出现，如果现在就想尝鲜的话就得使用 canary 版本了，这主要是因为 Ember 的新特性需要手动开启 |
44135dc37db6e69bf4a7cd78398c5a340
| 才能尝试，而目前只有 canary 版本允许你开启 Feature Flags（当前可以使用的 feature flags <a href="https://github.com/emberjs/ember.js/blob/master/FEATURES.md">有一份列表</a>可查）。</p>
<blockquote><p><strong>⚠警告：</strong>canary 版本是很不稳定的，并不推荐使用于要上线的应用。如果你要尝试新的特性，要么是新建一个测试用的 Ember App，要么是你的应用离正式上线还早并且你（和你的团队）折腾得起。就个人经验来说 canary 版本本身还算稳定（毕竟有测试），但问题主要出在：1）API 的变化没有文档，你需要自己去跟踪 issues；2）周边工具会收到影响（比如我在尝试 angle-bracket component 的时候，ember inspector 就有 bug 了，会影响正常的开发）</p></blockquote>
<p>下面简要列举开启 angle-bracket component 相关的 feature flags 的步骤：</p>
<h3>升级 ember 和 ember-data（可选）至 canary 版本</h3>
<p>更改 <code>bower.json</code> 文件内相关的部分为：</p>
<pre><code class="json">"dependencies": {
  "ember": "components/ember#canary",
  "ember-data": "components/ember-data#canary"
}</code></pre>
<p>然后执行 <code>$ bower uninstall ember &amp;&amp; bower uninstall ember-data &amp;&amp; bower install</code>，或者你也可以不去 <code>uninstall</code> 直接尝试 <code>bower install</code>，但是有时候会需要解决烦人的依赖问题。</p>
<h3>开启相关的 feature flags</h3>
<p>编辑 <code>config/environment.js</code>，在 <code>ENV.EmberENV.FEATURE</code> 下添加下面的代码：</p>
<pre><code class="javascript">var ENV = {
  // ...
  EmberENV: {
    FEATURES: {
        'ember-htmlbars-attribute-syntax': true,
        'ember-htmlbars-inline-if-helper': true,
        'ember-htmlbars-component-generation': true
    }
  // ...
  }
}</code></pre>
<h3>重写旧的 components</h3>
<p>旧的 components 都是 <code>Ember.Component</code> 的子类，而 angle-bracket component 则是 <code>Ember.GlimmerComponent</code> 的子类，所以你只需要保证这一点就可以完成转换了。一个新创建的 angle-bracket component 的代码看起来是这样的：</p>
<pre><code class="javascript">import Ember from 'ember'

export default Ember.GlimmerComponent.extend({
})</code></pre>
<p>不出意外的话我认为当正式版本发布后，现在的 <code>Ember.Component</code> 将被 <code>Ember.GlimmerComponent</code> 取代，所以以后可能还得改回来（这应该还有段日子的）。内部其他的 API 目前还是以 <code>Ember.Component</code> 的文档为准，未来有什么变化以后再看吧。</p>
<p>现在重要的是 component template 的写法，我在测试的时候把一个登录表单封装成了 component，以下是其 template 的写法和使用的方法：</p>
<pre><code class="handlebars">&lt;!-- components/signin-form/template.hbs --&gt;

&lt;form&gt;
  &lt;div class="form-group"&gt;
    &lt;label for="username"&gt;账号&lt;/label&gt;
    &lt;input class="form-control" id="username" name="username" value={{attrs.credential.username}}&gt;
  &lt;/div&gt;
  &lt;div class="form-group"&gt;
    &lt;label for="password"&gt;密码&lt;/label&gt;
    &lt;input class="form-control" id="password" name="password" type="password" value={{attrs.credential.password}}&gt;
  &lt;/div&gt;
  &lt;div class="form-group"&gt;
    &lt;button type="submit" class="button-submit"&gt;登录&lt;/button&gt;
  &lt;/div&gt;
&lt;/form&gt;</code></pre>
<pre><code class="handlebars">&lt;signin-form credential={{model}}&gt;&lt;/signin-form&gt;</code></pre>
<p>如上，可以看到新的模版语法里给 component 传递数据和访问数据的一些写法上的变化，这些变化其实是依赖于 <code>'ember-htmlbars-attribute-syntax'</code> 这个 feature flag 的。</p>
<h3>修复一个 deprecation warning</h3>
<p>观察修改后的应用，可以看到这样的警告：</p>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/3cc6bdf347318a5bbaa157670170613d.png" alt="" title=""></p>
<p>修补这个问题的代码很简单：</p>
<pre><code class="javascript">Ember.GlimmerComponent.reopenClass({
  isComponentFactory: true
})</code></pre>
<p>这段代码可以插入到 <code>app/app.js</code> 文件里，在应用初始化的时候即时生效。在此功能正式发布之后应该是不需要这段补丁代码的，目前来说也不会影响使用。</p>
<h3>结束</h3>
<p>就是这样了，从现在开始你可以使用新的语法来创建 components，除此之外还有新的 htmlbars-attribute-syntax（上例所示）和 htmlbars-inline-if-helpers 特性。HTMLBars 对于模版语法带来的改变，可以参考这篇总结性的文章：<a href="http://colintoh.com/blog/htmlbars">http://colintoh.com/blog/htmlbars</a></p>
<p>下一篇我打算讲讲 Sass 在 Ember CLI 里面的一些最佳方案，其中包括如何整合 Bootstrap 的 Sass 版（而不是直接 import 它的 css 版本），以及如何在此基础上使用其他的 Sass 库／框架等等。这个选题是因为新团队里的伙伴们对这件事情有些争执，所以我就确定了一个最佳方案，宗旨是：1）保证最大的灵活性和定制性；2）在此基础上让设置步骤足够简单。</p>
<p>我也乐意听听大家的反馈，如果有什么事情是你觉得很想了解的，或是你已经做到了但是觉得还不足够好的，可以回复我，等我有了答案之后我也会如此整理出来和大家分享。</p>
<h3>关于 Ember Inspector 的 bug</h3>
<p>目前使用 canary 版本的时候，ember inspector 会有一个隐蔽的 bug，其表现是：当你在 ember inspector 开启的状态下（开发者工具打开并且当前的 tab 是 Ember）刷新当前应用时页面会变空白，此时你可以在 console 下看到这样的警告：</p>
<p><img src="https://ruby-china-files.b0.upaiyun.com/photo/2015/31559723b708655aaa52ec7153d42057.png" alt="" title=""></p>
<p>这个问题其实和你的应用无关，是 ember inspector 在刷新后重新初始化的时候造成的，经个人测试只在最近的 canary 版本里存在，估计 ember inspector 更新以后会修复吧。有一个简单的临时解决办法就是关闭开发者工具然后再刷新就好了，之后再开启开发者工具之后 ember inspector 还可以用。其实你只要保证刷新的时候 ember inspector 不处于当前激活的 tab 就好了，开发者工具可以不关的。</p>
<hr>
<blockquote><p>原文首发于 <a href="https://ruby-china.org/topics/27155">Ruby China 社区</a>，转载请注明。</p></blockquote>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727708";}i:37;a:11:{s:5:"title";s:38:"DOM对象attribute和property的不同";s:4:"link";s:42:"http://segmentfault.com/a/1190000003727646";s:2:"id";s:42:"http://segmentfault.com/a/1190000003727646";s:7:"updated";s:25:"2015-09-09T18:15:08+08:00";s:9:"published";s:25:"2015-09-09T18:15:08+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:5:"zning";s:10:"author_uri";s:31:"http://segmentfault.com/u/zning";s:2:"re";a:1:{s:4:"rank";s:1:"2";}s:7:"summary";s:5153:"
<h2>property</h2>
<p>DOM对象的property值通过点方式获取</p>
<pre><code>document.body.className //获取body的类名</code></pre>
<p>DOM对象是对象，所以它可以像其他JS对象一样存储自定义的property</p>
<pre><code class="javascript">document.body.myData = {
    name : 'John'
}
document.body.sayHi = function(){
    alert('hello world');
}

console.log(document.body.myData.name);
console.log(document.body.sayHi());</code></pre>
<p>自定义的property和方法只会在JS中显示，不会影响HTML.</p>
<p>使用for...in可以遍历出所有的标准property和自定义propery</p>
<pre><code>document.body.custom = 5;
var list = [];
for(var key in document.body){
    list.push([key, document.body[key]]);
}
console.log(list);</code></pre>
<p>So,自定义的dom property：</p>
<ul>
<li><p>可以有任意值，property名区分大小写</p></li>
<li><p>不会影响HTML</p></li>
</ul>
<h2>attribute</h2>
<p>DOM节点提供如下方法来访问html attributes</p>
<pre><code> ele.hasAttribute(name) //&gt;=ie8
 ele.getAttribute(name)
 ele.setAttribute(name)
 ele.removeAttribute(name) //&gt;=ie8</code></pre>
<p><strong>Note:</strong> <em>IE8以下及ie8兼容模式下，setAttribute修改的是dom property，不是attribute</em>   </p>
<p>和property对比，attribute:</p>
<ul>
<li><p>值只能为字符串</p></li>
<li><p>名称不区分大小写</p></li>
<li><p>会在html中呈现</p></li>
<li><p>可以用DOM的attributes propery列出所有的attribute</p></li>
</ul>
<pre><code>&lt;body&gt;
  &lt;div about="Elephant" class="smiling"&gt;&lt;/div&gt;

  &lt;script&gt;
    var div = document.body.children[0]
    console.log( div.getAttribute('ABOUT') ) // (1)
    
    div.setAttribute('Test', 123)   // (2)
    console.log( document.body.innerHTML )   // (3)
  &lt;/script&gt;
&lt;/body&gt;</code></pre>
<h1>property和attribute的同步</h1>
<p>每个dom节点对象都有标准的properties，同步的可能性有三种</p>
<ol>
<li>
<p><strong>标准dom property和attribute值保持一致</strong></p>
<pre><code>document.body.setAttribute('id','pageWrap')
console.log(document.body.id) // pageWrap</code></pre>
</li>
<li>
<p><strong>标准dom property的值不一定和attribute完全一致</strong></p>
<pre><code>&lt;a id="test"&gt;测试&lt;/a&gt;

&lt;script&gt;    
var a = document.getElementById('test');
a.href = '/';
console.log(a.getAttribute('href')); // '/'
console.log(a.href); // 完整链接，但ie7及以下'/' (若链接中有中文，ff和chrome下会转义),这是因为w3c规定href property必须为格式良好的链接
&lt;/script&gt;   </code></pre>
<p>还有一些其他的attribute，同步的值却不相同，比如input.checked</p>
<pre><code>&lt;input type='checkbox' id='check' checked='aa'/&gt;
&lt;script&gt;
var input = document.getElementById('check');
console.log(input.checked); //true
console.log(input.getAttribute('checked')) //'aa'
&lt;/script&gt; </code></pre>
<p>input.checked的property值只可能为true或false，但attribute值是获取你填入的任意值</p>
</li>
<li>
<p><strong>有些内置property是单向同步的</strong><br>比如，input.value同步value attribute值，但value attribute值不同步value property值.<br>并且，input框内用户改变输入值后，value property值会随着变化，value attribute值不变.</p>
<pre><code>&lt;input type="text" id="text"/&gt;
&lt;script&gt;
var input = document.getElementById('text');

input.setAttribute('value','hello');
console.log(input.value); //hello
console.log(input.getAttribute('value')); //hello

input.value = 'new';
console.log(input.value); //new
console.log(input.getAttribute('value')); //hello

input.setAttribute('value','other'); //此时再改变value attribute，value property不再变化
console.log(input.value); //other
console.log(input.getAttribute('value')); //other
&lt;/script&gt;</code></pre>
<p>所以value attribute可以存储输入框的初始值,用于判断输入框值是否被改变</p>
</li>
<li>
<p><strong>同步的propery和attribute名称不一致</strong><br><em>class/className</em><br>因为JS中class是保留字，所以对于class attribute，用className property来代替class property。</p>
<pre><code>document.body.setAttribute('class', 'big red bloom');
console.log(document.body.className); //big red bloom, 但ie8及以下输出为空</code></pre>
<p>除了&lt;ie9,其他浏览器都会随着class attribute的变化，而修改类名。为了保证兼容性，不要用class attribute,用className property.</p>
</li>
</ol>
<h1>Summary</h1>
<p>attribute和property都是dom模型的重要特征.</p>
<p>在实际应用中，98%场景使用property，只有在如下两个场景使用attribute：</p>
<ol>
<li><p>自定义的html attribute，因为使用property时不会同步到HTML.</p></li>
<li><p>需要获取内置html attribute，并且不和property同步的，并且你确定你需要这个attribute. eg.input的value attribute.</p></li>
</ol>
<hr>
<p>translate for  <a href="http://javascript.info/tutorial/attributes-and-custom-properties">http://javascript.info/tutorial/attributes-and-custom-properties</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003727646";}i:38;a:11:{s:5:"title";s:24:"Nginx配置虚拟主机 ";s:4:"link";s:42:"http://segmentfault.com/a/1190000003726777";s:2:"id";s:42:"http://segmentfault.com/a/1190000003726777";s:7:"updated";s:25:"2015-09-09T16:03:04+08:00";s:9:"published";s:25:"2015-09-09T16:03:04+08:00";s:6:"author";s:3:"


";s:11:"author_name";s:6:"两仪";s:10:"author_uri";s:33:"http://segmentfault.com/u/liangyi";s:2:"re";a:1:{s:4:"rank";s:1:"2";}s:7:"summary";s:4726:"
<h2>增加 Nginx 虚拟主机</h2>
<p>这里假设大家的 Nginx 服务器已经安装好, 不懂的请阅读各 Linux 发行版的官方文档或者 LNMP 的安装说明. 配置 Virtual host 步骤如下:</p>
<ol>
<li><p>进入 /usr/local/nginx/conf/vhost 目录, 创建虚拟主机配置文件 demo.neoease.com.conf ({域名}.conf).</p></li>
<li>
<p>打开配置文件, 添加服务如下:</p>
<pre><code>server {
    listen       80;
    server_name demo.neoease.com;
    index index.html index.htm index.php;
    root  /var/www/demo_neoease_com;
 
    log_format demo.neoease.com '$remote_addr - $remote_user [$time_local] $request'
    '$status $body_bytes_sent $http_referer '
    '$http_user_agent $http_x_forwarded_for';
    access_log  /var/log/demo.neoease.com.log demo.neoease.com;
}
</code></pre>
</li>
<li>
<p>打开 Nginx 配置文件 /usr/local/nginx/conf/nginx.conf, 在 http 范围引入虚拟主机配置文件如下:</p>
<pre><code>include vhost/*.conf;
</code></pre>
</li>
<li><p>重启 Nginx 服务, 执行以下语句.</p></li>
</ol>
<h1>让 Nginx 虚拟主机支持 PHP</h1>
<p>在前面第 2 步的虚拟主机服务对应的目录加入对 PHP 的支持, 这里使用的是 FastCGI, 修改如下.</p>
<pre><code>server {
    listen       80;
    server_name demo.neoease.com;
    index index.html index.htm index.php;
    root  /var/www/demo_neoease_com;
 
    location ~ .*\.(php|php5)?$ {
        fastcgi_pass unix:/tmp/php-cgi.sock;
        fastcgi_index index.php;
        include fcgi.conf;
    }
 
    log_format demo.neoease.com '$remote_addr - $remote_user [$time_local] $request'
    '$status $body_bytes_sent $http_referer '
    '$http_user_agent $http_x_forwarded_for';
    access_log  /var/log/demo.neoease.com.log demo.neoease.com;
}
</code></pre>
<h2>图片防盗链</h2>
<p>图片作为重要的耗流量大的静态资源, 可能网站主并不希望其他网站直接引用, Nginx 可以通过 referer 来防止外站盗链图片.</p>
<pre><code>server {
    listen       80;
    server_name demo.neoease.com;
    index index.html index.htm index.php;
    root  /var/www/demo_neoease_com;
 
    # 这里为图片添加为期 1 年的过期时间, 并且禁止 Google, 百度和本站之外的网站引用图片
    location ~ .*\.(ico|jpg|jpeg|png|gif)$ {
        expires 1y;
        valid_referers none blocked demo.neoease.com *.google.com *.baidu.com;
        if ($invalid_referer) {
            return 404;
        }
    }
 
    log_format demo.neoease.com '$remote_addr - $remote_user [$time_local] $request'
    '$status $body_bytes_sent $http_referer '
    '$http_user_agent $http_x_forwarded_for';
    access_log  /var/log/demo.neoease.com.log demo.neoease.com;
}
</code></pre>
<h2>WordPress 伪静态配置</h2>
<p>如果将 WordPress 的链接结构设定为 /%postname%/, /%postname%.html 等格式时, 需要 rewrite URL, WordPress 提供 Apache 的 .htaccess 修改建议, 但没告知 Nginx 该如何修改. 我们可以将 WordPress 的虚拟主机配置修改如下:</p>
<pre><code>server {
    listen       80;
    server_name demo.neoease.com;
    index index.html index.htm index.php;
    root  /var/www/demo_neoease_com;
 
    location / {
        if (-f $request_filename/index.html){
            rewrite (.*) $1/index.html break;
        }
        if (-f $request_filename/index.php){
            rewrite (.*) $1/index.php;
        }
        if (!-f $request_filename){
            rewrite (.*) /index.php;
        }
    }
    rewrite /wp-admin$ $scheme://$host$uri/ permanent;
 
    location ~ .*\.(php|php5)?$ {
        fastcgi_pass unix:/tmp/php-cgi.sock;
        fastcgi_index index.php;
        include fcgi.conf;
    }
 
    log_format demo.neoease.com '$remote_addr - $remote_user [$time_local] $request'
    '$status $body_bytes_sent $http_referer '
    '$http_user_agent $http_x_forwarded_for';
    access_log  /var/log/demo.neoease.com.log demo.neoease.com;
}
</code></pre>
<p>LNMP 套件在提供了 WordPress 为静态配置文件 /usr/local/nginx/conf/wordpress.conf, 在虚拟主机配置的 server 范围引用如下即可.</p>
<pre><code>include wordpress.conf;
</code></pre>
<p>如果你使用 LNMP 套件, 进入 WordPress 后台发现会出现 404 页面, wp-admin 后面缺少了斜杆 /, 请在 wordpress.conf 最后添加以下语句:</p>
<pre><code>rewrite /wp-admin$ $scheme://$host$uri/ permanent;    
</code></pre>
<h2>帮助链接：</h2>
<p>原文链接：<a href="http://www.neoease.com/nginx-virtual-host/">http://www.neoease.com/nginx-virtual-host/</a><br>参考链接：<a href="http://zl382378867.blog.163.com/blog/static/407944212011124115813231/">http://zl382378867.blog.163.com/blog/static/407944212011124115813231/</a></p>
";s:12:"link_replies";s:42:"http://segmentfault.com/a/1190000003726777";}}s:7:"channel";a:6:{s:5:"title";s:28:"SegmentFault 最新的文章";s:7:"updated";s:25:"2015-09-12T16:58:42+08:00";s:4:"link";s:29:"http://segmentfault.com/blogs";s:9:"link_self";s:35:"http://segmentfault.com/feeds/blogs";s:2:"id";s:35:"http://segmentfault.com/feeds/blogs";s:15:"creativecommons";a:1:{s:7:"license";s:53:"http://www.creativecommons.org/licenses/by-sa/2.5/rdf";}}s:9:"textinput";a:0:{}s:5:"image";a:0:{}s:9:"feed_type";s:4:"Atom";s:12:"feed_version";N;s:8:"encoding";s:5:"UTF-8";s:16:"_source_encoding";s:0:"";s:5:"ERROR";s:0:"";s:7:"WARNING";s:0:"";s:19:"_CONTENT_CONSTRUCTS";a:6:{i:0;s:7:"content";i:1;s:7:"summary";i:2;s:4:"info";i:3;s:5:"title";i:4;s:7:"tagline";i:5;s:9:"copyright";}s:16:"_KNOWN_ENCODINGS";a:3:{i:0;s:5:"UTF-8";i:1;s:8:"US-ASCII";i:2;s:10:"ISO-8859-1";}s:5:"stack";a:1:{i:0;s:7:"updated";}s:9:"inchannel";b:1;s:6:"initem";b:1;s:9:"incontent";b:0;s:11:"intextinput";b:0;s:7:"inimage";b:0;s:17:"current_namespace";b:0;}